# This file was automatically generated by SWIG (http://www.swig.org).
# Version 1.3.36
#
# Don't modify this file, modify the SWIG interface instead.
# This file is compatible with both classic and new-style classes.

"""
The `Features` module gathers all Feature objects available in the SHOGUN toolkit.
"""

import _Features
import new
new_instancemethod = new.instancemethod
try:
    _swig_property = property
except NameError:
    pass # Python < 2.2 doesn't have 'property'.
def _swig_setattr_nondynamic(self,class_type,name,value,static=1):
    if (name == "thisown"): return self.this.own(value)
    if (name == "this"):
        if type(value).__name__ == 'PySwigObject':
            self.__dict__[name] = value
            return
    method = class_type.__swig_setmethods__.get(name,None)
    if method: return method(self,value)
    if (not static) or hasattr(self,name):
        self.__dict__[name] = value
    else:
        raise AttributeError("You cannot add attributes to %s" % self)

def _swig_setattr(self,class_type,name,value):
    return _swig_setattr_nondynamic(self,class_type,name,value,0)

def _swig_getattr(self,class_type,name):
    if (name == "thisown"): return self.this.own()
    method = class_type.__swig_getmethods__.get(name,None)
    if method: return method(self)
    raise AttributeError,name

def _swig_repr(self):
    try: strthis = "proxy of " + self.this.__repr__()
    except: strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)

import types
try:
    _object = types.ObjectType
    _newclass = 1
except AttributeError:
    class _object : pass
    _newclass = 0
del types


class ShogunException(_object):
    """Proxy of C++ ShogunException class"""
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, ShogunException, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, ShogunException, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """__init__(self, str) -> ShogunException"""
        this = _Features.new_ShogunException(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_ShogunException
    __del__ = lambda self : None;
    def get_exception_string(*args):
        """get_exception_string(self) -> str"""
        return _Features.ShogunException_get_exception_string(*args)

ShogunException_swigregister = _Features.ShogunException_swigregister
ShogunException_swigregister(ShogunException)

MSG_GCDEBUG = _Features.MSG_GCDEBUG
MSG_DEBUG = _Features.MSG_DEBUG
MSG_INFO = _Features.MSG_INFO
MSG_NOTICE = _Features.MSG_NOTICE
MSG_WARN = _Features.MSG_WARN
MSG_ERROR = _Features.MSG_ERROR
MSG_CRITICAL = _Features.MSG_CRITICAL
MSG_ALERT = _Features.MSG_ALERT
MSG_EMERGENCY = _Features.MSG_EMERGENCY
MSG_MESSAGEONLY = _Features.MSG_MESSAGEONLY
class IO(_object):
    """Proxy of C++ IO class"""
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, IO, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, IO, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> IO
        __init__(self, orig) -> IO
        """
        this = _Features.new_IO(*args)
        try: self.this.append(this)
        except: self.this = this
    def set_loglevel(*args):
        """set_loglevel(self, level)"""
        return _Features.IO_set_loglevel(*args)

    def get_loglevel(*args):
        """get_loglevel(self) -> EMessageType"""
        return _Features.IO_get_loglevel(*args)

    def get_show_progress(*args):
        """get_show_progress(self) -> bool"""
        return _Features.IO_get_show_progress(*args)

    def get_show_file_and_line(*args):
        """get_show_file_and_line(self) -> bool"""
        return _Features.IO_get_show_file_and_line(*args)

    def message(*args):
        """message(self, prio, file, line, fmt, ?)"""
        return _Features.IO_message(*args)

    def progress(*args):
        """
        progress(self, current_val, min_val=0.0, max_val=1.0, decimals=1, 
            prefix="PROGRESS:\t")
        progress(self, current_val, min_val=0.0, max_val=1.0, decimals=1)
        progress(self, current_val, min_val=0.0, max_val=1.0)
        progress(self, current_val, min_val=0.0)
        progress(self, current_val)
        """
        return _Features.IO_progress(*args)

    def absolute_progress(*args):
        """
        absolute_progress(self, current_val, val, min_val=0.0, max_val=1.0, decimals=1, 
            prefix="PROGRESS:\t")
        absolute_progress(self, current_val, val, min_val=0.0, max_val=1.0, decimals=1)
        absolute_progress(self, current_val, val, min_val=0.0, max_val=1.0)
        absolute_progress(self, current_val, val, min_val=0.0)
        absolute_progress(self, current_val, val)
        """
        return _Features.IO_absolute_progress(*args)

    def done(*args):
        """done(self)"""
        return _Features.IO_done(*args)

    def not_implemented(*args):
        """not_implemented(self, file, line)"""
        return _Features.IO_not_implemented(*args)

    def deprecated(*args):
        """deprecated(self, file, line)"""
        return _Features.IO_deprecated(*args)

    def buffered_message(*args):
        """buffered_message(self, prio, fmt, ?)"""
        return _Features.IO_buffered_message(*args)

    def skip_spaces(*args):
        """skip_spaces(str) -> str"""
        return _Features.IO_skip_spaces(*args)

    if _newclass:skip_spaces = staticmethod(skip_spaces)
    __swig_getmethods__["skip_spaces"] = lambda x: skip_spaces
    def skip_blanks(*args):
        """skip_blanks(str) -> str"""
        return _Features.IO_skip_blanks(*args)

    if _newclass:skip_blanks = staticmethod(skip_blanks)
    __swig_getmethods__["skip_blanks"] = lambda x: skip_blanks
    def get_target(*args):
        """get_target(self) -> FILE"""
        return _Features.IO_get_target(*args)

    def set_target(*args):
        """set_target(self, target)"""
        return _Features.IO_set_target(*args)

    def set_target_to_stderr(*args):
        """set_target_to_stderr(self)"""
        return _Features.IO_set_target_to_stderr(*args)

    def set_target_to_stdout(*args):
        """set_target_to_stdout(self)"""
        return _Features.IO_set_target_to_stdout(*args)

    def enable_progress(*args):
        """enable_progress(self)"""
        return _Features.IO_enable_progress(*args)

    def disable_progress(*args):
        """disable_progress(self)"""
        return _Features.IO_disable_progress(*args)

    def enable_file_and_line(*args):
        """enable_file_and_line(self)"""
        return _Features.IO_enable_file_and_line(*args)

    def disable_file_and_line(*args):
        """disable_file_and_line(self)"""
        return _Features.IO_disable_file_and_line(*args)

    def set_dirname(*args):
        """set_dirname(dirname)"""
        return _Features.IO_set_dirname(*args)

    if _newclass:set_dirname = staticmethod(set_dirname)
    __swig_getmethods__["set_dirname"] = lambda x: set_dirname
    def concat_filename(*args):
        """concat_filename(filename) -> str"""
        return _Features.IO_concat_filename(*args)

    if _newclass:concat_filename = staticmethod(concat_filename)
    __swig_getmethods__["concat_filename"] = lambda x: concat_filename
    def filter(*args):
        """filter(d) -> int"""
        return _Features.IO_filter(*args)

    if _newclass:filter = staticmethod(filter)
    __swig_getmethods__["filter"] = lambda x: filter
    def ref(*args):
        """ref(self) ->  int"""
        return _Features.IO_ref(*args)

    def ref_count(*args):
        """ref_count(self) ->  int"""
        return _Features.IO_ref_count(*args)

    def unref(*args):
        """unref(self) ->  int"""
        return _Features.IO_unref(*args)

    def get_name(*args):
        """get_name(self) -> str"""
        return _Features.IO_get_name(*args)

    __swig_destroy__ = _Features.delete_IO
    __del__ = lambda self : None;
IO_swigregister = _Features.IO_swigregister
IO_swigregister(IO)
cvar = _Features.cvar

def IO_skip_spaces(*args):
  """IO_skip_spaces(str) -> str"""
  return _Features.IO_skip_spaces(*args)

def IO_skip_blanks(*args):
  """IO_skip_blanks(str) -> str"""
  return _Features.IO_skip_blanks(*args)

def IO_set_dirname(*args):
  """IO_set_dirname(dirname)"""
  return _Features.IO_set_dirname(*args)

def IO_concat_filename(*args):
  """IO_concat_filename(filename) -> str"""
  return _Features.IO_concat_filename(*args)

def IO_filter(*args):
  """IO_filter(d) -> int"""
  return _Features.IO_filter(*args)

class SGObject(_object):
    """Proxy of C++ SGObject class"""
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, SGObject, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, SGObject, name)
    def __init__(self, *args, **kwargs): raise AttributeError, "No constructor defined"
    __repr__ = _swig_repr
    __swig_destroy__ = _Features.delete_SGObject
    __del__ = lambda self : None;
    def ref(*args):
        """ref(self) ->  int"""
        return _Features.SGObject_ref(*args)

    def ref_count(*args):
        """ref_count(self) ->  int"""
        return _Features.SGObject_ref_count(*args)

    def unref(*args):
        """unref(self) ->  int"""
        return _Features.SGObject_unref(*args)

    def get_name(*args):
        """get_name(self) -> str"""
        return _Features.SGObject_get_name(*args)

    __swig_setmethods__["io"] = _Features.SGObject_io_set
    __swig_getmethods__["io"] = _Features.SGObject_io_get
    if _newclass:io = _swig_property(_Features.SGObject_io_get, _Features.SGObject_io_set)
    __swig_setmethods__["parallel"] = _Features.SGObject_parallel_set
    __swig_getmethods__["parallel"] = _Features.SGObject_parallel_get
    if _newclass:parallel = _swig_property(_Features.SGObject_parallel_get, _Features.SGObject_parallel_set)
    __swig_setmethods__["version"] = _Features.SGObject_version_set
    __swig_getmethods__["version"] = _Features.SGObject_version_get
    if _newclass:version = _swig_property(_Features.SGObject_version_get, _Features.SGObject_version_set)
SGObject_swigregister = _Features.SGObject_swigregister
SGObject_swigregister(SGObject)

class Version(_object):
    """Proxy of C++ Version class"""
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, Version, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, Version, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """__init__(self) -> Version"""
        this = _Features.new_Version(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_Version
    __del__ = lambda self : None;
    def print_version(*args):
        """print_version()"""
        return _Features.Version_print_version(*args)

    if _newclass:print_version = staticmethod(print_version)
    __swig_getmethods__["print_version"] = lambda x: print_version
    def get_version_extra(*args):
        """get_version_extra() -> str"""
        return _Features.Version_get_version_extra(*args)

    if _newclass:get_version_extra = staticmethod(get_version_extra)
    __swig_getmethods__["get_version_extra"] = lambda x: get_version_extra
    def get_version_release(*args):
        """get_version_release() -> str"""
        return _Features.Version_get_version_release(*args)

    if _newclass:get_version_release = staticmethod(get_version_release)
    __swig_getmethods__["get_version_release"] = lambda x: get_version_release
    def get_version_revision(*args):
        """get_version_revision() ->  int"""
        return _Features.Version_get_version_revision(*args)

    if _newclass:get_version_revision = staticmethod(get_version_revision)
    __swig_getmethods__["get_version_revision"] = lambda x: get_version_revision
    def get_version_year(*args):
        """get_version_year() ->  int"""
        return _Features.Version_get_version_year(*args)

    if _newclass:get_version_year = staticmethod(get_version_year)
    __swig_getmethods__["get_version_year"] = lambda x: get_version_year
    def get_version_month(*args):
        """get_version_month() ->  int"""
        return _Features.Version_get_version_month(*args)

    if _newclass:get_version_month = staticmethod(get_version_month)
    __swig_getmethods__["get_version_month"] = lambda x: get_version_month
    def get_version_day(*args):
        """get_version_day() ->  int"""
        return _Features.Version_get_version_day(*args)

    if _newclass:get_version_day = staticmethod(get_version_day)
    __swig_getmethods__["get_version_day"] = lambda x: get_version_day
    def get_version_hour(*args):
        """get_version_hour() ->  int"""
        return _Features.Version_get_version_hour(*args)

    if _newclass:get_version_hour = staticmethod(get_version_hour)
    __swig_getmethods__["get_version_hour"] = lambda x: get_version_hour
    def get_version_minute(*args):
        """get_version_minute() ->  int"""
        return _Features.Version_get_version_minute(*args)

    if _newclass:get_version_minute = staticmethod(get_version_minute)
    __swig_getmethods__["get_version_minute"] = lambda x: get_version_minute
    def get_version_in_minutes(*args):
        """get_version_in_minutes() -> int"""
        return _Features.Version_get_version_in_minutes(*args)

    if _newclass:get_version_in_minutes = staticmethod(get_version_in_minutes)
    __swig_getmethods__["get_version_in_minutes"] = lambda x: get_version_in_minutes
    def ref(*args):
        """ref(self) ->  int"""
        return _Features.Version_ref(*args)

    def ref_count(*args):
        """ref_count(self) ->  int"""
        return _Features.Version_ref_count(*args)

    def unref(*args):
        """unref(self) ->  int"""
        return _Features.Version_unref(*args)

Version_swigregister = _Features.Version_swigregister
Version_swigregister(Version)

def Version_print_version(*args):
  """Version_print_version()"""
  return _Features.Version_print_version(*args)

def Version_get_version_extra(*args):
  """Version_get_version_extra() -> str"""
  return _Features.Version_get_version_extra(*args)

def Version_get_version_release(*args):
  """Version_get_version_release() -> str"""
  return _Features.Version_get_version_release(*args)

def Version_get_version_revision(*args):
  """Version_get_version_revision() ->  int"""
  return _Features.Version_get_version_revision(*args)

def Version_get_version_year(*args):
  """Version_get_version_year() ->  int"""
  return _Features.Version_get_version_year(*args)

def Version_get_version_month(*args):
  """Version_get_version_month() ->  int"""
  return _Features.Version_get_version_month(*args)

def Version_get_version_day(*args):
  """Version_get_version_day() ->  int"""
  return _Features.Version_get_version_day(*args)

def Version_get_version_hour(*args):
  """Version_get_version_hour() ->  int"""
  return _Features.Version_get_version_hour(*args)

def Version_get_version_minute(*args):
  """Version_get_version_minute() ->  int"""
  return _Features.Version_get_version_minute(*args)

def Version_get_version_in_minutes(*args):
  """Version_get_version_in_minutes() -> int"""
  return _Features.Version_get_version_in_minutes(*args)

class Parallel(_object):
    """Proxy of C++ Parallel class"""
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, Parallel, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, Parallel, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> Parallel
        __init__(self, orig) -> Parallel
        """
        this = _Features.new_Parallel(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_Parallel
    __del__ = lambda self : None;
    def get_num_cpus(*args):
        """get_num_cpus(self) ->  int"""
        return _Features.Parallel_get_num_cpus(*args)

    def set_num_threads(*args):
        """set_num_threads(self, n)"""
        return _Features.Parallel_set_num_threads(*args)

    def get_num_threads(*args):
        """get_num_threads(self) ->  int"""
        return _Features.Parallel_get_num_threads(*args)

    def ref(*args):
        """ref(self) ->  int"""
        return _Features.Parallel_ref(*args)

    def ref_count(*args):
        """ref_count(self) ->  int"""
        return _Features.Parallel_ref_count(*args)

    def unref(*args):
        """unref(self) ->  int"""
        return _Features.Parallel_unref(*args)

Parallel_swigregister = _Features.Parallel_swigregister
Parallel_swigregister(Parallel)

class PySwigIterator(_object):
    """Proxy of C++ PySwigIterator class"""
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, PySwigIterator, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, PySwigIterator, name)
    def __init__(self, *args, **kwargs): raise AttributeError, "No constructor defined"
    __repr__ = _swig_repr
    __swig_destroy__ = _Features.delete_PySwigIterator
    __del__ = lambda self : None;
    def value(*args):
        """value(self) -> PyObject"""
        return _Features.PySwigIterator_value(*args)

    def incr(*args):
        """
        incr(self, n=1) -> PySwigIterator
        incr(self) -> PySwigIterator
        """
        return _Features.PySwigIterator_incr(*args)

    def decr(*args):
        """
        decr(self, n=1) -> PySwigIterator
        decr(self) -> PySwigIterator
        """
        return _Features.PySwigIterator_decr(*args)

    def distance(*args):
        """distance(self, x) -> ptrdiff_t"""
        return _Features.PySwigIterator_distance(*args)

    def equal(*args):
        """equal(self, x) -> bool"""
        return _Features.PySwigIterator_equal(*args)

    def copy(*args):
        """copy(self) -> PySwigIterator"""
        return _Features.PySwigIterator_copy(*args)

    def next(*args):
        """next(self) -> PyObject"""
        return _Features.PySwigIterator_next(*args)

    def previous(*args):
        """previous(self) -> PyObject"""
        return _Features.PySwigIterator_previous(*args)

    def advance(*args):
        """advance(self, n) -> PySwigIterator"""
        return _Features.PySwigIterator_advance(*args)

    def __eq__(*args):
        """__eq__(self, x) -> bool"""
        return _Features.PySwigIterator___eq__(*args)

    def __ne__(*args):
        """__ne__(self, x) -> bool"""
        return _Features.PySwigIterator___ne__(*args)

    def __iadd__(*args):
        """__iadd__(self, n) -> PySwigIterator"""
        return _Features.PySwigIterator___iadd__(*args)

    def __isub__(*args):
        """__isub__(self, n) -> PySwigIterator"""
        return _Features.PySwigIterator___isub__(*args)

    def __add__(*args):
        """__add__(self, n) -> PySwigIterator"""
        return _Features.PySwigIterator___add__(*args)

    def __sub__(*args):
        """
        __sub__(self, n) -> PySwigIterator
        __sub__(self, x) -> ptrdiff_t
        """
        return _Features.PySwigIterator___sub__(*args)

    def __iter__(self): return self
PySwigIterator_swigregister = _Features.PySwigIterator_swigregister
PySwigIterator_swigregister(PySwigIterator)

class IntVector(_object):
    """Proxy of C++ IntVector class"""
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, IntVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, IntVector, name)
    __repr__ = _swig_repr
    def iterator(*args):
        """iterator(self, PYTHON_SELF) -> PySwigIterator"""
        return _Features.IntVector_iterator(*args)

    def __iter__(self): return self.iterator()
    def __nonzero__(*args):
        """__nonzero__(self) -> bool"""
        return _Features.IntVector___nonzero__(*args)

    def __len__(*args):
        """__len__(self) -> std::vector<(int)>::size_type"""
        return _Features.IntVector___len__(*args)

    def pop(*args):
        """pop(self) -> std::vector<(int)>::value_type"""
        return _Features.IntVector_pop(*args)

    def __getslice__(*args):
        """__getslice__(self, i, j) -> IntVector"""
        return _Features.IntVector___getslice__(*args)

    def __setslice__(*args):
        """__setslice__(self, i, j, v)"""
        return _Features.IntVector___setslice__(*args)

    def __delslice__(*args):
        """__delslice__(self, i, j)"""
        return _Features.IntVector___delslice__(*args)

    def __delitem__(*args):
        """__delitem__(self, i)"""
        return _Features.IntVector___delitem__(*args)

    def __getitem__(*args):
        """__getitem__(self, i) -> std::vector<(int)>::value_type"""
        return _Features.IntVector___getitem__(*args)

    def __setitem__(*args):
        """__setitem__(self, i, x)"""
        return _Features.IntVector___setitem__(*args)

    def append(*args):
        """append(self, x)"""
        return _Features.IntVector_append(*args)

    def empty(*args):
        """empty(self) -> bool"""
        return _Features.IntVector_empty(*args)

    def size(*args):
        """size(self) -> std::vector<(int)>::size_type"""
        return _Features.IntVector_size(*args)

    def clear(*args):
        """clear(self)"""
        return _Features.IntVector_clear(*args)

    def swap(*args):
        """swap(self, v)"""
        return _Features.IntVector_swap(*args)

    def get_allocator(*args):
        """get_allocator(self) -> std::vector<(int)>::allocator_type"""
        return _Features.IntVector_get_allocator(*args)

    def begin(*args):
        """begin(self) -> std::vector<(int)>::const_iterator"""
        return _Features.IntVector_begin(*args)

    def end(*args):
        """end(self) -> std::vector<(int)>::const_iterator"""
        return _Features.IntVector_end(*args)

    def rbegin(*args):
        """rbegin(self) -> std::vector<(int)>::const_reverse_iterator"""
        return _Features.IntVector_rbegin(*args)

    def rend(*args):
        """rend(self) -> std::vector<(int)>::const_reverse_iterator"""
        return _Features.IntVector_rend(*args)

    def pop_back(*args):
        """pop_back(self)"""
        return _Features.IntVector_pop_back(*args)

    def erase(*args):
        """
        erase(self, pos) -> std::vector<(int)>::iterator
        erase(self, first, last) -> std::vector<(int)>::iterator
        """
        return _Features.IntVector_erase(*args)

    def __init__(self, *args): 
        """
        __init__(self) -> IntVector
        __init__(self, ?) -> IntVector
        __init__(self, size) -> IntVector
        __init__(self, size, value) -> IntVector
        """
        this = _Features.new_IntVector(*args)
        try: self.this.append(this)
        except: self.this = this
    def push_back(*args):
        """push_back(self, x)"""
        return _Features.IntVector_push_back(*args)

    def front(*args):
        """front(self) -> std::vector<(int)>::value_type"""
        return _Features.IntVector_front(*args)

    def back(*args):
        """back(self) -> std::vector<(int)>::value_type"""
        return _Features.IntVector_back(*args)

    def assign(*args):
        """assign(self, n, x)"""
        return _Features.IntVector_assign(*args)

    def resize(*args):
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _Features.IntVector_resize(*args)

    def insert(*args):
        """
        insert(self, pos, x) -> std::vector<(int)>::iterator
        insert(self, pos, n, x)
        """
        return _Features.IntVector_insert(*args)

    def reserve(*args):
        """reserve(self, n)"""
        return _Features.IntVector_reserve(*args)

    def capacity(*args):
        """capacity(self) -> std::vector<(int)>::size_type"""
        return _Features.IntVector_capacity(*args)

    __swig_destroy__ = _Features.delete_IntVector
    __del__ = lambda self : None;
IntVector_swigregister = _Features.IntVector_swigregister
IntVector_swigregister(IntVector)

class DoubleVector(_object):
    """Proxy of C++ DoubleVector class"""
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, DoubleVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, DoubleVector, name)
    __repr__ = _swig_repr
    def iterator(*args):
        """iterator(self, PYTHON_SELF) -> PySwigIterator"""
        return _Features.DoubleVector_iterator(*args)

    def __iter__(self): return self.iterator()
    def __nonzero__(*args):
        """__nonzero__(self) -> bool"""
        return _Features.DoubleVector___nonzero__(*args)

    def __len__(*args):
        """__len__(self) -> std::vector<(double)>::size_type"""
        return _Features.DoubleVector___len__(*args)

    def pop(*args):
        """pop(self) -> std::vector<(double)>::value_type"""
        return _Features.DoubleVector_pop(*args)

    def __getslice__(*args):
        """__getslice__(self, i, j) -> DoubleVector"""
        return _Features.DoubleVector___getslice__(*args)

    def __setslice__(*args):
        """__setslice__(self, i, j, v)"""
        return _Features.DoubleVector___setslice__(*args)

    def __delslice__(*args):
        """__delslice__(self, i, j)"""
        return _Features.DoubleVector___delslice__(*args)

    def __delitem__(*args):
        """__delitem__(self, i)"""
        return _Features.DoubleVector___delitem__(*args)

    def __getitem__(*args):
        """__getitem__(self, i) -> std::vector<(double)>::value_type"""
        return _Features.DoubleVector___getitem__(*args)

    def __setitem__(*args):
        """__setitem__(self, i, x)"""
        return _Features.DoubleVector___setitem__(*args)

    def append(*args):
        """append(self, x)"""
        return _Features.DoubleVector_append(*args)

    def empty(*args):
        """empty(self) -> bool"""
        return _Features.DoubleVector_empty(*args)

    def size(*args):
        """size(self) -> std::vector<(double)>::size_type"""
        return _Features.DoubleVector_size(*args)

    def clear(*args):
        """clear(self)"""
        return _Features.DoubleVector_clear(*args)

    def swap(*args):
        """swap(self, v)"""
        return _Features.DoubleVector_swap(*args)

    def get_allocator(*args):
        """get_allocator(self) -> std::vector<(double)>::allocator_type"""
        return _Features.DoubleVector_get_allocator(*args)

    def begin(*args):
        """begin(self) -> std::vector<(double)>::const_iterator"""
        return _Features.DoubleVector_begin(*args)

    def end(*args):
        """end(self) -> std::vector<(double)>::const_iterator"""
        return _Features.DoubleVector_end(*args)

    def rbegin(*args):
        """rbegin(self) -> std::vector<(double)>::const_reverse_iterator"""
        return _Features.DoubleVector_rbegin(*args)

    def rend(*args):
        """rend(self) -> std::vector<(double)>::const_reverse_iterator"""
        return _Features.DoubleVector_rend(*args)

    def pop_back(*args):
        """pop_back(self)"""
        return _Features.DoubleVector_pop_back(*args)

    def erase(*args):
        """
        erase(self, pos) -> std::vector<(double)>::iterator
        erase(self, first, last) -> std::vector<(double)>::iterator
        """
        return _Features.DoubleVector_erase(*args)

    def __init__(self, *args): 
        """
        __init__(self) -> DoubleVector
        __init__(self, ?) -> DoubleVector
        __init__(self, size) -> DoubleVector
        __init__(self, size, value) -> DoubleVector
        """
        this = _Features.new_DoubleVector(*args)
        try: self.this.append(this)
        except: self.this = this
    def push_back(*args):
        """push_back(self, x)"""
        return _Features.DoubleVector_push_back(*args)

    def front(*args):
        """front(self) -> std::vector<(double)>::value_type"""
        return _Features.DoubleVector_front(*args)

    def back(*args):
        """back(self) -> std::vector<(double)>::value_type"""
        return _Features.DoubleVector_back(*args)

    def assign(*args):
        """assign(self, n, x)"""
        return _Features.DoubleVector_assign(*args)

    def resize(*args):
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _Features.DoubleVector_resize(*args)

    def insert(*args):
        """
        insert(self, pos, x) -> std::vector<(double)>::iterator
        insert(self, pos, n, x)
        """
        return _Features.DoubleVector_insert(*args)

    def reserve(*args):
        """reserve(self, n)"""
        return _Features.DoubleVector_reserve(*args)

    def capacity(*args):
        """capacity(self) -> std::vector<(double)>::size_type"""
        return _Features.DoubleVector_capacity(*args)

    __swig_destroy__ = _Features.delete_DoubleVector
    __del__ = lambda self : None;
DoubleVector_swigregister = _Features.DoubleVector_swigregister
DoubleVector_swigregister(DoubleVector)

class Features(SGObject):
    """
    The class Features is the base class of all feature objects.

    It can be understood as a dense real valued feature matrix (with e.g.
    columns as single feature vectors), a set of strings, graphs or any
    other arbitrary collection of objects. As a result this class is kept
    very general and implements only very weak interfaces to

    duplicate the Feature object

    obtain the feature type (like F_DREAL, F_SHORT ...)

    obtain the feature class (like Simple dense matrices, sparse or
    strings)

    obtain the number of feature "vectors"

    In addition it provides helpers to check e.g. for compability of
    feature objects.

    Currently there are 3 general feature classes, which are
    CSimpleFeatures (dense matrices), CSparseFeatures (sparse matrices),
    CStringFeatures (a set of strings) from which all the specific
    features like CSimpleFeatures<float64_t> (dense real valued feature
    matrices) are derived.

    C++ includes: Features.h 
    """
    __swig_setmethods__ = {}
    for _s in [SGObject]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, Features, name, value)
    __swig_getmethods__ = {}
    for _s in [SGObject]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, Features, name)
    def __init__(self, *args, **kwargs): raise AttributeError, "No constructor defined"
    __repr__ = _swig_repr
    def duplicate(*args):
        """
        duplicate(self) -> Features

        duplicate feature object

        abstract base method

        feature object 
        """
        return _Features.Features_duplicate(*args)

    __swig_destroy__ = _Features.delete_Features
    __del__ = lambda self : None;
    def get_feature_type(*args):
        """
        get_feature_type(self) -> EFeatureType

        get feature type

        abstract base method

        templated feature type 
        """
        return _Features.Features_get_feature_type(*args)

    def get_feature_class(*args):
        """
        get_feature_class(self) -> EFeatureClass

        get feature class

        abstract base method

        feature class like STRING, SIMPLE, SPARSE... 
        """
        return _Features.Features_get_feature_class(*args)

    def add_preproc(*args):
        """
        add_preproc(self, p) ->  int

        add preprocessor

        Parameters:
        -----------

        p:  preprocessor to set

        something inty 
        """
        return _Features.Features_add_preproc(*args)

    def del_preproc(*args):
        """
        del_preproc(self, num) -> CPreProc

        delete preprocessor from list caller has to clean up returned preproc

        Parameters:
        -----------

        num:  index of preprocessor in list 
        """
        return _Features.Features_del_preproc(*args)

    def get_preproc(*args):
        """
        get_preproc(self, num) -> CPreProc

        get specified preprocessor

        Parameters:
        -----------

        num:  index of preprocessor in list 
        """
        return _Features.Features_get_preproc(*args)

    def set_preprocessed(*args):
        """
        set_preprocessed(self, num)

        set applied flag for preprocessor

        Parameters:
        -----------

        num:  index of preprocessor in list 
        """
        return _Features.Features_set_preprocessed(*args)

    def is_preprocessed(*args):
        """
        is_preprocessed(self, num) -> bool

        get whether specified preprocessor was already applied

        Parameters:
        -----------

        num:  index of preprocessor in list 
        """
        return _Features.Features_is_preprocessed(*args)

    def get_num_preprocessed(*args):
        """
        get_num_preprocessed(self) ->  int

        get the number of applied preprocs

        number of applied preprocessors 
        """
        return _Features.Features_get_num_preprocessed(*args)

    def get_num_preproc(*args):
        """
        get_num_preproc(self) ->  int

        get number of preprocessors

        number of preprocessors 
        """
        return _Features.Features_get_num_preproc(*args)

    def clean_preprocs(*args):
        """
        clean_preprocs(self)

        clears all preprocs 
        """
        return _Features.Features_clean_preprocs(*args)

    def get_cache_size(*args):
        """
        get_cache_size(self) ->  int

        get cache size

        cache size 
        """
        return _Features.Features_get_cache_size(*args)

    def get_num_vectors(*args):
        """
        get_num_vectors(self) ->  int

        get number of examples/vectors

        abstract base method

        number of examples/vectors 
        """
        return _Features.Features_get_num_vectors(*args)

    def reshape(*args):
        """
        reshape(self, num_features, num_vectors) -> bool

        in case there is a feature matrix allow for reshaping

        NOT IMPLEMENTED!

        Parameters:
        -----------

        num_features:  new number of features

        num_vectors:  new number of vectors

        if reshaping was successful 
        """
        return _Features.Features_reshape(*args)

    def get_size(*args):
        """
        get_size(self) ->  int

        get memory footprint of one feature

        abstract base method

        memory footprint of one feature 
        """
        return _Features.Features_get_size(*args)

    def list_feature_obj(*args):
        """
        list_feature_obj(self)

        list feature object 
        """
        return _Features.Features_list_feature_obj(*args)

    def load(*args):
        """
        load(self, fname) -> bool

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        if loading was successful 
        """
        return _Features.Features_load(*args)

    def save(*args):
        """
        save(self, fname) -> bool

        save features to file

        Parameters:
        -----------

        fname:  filename to save to

        if saving was successful 
        """
        return _Features.Features_save(*args)

    def check_feature_compatibility(*args):
        """
        check_feature_compatibility(self, f) -> bool

        check feature compatibility

        Parameters:
        -----------

        f:  features to check for compatibility

        if features are compatible 
        """
        return _Features.Features_check_feature_compatibility(*args)

    def has_property(*args):
        """
        has_property(self, p) -> bool

        check if features have given property

        Parameters:
        -----------

        p:  feature property

        if features have given property 
        """
        return _Features.Features_has_property(*args)

    def set_property(*args):
        """
        set_property(self, p)

        set property

        Parameters:
        -----------

        p:  kernel property to set 
        """
        return _Features.Features_set_property(*args)

    def unset_property(*args):
        """
        unset_property(self, p)

        unset property

        Parameters:
        -----------

        p:  kernel property to unset 
        """
        return _Features.Features_unset_property(*args)

Features_swigregister = _Features.Features_swigregister
Features_swigregister(Features)

class DotFeatures(Features):
    """
    Features that support dot products among other operations.

    DotFeatures support the following operations:

    a way to obtain the dimensionality of the feature space, i.e.
    $\\mbox{dim}({\\cal X})$

    dot product between feature vectors:

    \\[r = {\\bf x} \\cdot {\\bf x'}\\]

    dot product between feature vector and a dense vector ${\\bf z}$:

    \\[r = {\\bf x} \\cdot {\\bf z}\\]

    multiplication with a scalar $\\alpha$ and addition on to a dense
    vector ${\\bf z}$:

    \\[{\\bf z'} = \\alpha {\\bf x} + {\\bf z}\\]

    C++ includes: DotFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, DotFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, DotFeatures, name)
    def __init__(self, *args, **kwargs): raise AttributeError, "No constructor defined"
    __repr__ = _swig_repr
    __swig_destroy__ = _Features.delete_DotFeatures
    __del__ = lambda self : None;
    def get_dim_feature_space(*args):
        """
        get_dim_feature_space(self) ->  int

        obtain the dimensionality of the feature space

        (not mix this up with the dimensionality of the input space, usually
        obtained via get_num_features())

        dimensionality 
        """
        return _Features.DotFeatures_get_dim_feature_space(*args)

    def dot(*args):
        """
        dot(self, vec_idx1, vec_idx2) -> float

        compute dot product between vector1 and vector2, appointed by their
        indices

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec_idx2:  index of second vector 
        """
        return _Features.DotFeatures_dot(*args)

    def dense_dot(*args):
        """
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.DotFeatures_dense_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.DotFeatures_add_to_dense_vec(*args)

    def dense_dot_range(*args):
        """
        dense_dot_range(self, output, start, stop, alphas, vec, dim, b)

        Compute the dot product for a range of vectors. This function makes
        use of dense_dot alphas[i] * sparse[i]^T * w + b

        Parameters:
        -----------

        output:  result for the given vector range

        start:  start vector range from this idx

        stop:  stop vector range at this idx

        alphas:  scalars to multiply with, may be NULL

        vec:  dense vector to compute dot product with

        dim:  length of the dense vector

        b:  bias 
        """
        return _Features.DotFeatures_dense_dot_range(*args)

    def dense_dot_range_helper(*args):
        """dense_dot_range_helper(p) -> void"""
        return _Features.DotFeatures_dense_dot_range_helper(*args)

    if _newclass:dense_dot_range_helper = staticmethod(dense_dot_range_helper)
    __swig_getmethods__["dense_dot_range_helper"] = lambda x: dense_dot_range_helper
    def get_nnz_features_for_vector(*args):
        """
        get_nnz_features_for_vector(self, num) ->  int

        get number of non-zero features in vector

        (in case accurate estimates are too expensive overestimating is OK)

        Parameters:
        -----------

        num:  which vector

        number of sparse features in vector 
        """
        return _Features.DotFeatures_get_nnz_features_for_vector(*args)

    def get_combined_feature_weight(*args):
        """
        get_combined_feature_weight(self) -> float

        get combined feature weight

        combined feature weight 
        """
        return _Features.DotFeatures_get_combined_feature_weight(*args)

    def set_combined_feature_weight(*args):
        """
        set_combined_feature_weight(self, nw)

        set combined kernel weight

        Parameters:
        -----------

        nw:  new combined feature weight 
        """
        return _Features.DotFeatures_set_combined_feature_weight(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)

        get a copy of the feature matrix (in feature space)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  destination to store matrix in

        num_feat:  number of features (rows of matrix)

        num_vec:  number of vectors (columns of matrix) 
        """
        return _Features.DotFeatures_get_feature_matrix(*args)

DotFeatures_swigregister = _Features.DotFeatures_swigregister
DotFeatures_swigregister(DotFeatures)

def DotFeatures_dense_dot_range_helper(*args):
  """DotFeatures_dense_dot_range_helper(p) -> void"""
  return _Features.DotFeatures_dense_dot_range_helper(*args)

class StringBoolFeatures(Features):
    """
    Template class StringFeatures implements a list of strings.

    As this class is a template the underlying storage type is quite
    arbitrary and not limited to stracter strings, but could also be
    sequences of floating point numbers etc. Strings differ from matrices
    (cf. CSimpleFeatures) in a way that the dimensionality of the feature
    vectors (i.e. the strings) is not fixed; it may vary between strings.

    Most string kernels require StringFeatures but a number of them
    actually requires strings to have same length.

    When preprocessors are attached to string features they may shorten
    the string, but are not allowed to return strings longer than
    max_string_length, as some algorithms depend on this.

    Also note that string features cannot currently be computed on-the-
    fly.

    C++ includes: StringFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringBoolFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringBoolFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringBoolFeatures
        __init__(self, alpha) -> StringBoolFeatures
        __init__(self, p_features, alpha) -> StringBoolFeatures
        __init__(self, alpha) -> StringBoolFeatures
        __init__(self, orig) -> StringBoolFeatures
        __init__(self, fname, alpha=DNA) -> StringBoolFeatures
        __init__(self, fname) -> StringBoolFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringBoolFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringBoolFeatures
    __del__ = lambda self : None;
    def cleanup(*args):
        """
        cleanup(self)

        cleanup string features 
        """
        return _Features.StringBoolFeatures_cleanup(*args)

    def cleanup_feature_vector(*args):
        """
        cleanup_feature_vector(self, num)

        cleanup a single feature vector 
        """
        return _Features.StringBoolFeatures_cleanup_feature_vector(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> Alphabet

        get alphabet used in string features

        alphabet 
        """
        return _Features.StringBoolFeatures_get_alphabet(*args)

    def enable_on_the_fly_preprocessing(*args):
        """
        enable_on_the_fly_preprocessing(self)

        call this to preprocess string features upon get_feature_vector 
        """
        return _Features.StringBoolFeatures_enable_on_the_fly_preprocessing(*args)

    def disable_on_the_fly_preprocessing(*args):
        """
        disable_on_the_fly_preprocessing(self)

        call this to disable on the fly feature preprocessing on
        get_feature_vector. Useful when you manually apply preprocessors. 
        """
        return _Features.StringBoolFeatures_disable_on_the_fly_preprocessing(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, dst, num)
        get_feature_vector(self, num, len, dofree) -> bool

        get feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        len:  length is returned by reference

        dofree:  whether returned vector must be freed by caller via
        free_feature_vector

        feature vector for sample num 
        """
        return _Features.StringBoolFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.StringBoolFeatures_free_feature_vector(*args)

    def get_feature(*args):
        """
        get_feature(self, vec_num, feat_num) -> bool

        get feature

        Parameters:
        -----------

        vec_num:  which vector

        feat_num:  which feature

        feature 
        """
        return _Features.StringBoolFeatures_get_feature(*args)

    def get_vector_length(*args):
        """
        get_vector_length(self, vec_num) ->  int

        get vector length

        Parameters:
        -----------

        vec_num:  which vector

        length of vector 
        """
        return _Features.StringBoolFeatures_get_vector_length(*args)

    def get_max_vector_length(*args):
        """
        get_max_vector_length(self) ->  int

        get maximum vector length

        maximum vector/string length 
        """
        return _Features.StringBoolFeatures_get_max_vector_length(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) -> floatmax_t

        get number of symbols

        Note: floatmax_t sounds weird, but LONG is not long enough

        number of symbols 
        """
        return _Features.StringBoolFeatures_get_num_symbols(*args)

    def get_max_num_symbols(*args):
        """
        get_max_num_symbols(self) -> floatmax_t

        get maximum number of symbols

        Note: floatmax_t sounds weird, but int is not long enough (and
        there is no int128_t type)

        maximum number of symbols 
        """
        return _Features.StringBoolFeatures_get_max_num_symbols(*args)

    def get_original_num_symbols(*args):
        """
        get_original_num_symbols(self) -> floatmax_t

        number of symbols before higher order mapping

        original number of symbols 
        """
        return _Features.StringBoolFeatures_get_original_num_symbols(*args)

    def get_order(*args):
        """
        get_order(self) ->  int

        order used for higher order mapping

        order 
        """
        return _Features.StringBoolFeatures_get_order(*args)

    def get_masked_symbols(*args):
        """get_masked_symbols(self, symbol, mask) -> bool"""
        return _Features.StringBoolFeatures_get_masked_symbols(*args)

    def shift_offset(*args):
        """shift_offset(self, offset, amount) -> bool"""
        return _Features.StringBoolFeatures_shift_offset(*args)

    def shift_symbol(*args):
        """shift_symbol(self, symbol, amount) -> bool"""
        return _Features.StringBoolFeatures_shift_symbol(*args)

    def load_dna_file(*args):
        """
        load_dna_file(self, fname, remap_to_bin=True) -> bool
        load_dna_file(self, fname) -> bool

        load DNA features from file

        Parameters:
        -----------

        fname:  filename to load from

        remap_to_bin:  if remap_to_bin

        if loading was successful 
        """
        return _Features.StringBoolFeatures_load_dna_file(*args)

    def load_fasta_file(*args):
        """
        load_fasta_file(self, fname, ignore_invalid=False) -> bool
        load_fasta_file(self, fname) -> bool

        load fasta file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        if loading was successful 
        """
        return _Features.StringBoolFeatures_load_fasta_file(*args)

    def load_fastq_file(*args):
        """
        load_fastq_file(self, fname, ignore_invalid=False, bitremap_in_single_string=False) -> bool
        load_fastq_file(self, fname, ignore_invalid=False) -> bool
        load_fastq_file(self, fname) -> bool

        load fastq file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        bitremap_in_single_string:  if set to true, do binary embedding of
        symbols

        if loading was successful 
        """
        return _Features.StringBoolFeatures_load_fastq_file(*args)

    def load_from_directory(*args):
        """
        load_from_directory(self, dirname) -> bool

        load features from directory

        Parameters:
        -----------

        dirname:  directory name to load from

        if loading was successful 
        """
        return _Features.StringBoolFeatures_load_from_directory(*args)

    def set_features(*args):
        """
        set_features(self, p_features) -> bool

        set features

        Parameters:
        -----------

        p_features:  new features

        p_num_vectors:  number of vectors

        p_max_string_length:  maximum string length

        if setting was successful 
        """
        return _Features.StringBoolFeatures_set_features(*args)

    def copy_features(*args):
        """
        copy_features(self, num_str, max_str_len) -> shogun::T_STRING<(bool)>

        copy_features

        Parameters:
        -----------

        num_str:  number of strings (returned)

        max_str_len:  maximal string length (returned)

        string features 
        """
        return _Features.StringBoolFeatures_copy_features(*args)

    def get_features(*args):
        """
        get_features(self, num_str, max_str_len) -> shogun::T_STRING<(bool)>
        get_features(self, dst)

        get_features (swig compatible)

        Parameters:
        -----------

        dst:  string features (returned)

        num_str:  number of strings (returned) 
        """
        return _Features.StringBoolFeatures_get_features(*args)

    def load_compressed(*args):
        """
        load_compressed(self, src, decompress) -> bool

        load compressed features from file

        Parameters:
        -----------

        src:  filename to load from

        decompress:  whether to decompress on loading

        if loading was successful 
        """
        return _Features.StringBoolFeatures_load_compressed(*args)

    def save_compressed(*args):
        """
        save_compressed(self, dest, compression, level) -> bool

        save compressed features to file

        Parameters:
        -----------

        dest:  filename to save to

        compression:  compressor to use

        level:  compression level to use (1-9)

        if saving was successful 
        """
        return _Features.StringBoolFeatures_save_compressed(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.StringBoolFeatures_apply_preproc(*args)

    def obtain_by_sliding_window(*args):
        """
        obtain_by_sliding_window(self, window_size, step_size, skip=0) ->  int
        obtain_by_sliding_window(self, window_size, step_size) ->  int

        slides a window of size window_size over the current single string
        step_size is the amount by which the window is shifted. creates
        (string_len-window_size)/step_size many feature obj if skip is
        nonzero, skip the first 'skip' stracters of each string

        Parameters:
        -----------

        window_size:  window size

        step_size:  step size

        skip:  skip

        something inty 
        """
        return _Features.StringBoolFeatures_obtain_by_sliding_window(*args)

    def obtain_by_position_list(*args):
        """
        obtain_by_position_list(self, window_size, positions, skip=0) ->  int
        obtain_by_position_list(self, window_size, positions) ->  int

        extracts windows of size window_size from first string using the
        positions in list

        Parameters:
        -----------

        window_size:  window size

        positions:  positions

        skip:  skip

        something inty 
        """
        return _Features.StringBoolFeatures_obtain_by_position_list(*args)

    def obtain_from_char(*args):
        """
        obtain_from_char(self, sf, start, p_order, gap, rev) -> bool

        obtain string features from str features

        wrapper for template method

        Parameters:
        -----------

        sf:  string features

        start:  start

        p_order:  order

        gap:  gap

        rev:  reverse

        if obtaining was successful 
        """
        return _Features.StringBoolFeatures_obtain_from_char(*args)

    def have_same_length(*args):
        """
        have_same_length(self, len=-1) -> bool
        have_same_length(self) -> bool

        check if length of each vector in this feature object equals the given
        length.

        Parameters:
        -----------

        len:  vector length to check against

        if length of each vector in this feature object equals the given
        length. 
        """
        return _Features.StringBoolFeatures_have_same_length(*args)

    def embed_features(*args):
        """embed_features(self, p_order)"""
        return _Features.StringBoolFeatures_embed_features(*args)

    def compute_symbol_mask_table(*args):
        """compute_symbol_mask_table(self, max_val)"""
        return _Features.StringBoolFeatures_compute_symbol_mask_table(*args)

    def unembed_word(*args):
        """unembed_word(self, word, seq, len)"""
        return _Features.StringBoolFeatures_unembed_word(*args)

    def embed_word(*args):
        """embed_word(self, seq, len) -> bool"""
        return _Features.StringBoolFeatures_embed_word(*args)

    def determine_maximum_string_length(*args):
        """
        determine_maximum_string_length(self)

        determine new maximum string length 
        """
        return _Features.StringBoolFeatures_determine_maximum_string_length(*args)

    def get_zero_terminated_string_copy(*args):
        """get_zero_terminated_string_copy(str) -> bool"""
        return _Features.StringBoolFeatures_get_zero_terminated_string_copy(*args)

    if _newclass:get_zero_terminated_string_copy = staticmethod(get_zero_terminated_string_copy)
    __swig_getmethods__["get_zero_terminated_string_copy"] = lambda x: get_zero_terminated_string_copy
    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)
        set_feature_vector(self, num, string, len)

        set feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        string:  string with the feature vector's content

        len:  length of the string 
        """
        return _Features.StringBoolFeatures_set_feature_vector(*args)

StringBoolFeatures_swigregister = _Features.StringBoolFeatures_swigregister
StringBoolFeatures_swigregister(StringBoolFeatures)

def StringBoolFeatures_get_zero_terminated_string_copy(*args):
  """StringBoolFeatures_get_zero_terminated_string_copy(str) -> bool"""
  return _Features.StringBoolFeatures_get_zero_terminated_string_copy(*args)

class StringCharFeatures(Features):
    """
    Template class StringFeatures implements a list of strings.

    As this class is a template the underlying storage type is quite
    arbitrary and not limited to stracter strings, but could also be
    sequences of floating point numbers etc. Strings differ from matrices
    (cf. CSimpleFeatures) in a way that the dimensionality of the feature
    vectors (i.e. the strings) is not fixed; it may vary between strings.

    Most string kernels require StringFeatures but a number of them
    actually requires strings to have same length.

    When preprocessors are attached to string features they may shorten
    the string, but are not allowed to return strings longer than
    max_string_length, as some algorithms depend on this.

    Also note that string features cannot currently be computed on-the-
    fly.

    C++ includes: StringFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringCharFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringCharFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringCharFeatures
        __init__(self, alpha) -> StringCharFeatures
        __init__(self, p_features, alpha) -> StringCharFeatures
        __init__(self, alpha) -> StringCharFeatures
        __init__(self, orig) -> StringCharFeatures
        __init__(self, fname, alpha=DNA) -> StringCharFeatures
        __init__(self, fname) -> StringCharFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringCharFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringCharFeatures
    __del__ = lambda self : None;
    def cleanup(*args):
        """
        cleanup(self)

        cleanup string features 
        """
        return _Features.StringCharFeatures_cleanup(*args)

    def cleanup_feature_vector(*args):
        """
        cleanup_feature_vector(self, num)

        cleanup a single feature vector 
        """
        return _Features.StringCharFeatures_cleanup_feature_vector(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> Alphabet

        get alphabet used in string features

        alphabet 
        """
        return _Features.StringCharFeatures_get_alphabet(*args)

    def enable_on_the_fly_preprocessing(*args):
        """
        enable_on_the_fly_preprocessing(self)

        call this to preprocess string features upon get_feature_vector 
        """
        return _Features.StringCharFeatures_enable_on_the_fly_preprocessing(*args)

    def disable_on_the_fly_preprocessing(*args):
        """
        disable_on_the_fly_preprocessing(self)

        call this to disable on the fly feature preprocessing on
        get_feature_vector. Useful when you manually apply preprocessors. 
        """
        return _Features.StringCharFeatures_disable_on_the_fly_preprocessing(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, dst, num)
        get_feature_vector(self, num, len, dofree) -> str

        get feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        len:  length is returned by reference

        dofree:  whether returned vector must be freed by caller via
        free_feature_vector

        feature vector for sample num 
        """
        return _Features.StringCharFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.StringCharFeatures_free_feature_vector(*args)

    def get_feature(*args):
        """
        get_feature(self, vec_num, feat_num) -> str

        get feature

        Parameters:
        -----------

        vec_num:  which vector

        feat_num:  which feature

        feature 
        """
        return _Features.StringCharFeatures_get_feature(*args)

    def get_vector_length(*args):
        """
        get_vector_length(self, vec_num) ->  int

        get vector length

        Parameters:
        -----------

        vec_num:  which vector

        length of vector 
        """
        return _Features.StringCharFeatures_get_vector_length(*args)

    def get_max_vector_length(*args):
        """
        get_max_vector_length(self) ->  int

        get maximum vector length

        maximum vector/string length 
        """
        return _Features.StringCharFeatures_get_max_vector_length(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) -> floatmax_t

        get number of symbols

        Note: floatmax_t sounds weird, but LONG is not long enough

        number of symbols 
        """
        return _Features.StringCharFeatures_get_num_symbols(*args)

    def get_max_num_symbols(*args):
        """
        get_max_num_symbols(self) -> floatmax_t

        get maximum number of symbols

        Note: floatmax_t sounds weird, but int is not long enough (and
        there is no int128_t type)

        maximum number of symbols 
        """
        return _Features.StringCharFeatures_get_max_num_symbols(*args)

    def get_original_num_symbols(*args):
        """
        get_original_num_symbols(self) -> floatmax_t

        number of symbols before higher order mapping

        original number of symbols 
        """
        return _Features.StringCharFeatures_get_original_num_symbols(*args)

    def get_order(*args):
        """
        get_order(self) ->  int

        order used for higher order mapping

        order 
        """
        return _Features.StringCharFeatures_get_order(*args)

    def get_masked_symbols(*args):
        """get_masked_symbols(self, symbol, mask) -> str"""
        return _Features.StringCharFeatures_get_masked_symbols(*args)

    def shift_offset(*args):
        """shift_offset(self, offset, amount) -> str"""
        return _Features.StringCharFeatures_shift_offset(*args)

    def shift_symbol(*args):
        """shift_symbol(self, symbol, amount) -> str"""
        return _Features.StringCharFeatures_shift_symbol(*args)

    def load_dna_file(*args):
        """
        load_dna_file(self, fname, remap_to_bin=True) -> bool
        load_dna_file(self, fname) -> bool

        load DNA features from file

        Parameters:
        -----------

        fname:  filename to load from

        remap_to_bin:  if remap_to_bin

        if loading was successful 
        """
        return _Features.StringCharFeatures_load_dna_file(*args)

    def load_fasta_file(*args):
        """
        load_fasta_file(self, fname, ignore_invalid=False) -> bool
        load_fasta_file(self, fname) -> bool

        load fasta file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        if loading was successful 
        """
        return _Features.StringCharFeatures_load_fasta_file(*args)

    def load_fastq_file(*args):
        """
        load_fastq_file(self, fname, ignore_invalid=False, bitremap_in_single_string=False) -> bool
        load_fastq_file(self, fname, ignore_invalid=False) -> bool
        load_fastq_file(self, fname) -> bool

        load fastq file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        bitremap_in_single_string:  if set to true, do binary embedding of
        symbols

        if loading was successful 
        """
        return _Features.StringCharFeatures_load_fastq_file(*args)

    def load_from_directory(*args):
        """
        load_from_directory(self, dirname) -> bool

        load features from directory

        Parameters:
        -----------

        dirname:  directory name to load from

        if loading was successful 
        """
        return _Features.StringCharFeatures_load_from_directory(*args)

    def set_features(*args):
        """
        set_features(self, p_features) -> bool

        set features

        Parameters:
        -----------

        p_features:  new features

        p_num_vectors:  number of vectors

        p_max_string_length:  maximum string length

        if setting was successful 
        """
        return _Features.StringCharFeatures_set_features(*args)

    def copy_features(*args):
        """
        copy_features(self, num_str, max_str_len) -> shogun::T_STRING<(char)>

        copy_features

        Parameters:
        -----------

        num_str:  number of strings (returned)

        max_str_len:  maximal string length (returned)

        string features 
        """
        return _Features.StringCharFeatures_copy_features(*args)

    def get_features(*args):
        """
        get_features(self, num_str, max_str_len) -> shogun::T_STRING<(char)>
        get_features(self, dst)

        get_features (swig compatible)

        Parameters:
        -----------

        dst:  string features (returned)

        num_str:  number of strings (returned) 
        """
        return _Features.StringCharFeatures_get_features(*args)

    def load_compressed(*args):
        """
        load_compressed(self, src, decompress) -> bool

        load compressed features from file

        Parameters:
        -----------

        src:  filename to load from

        decompress:  whether to decompress on loading

        if loading was successful 
        """
        return _Features.StringCharFeatures_load_compressed(*args)

    def save_compressed(*args):
        """
        save_compressed(self, dest, compression, level) -> bool

        save compressed features to file

        Parameters:
        -----------

        dest:  filename to save to

        compression:  compressor to use

        level:  compression level to use (1-9)

        if saving was successful 
        """
        return _Features.StringCharFeatures_save_compressed(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.StringCharFeatures_apply_preproc(*args)

    def obtain_by_sliding_window(*args):
        """
        obtain_by_sliding_window(self, window_size, step_size, skip=0) ->  int
        obtain_by_sliding_window(self, window_size, step_size) ->  int

        slides a window of size window_size over the current single string
        step_size is the amount by which the window is shifted. creates
        (string_len-window_size)/step_size many feature obj if skip is
        nonzero, skip the first 'skip' stracters of each string

        Parameters:
        -----------

        window_size:  window size

        step_size:  step size

        skip:  skip

        something inty 
        """
        return _Features.StringCharFeatures_obtain_by_sliding_window(*args)

    def obtain_by_position_list(*args):
        """
        obtain_by_position_list(self, window_size, positions, skip=0) ->  int
        obtain_by_position_list(self, window_size, positions) ->  int

        extracts windows of size window_size from first string using the
        positions in list

        Parameters:
        -----------

        window_size:  window size

        positions:  positions

        skip:  skip

        something inty 
        """
        return _Features.StringCharFeatures_obtain_by_position_list(*args)

    def obtain_from_char(*args):
        """
        obtain_from_char(self, sf, start, p_order, gap, rev) -> bool

        obtain string features from str features

        wrapper for template method

        Parameters:
        -----------

        sf:  string features

        start:  start

        p_order:  order

        gap:  gap

        rev:  reverse

        if obtaining was successful 
        """
        return _Features.StringCharFeatures_obtain_from_char(*args)

    def have_same_length(*args):
        """
        have_same_length(self, len=-1) -> bool
        have_same_length(self) -> bool

        check if length of each vector in this feature object equals the given
        length.

        Parameters:
        -----------

        len:  vector length to check against

        if length of each vector in this feature object equals the given
        length. 
        """
        return _Features.StringCharFeatures_have_same_length(*args)

    def embed_features(*args):
        """embed_features(self, p_order)"""
        return _Features.StringCharFeatures_embed_features(*args)

    def compute_symbol_mask_table(*args):
        """compute_symbol_mask_table(self, max_val)"""
        return _Features.StringCharFeatures_compute_symbol_mask_table(*args)

    def unembed_word(*args):
        """unembed_word(self, word, seq, len)"""
        return _Features.StringCharFeatures_unembed_word(*args)

    def embed_word(*args):
        """embed_word(self, seq, len) -> str"""
        return _Features.StringCharFeatures_embed_word(*args)

    def determine_maximum_string_length(*args):
        """
        determine_maximum_string_length(self)

        determine new maximum string length 
        """
        return _Features.StringCharFeatures_determine_maximum_string_length(*args)

    def get_zero_terminated_string_copy(*args):
        """get_zero_terminated_string_copy(str) -> str"""
        return _Features.StringCharFeatures_get_zero_terminated_string_copy(*args)

    if _newclass:get_zero_terminated_string_copy = staticmethod(get_zero_terminated_string_copy)
    __swig_getmethods__["get_zero_terminated_string_copy"] = lambda x: get_zero_terminated_string_copy
    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)
        set_feature_vector(self, num, string, len)

        set feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        string:  string with the feature vector's content

        len:  length of the string 
        """
        return _Features.StringCharFeatures_set_feature_vector(*args)

StringCharFeatures_swigregister = _Features.StringCharFeatures_swigregister
StringCharFeatures_swigregister(StringCharFeatures)

def StringCharFeatures_get_zero_terminated_string_copy(*args):
  """StringCharFeatures_get_zero_terminated_string_copy(str) -> str"""
  return _Features.StringCharFeatures_get_zero_terminated_string_copy(*args)

class StringByteFeatures(Features):
    """
    Template class StringFeatures implements a list of strings.

    As this class is a template the underlying storage type is quite
    arbitrary and not limited to stracter strings, but could also be
    sequences of floating point numbers etc. Strings differ from matrices
    (cf. CSimpleFeatures) in a way that the dimensionality of the feature
    vectors (i.e. the strings) is not fixed; it may vary between strings.

    Most string kernels require StringFeatures but a number of them
    actually requires strings to have same length.

    When preprocessors are attached to string features they may shorten
    the string, but are not allowed to return strings longer than
    max_string_length, as some algorithms depend on this.

    Also note that string features cannot currently be computed on-the-
    fly.

    C++ includes: StringFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringByteFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringByteFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringByteFeatures
        __init__(self, alpha) -> StringByteFeatures
        __init__(self, p_features, alpha) -> StringByteFeatures
        __init__(self, alpha) -> StringByteFeatures
        __init__(self, orig) -> StringByteFeatures
        __init__(self, fname, alpha=DNA) -> StringByteFeatures
        __init__(self, fname) -> StringByteFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringByteFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringByteFeatures
    __del__ = lambda self : None;
    def cleanup(*args):
        """
        cleanup(self)

        cleanup string features 
        """
        return _Features.StringByteFeatures_cleanup(*args)

    def cleanup_feature_vector(*args):
        """
        cleanup_feature_vector(self, num)

        cleanup a single feature vector 
        """
        return _Features.StringByteFeatures_cleanup_feature_vector(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> Alphabet

        get alphabet used in string features

        alphabet 
        """
        return _Features.StringByteFeatures_get_alphabet(*args)

    def enable_on_the_fly_preprocessing(*args):
        """
        enable_on_the_fly_preprocessing(self)

        call this to preprocess string features upon get_feature_vector 
        """
        return _Features.StringByteFeatures_enable_on_the_fly_preprocessing(*args)

    def disable_on_the_fly_preprocessing(*args):
        """
        disable_on_the_fly_preprocessing(self)

        call this to disable on the fly feature preprocessing on
        get_feature_vector. Useful when you manually apply preprocessors. 
        """
        return _Features.StringByteFeatures_disable_on_the_fly_preprocessing(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, dst, num)
        get_feature_vector(self, num, len, dofree) -> unsigned str

        get feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        len:  length is returned by reference

        dofree:  whether returned vector must be freed by caller via
        free_feature_vector

        feature vector for sample num 
        """
        return _Features.StringByteFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.StringByteFeatures_free_feature_vector(*args)

    def get_feature(*args):
        """
        get_feature(self, vec_num, feat_num) -> unsigned str

        get feature

        Parameters:
        -----------

        vec_num:  which vector

        feat_num:  which feature

        feature 
        """
        return _Features.StringByteFeatures_get_feature(*args)

    def get_vector_length(*args):
        """
        get_vector_length(self, vec_num) ->  int

        get vector length

        Parameters:
        -----------

        vec_num:  which vector

        length of vector 
        """
        return _Features.StringByteFeatures_get_vector_length(*args)

    def get_max_vector_length(*args):
        """
        get_max_vector_length(self) ->  int

        get maximum vector length

        maximum vector/string length 
        """
        return _Features.StringByteFeatures_get_max_vector_length(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) -> floatmax_t

        get number of symbols

        Note: floatmax_t sounds weird, but LONG is not long enough

        number of symbols 
        """
        return _Features.StringByteFeatures_get_num_symbols(*args)

    def get_max_num_symbols(*args):
        """
        get_max_num_symbols(self) -> floatmax_t

        get maximum number of symbols

        Note: floatmax_t sounds weird, but int is not long enough (and
        there is no int128_t type)

        maximum number of symbols 
        """
        return _Features.StringByteFeatures_get_max_num_symbols(*args)

    def get_original_num_symbols(*args):
        """
        get_original_num_symbols(self) -> floatmax_t

        number of symbols before higher order mapping

        original number of symbols 
        """
        return _Features.StringByteFeatures_get_original_num_symbols(*args)

    def get_order(*args):
        """
        get_order(self) ->  int

        order used for higher order mapping

        order 
        """
        return _Features.StringByteFeatures_get_order(*args)

    def get_masked_symbols(*args):
        """get_masked_symbols(self, symbol, mask) -> unsigned str"""
        return _Features.StringByteFeatures_get_masked_symbols(*args)

    def shift_offset(*args):
        """shift_offset(self, offset, amount) -> unsigned str"""
        return _Features.StringByteFeatures_shift_offset(*args)

    def shift_symbol(*args):
        """shift_symbol(self, symbol, amount) -> unsigned str"""
        return _Features.StringByteFeatures_shift_symbol(*args)

    def load_dna_file(*args):
        """
        load_dna_file(self, fname, remap_to_bin=True) -> bool
        load_dna_file(self, fname) -> bool

        load DNA features from file

        Parameters:
        -----------

        fname:  filename to load from

        remap_to_bin:  if remap_to_bin

        if loading was successful 
        """
        return _Features.StringByteFeatures_load_dna_file(*args)

    def load_fasta_file(*args):
        """
        load_fasta_file(self, fname, ignore_invalid=False) -> bool
        load_fasta_file(self, fname) -> bool

        load fasta file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        if loading was successful 
        """
        return _Features.StringByteFeatures_load_fasta_file(*args)

    def load_fastq_file(*args):
        """
        load_fastq_file(self, fname, ignore_invalid=False, bitremap_in_single_string=False) -> bool
        load_fastq_file(self, fname, ignore_invalid=False) -> bool
        load_fastq_file(self, fname) -> bool

        load fastq file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        bitremap_in_single_string:  if set to true, do binary embedding of
        symbols

        if loading was successful 
        """
        return _Features.StringByteFeatures_load_fastq_file(*args)

    def load_from_directory(*args):
        """
        load_from_directory(self, dirname) -> bool

        load features from directory

        Parameters:
        -----------

        dirname:  directory name to load from

        if loading was successful 
        """
        return _Features.StringByteFeatures_load_from_directory(*args)

    def set_features(*args):
        """
        set_features(self, p_features) -> bool

        set features

        Parameters:
        -----------

        p_features:  new features

        p_num_vectors:  number of vectors

        p_max_string_length:  maximum string length

        if setting was successful 
        """
        return _Features.StringByteFeatures_set_features(*args)

    def copy_features(*args):
        """
        copy_features(self, num_str, max_str_len) -> shogun::T_STRING<(unsigned str)>

        copy_features

        Parameters:
        -----------

        num_str:  number of strings (returned)

        max_str_len:  maximal string length (returned)

        string features 
        """
        return _Features.StringByteFeatures_copy_features(*args)

    def get_features(*args):
        """
        get_features(self, num_str, max_str_len) -> shogun::T_STRING<(unsigned str)>
        get_features(self, dst)

        get_features (swig compatible)

        Parameters:
        -----------

        dst:  string features (returned)

        num_str:  number of strings (returned) 
        """
        return _Features.StringByteFeatures_get_features(*args)

    def load_compressed(*args):
        """
        load_compressed(self, src, decompress) -> bool

        load compressed features from file

        Parameters:
        -----------

        src:  filename to load from

        decompress:  whether to decompress on loading

        if loading was successful 
        """
        return _Features.StringByteFeatures_load_compressed(*args)

    def save_compressed(*args):
        """
        save_compressed(self, dest, compression, level) -> bool

        save compressed features to file

        Parameters:
        -----------

        dest:  filename to save to

        compression:  compressor to use

        level:  compression level to use (1-9)

        if saving was successful 
        """
        return _Features.StringByteFeatures_save_compressed(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.StringByteFeatures_apply_preproc(*args)

    def obtain_by_sliding_window(*args):
        """
        obtain_by_sliding_window(self, window_size, step_size, skip=0) ->  int
        obtain_by_sliding_window(self, window_size, step_size) ->  int

        slides a window of size window_size over the current single string
        step_size is the amount by which the window is shifted. creates
        (string_len-window_size)/step_size many feature obj if skip is
        nonzero, skip the first 'skip' stracters of each string

        Parameters:
        -----------

        window_size:  window size

        step_size:  step size

        skip:  skip

        something inty 
        """
        return _Features.StringByteFeatures_obtain_by_sliding_window(*args)

    def obtain_by_position_list(*args):
        """
        obtain_by_position_list(self, window_size, positions, skip=0) ->  int
        obtain_by_position_list(self, window_size, positions) ->  int

        extracts windows of size window_size from first string using the
        positions in list

        Parameters:
        -----------

        window_size:  window size

        positions:  positions

        skip:  skip

        something inty 
        """
        return _Features.StringByteFeatures_obtain_by_position_list(*args)

    def obtain_from_char(*args):
        """
        obtain_from_char(self, sf, start, p_order, gap, rev) -> bool

        obtain string features from str features

        wrapper for template method

        Parameters:
        -----------

        sf:  string features

        start:  start

        p_order:  order

        gap:  gap

        rev:  reverse

        if obtaining was successful 
        """
        return _Features.StringByteFeatures_obtain_from_char(*args)

    def have_same_length(*args):
        """
        have_same_length(self, len=-1) -> bool
        have_same_length(self) -> bool

        check if length of each vector in this feature object equals the given
        length.

        Parameters:
        -----------

        len:  vector length to check against

        if length of each vector in this feature object equals the given
        length. 
        """
        return _Features.StringByteFeatures_have_same_length(*args)

    def embed_features(*args):
        """embed_features(self, p_order)"""
        return _Features.StringByteFeatures_embed_features(*args)

    def compute_symbol_mask_table(*args):
        """compute_symbol_mask_table(self, max_val)"""
        return _Features.StringByteFeatures_compute_symbol_mask_table(*args)

    def unembed_word(*args):
        """unembed_word(self, word, seq, len)"""
        return _Features.StringByteFeatures_unembed_word(*args)

    def embed_word(*args):
        """embed_word(self, seq, len) -> unsigned str"""
        return _Features.StringByteFeatures_embed_word(*args)

    def determine_maximum_string_length(*args):
        """
        determine_maximum_string_length(self)

        determine new maximum string length 
        """
        return _Features.StringByteFeatures_determine_maximum_string_length(*args)

    def get_zero_terminated_string_copy(*args):
        """get_zero_terminated_string_copy(str) -> unsigned str"""
        return _Features.StringByteFeatures_get_zero_terminated_string_copy(*args)

    if _newclass:get_zero_terminated_string_copy = staticmethod(get_zero_terminated_string_copy)
    __swig_getmethods__["get_zero_terminated_string_copy"] = lambda x: get_zero_terminated_string_copy
    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)
        set_feature_vector(self, num, string, len)

        set feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        string:  string with the feature vector's content

        len:  length of the string 
        """
        return _Features.StringByteFeatures_set_feature_vector(*args)

StringByteFeatures_swigregister = _Features.StringByteFeatures_swigregister
StringByteFeatures_swigregister(StringByteFeatures)

def StringByteFeatures_get_zero_terminated_string_copy(*args):
  """StringByteFeatures_get_zero_terminated_string_copy(str) -> unsigned str"""
  return _Features.StringByteFeatures_get_zero_terminated_string_copy(*args)

class StringShortFeatures(Features):
    """
    Template class StringFeatures implements a list of strings.

    As this class is a template the underlying storage type is quite
    arbitrary and not limited to stracter strings, but could also be
    sequences of floating point numbers etc. Strings differ from matrices
    (cf. CSimpleFeatures) in a way that the dimensionality of the feature
    vectors (i.e. the strings) is not fixed; it may vary between strings.

    Most string kernels require StringFeatures but a number of them
    actually requires strings to have same length.

    When preprocessors are attached to string features they may shorten
    the string, but are not allowed to return strings longer than
    max_string_length, as some algorithms depend on this.

    Also note that string features cannot currently be computed on-the-
    fly.

    C++ includes: StringFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringShortFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringShortFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringShortFeatures
        __init__(self, alpha) -> StringShortFeatures
        __init__(self, p_features, alpha) -> StringShortFeatures
        __init__(self, alpha) -> StringShortFeatures
        __init__(self, orig) -> StringShortFeatures
        __init__(self, fname, alpha=DNA) -> StringShortFeatures
        __init__(self, fname) -> StringShortFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringShortFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringShortFeatures
    __del__ = lambda self : None;
    def cleanup(*args):
        """
        cleanup(self)

        cleanup string features 
        """
        return _Features.StringShortFeatures_cleanup(*args)

    def cleanup_feature_vector(*args):
        """
        cleanup_feature_vector(self, num)

        cleanup a single feature vector 
        """
        return _Features.StringShortFeatures_cleanup_feature_vector(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> Alphabet

        get alphabet used in string features

        alphabet 
        """
        return _Features.StringShortFeatures_get_alphabet(*args)

    def enable_on_the_fly_preprocessing(*args):
        """
        enable_on_the_fly_preprocessing(self)

        call this to preprocess string features upon get_feature_vector 
        """
        return _Features.StringShortFeatures_enable_on_the_fly_preprocessing(*args)

    def disable_on_the_fly_preprocessing(*args):
        """
        disable_on_the_fly_preprocessing(self)

        call this to disable on the fly feature preprocessing on
        get_feature_vector. Useful when you manually apply preprocessors. 
        """
        return _Features.StringShortFeatures_disable_on_the_fly_preprocessing(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, dst, num)
        get_feature_vector(self, num, len, dofree) -> short

        get feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        len:  length is returned by reference

        dofree:  whether returned vector must be freed by caller via
        free_feature_vector

        feature vector for sample num 
        """
        return _Features.StringShortFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.StringShortFeatures_free_feature_vector(*args)

    def get_feature(*args):
        """
        get_feature(self, vec_num, feat_num) -> short

        get feature

        Parameters:
        -----------

        vec_num:  which vector

        feat_num:  which feature

        feature 
        """
        return _Features.StringShortFeatures_get_feature(*args)

    def get_vector_length(*args):
        """
        get_vector_length(self, vec_num) ->  int

        get vector length

        Parameters:
        -----------

        vec_num:  which vector

        length of vector 
        """
        return _Features.StringShortFeatures_get_vector_length(*args)

    def get_max_vector_length(*args):
        """
        get_max_vector_length(self) ->  int

        get maximum vector length

        maximum vector/string length 
        """
        return _Features.StringShortFeatures_get_max_vector_length(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) -> floatmax_t

        get number of symbols

        Note: floatmax_t sounds weird, but LONG is not long enough

        number of symbols 
        """
        return _Features.StringShortFeatures_get_num_symbols(*args)

    def get_max_num_symbols(*args):
        """
        get_max_num_symbols(self) -> floatmax_t

        get maximum number of symbols

        Note: floatmax_t sounds weird, but int is not long enough (and
        there is no int128_t type)

        maximum number of symbols 
        """
        return _Features.StringShortFeatures_get_max_num_symbols(*args)

    def get_original_num_symbols(*args):
        """
        get_original_num_symbols(self) -> floatmax_t

        number of symbols before higher order mapping

        original number of symbols 
        """
        return _Features.StringShortFeatures_get_original_num_symbols(*args)

    def get_order(*args):
        """
        get_order(self) ->  int

        order used for higher order mapping

        order 
        """
        return _Features.StringShortFeatures_get_order(*args)

    def get_masked_symbols(*args):
        """get_masked_symbols(self, symbol, mask) -> short"""
        return _Features.StringShortFeatures_get_masked_symbols(*args)

    def shift_offset(*args):
        """shift_offset(self, offset, amount) -> short"""
        return _Features.StringShortFeatures_shift_offset(*args)

    def shift_symbol(*args):
        """shift_symbol(self, symbol, amount) -> short"""
        return _Features.StringShortFeatures_shift_symbol(*args)

    def load_dna_file(*args):
        """
        load_dna_file(self, fname, remap_to_bin=True) -> bool
        load_dna_file(self, fname) -> bool

        load DNA features from file

        Parameters:
        -----------

        fname:  filename to load from

        remap_to_bin:  if remap_to_bin

        if loading was successful 
        """
        return _Features.StringShortFeatures_load_dna_file(*args)

    def load_fasta_file(*args):
        """
        load_fasta_file(self, fname, ignore_invalid=False) -> bool
        load_fasta_file(self, fname) -> bool

        load fasta file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        if loading was successful 
        """
        return _Features.StringShortFeatures_load_fasta_file(*args)

    def load_fastq_file(*args):
        """
        load_fastq_file(self, fname, ignore_invalid=False, bitremap_in_single_string=False) -> bool
        load_fastq_file(self, fname, ignore_invalid=False) -> bool
        load_fastq_file(self, fname) -> bool

        load fastq file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        bitremap_in_single_string:  if set to true, do binary embedding of
        symbols

        if loading was successful 
        """
        return _Features.StringShortFeatures_load_fastq_file(*args)

    def load_from_directory(*args):
        """
        load_from_directory(self, dirname) -> bool

        load features from directory

        Parameters:
        -----------

        dirname:  directory name to load from

        if loading was successful 
        """
        return _Features.StringShortFeatures_load_from_directory(*args)

    def set_features(*args):
        """
        set_features(self, p_features) -> bool

        set features

        Parameters:
        -----------

        p_features:  new features

        p_num_vectors:  number of vectors

        p_max_string_length:  maximum string length

        if setting was successful 
        """
        return _Features.StringShortFeatures_set_features(*args)

    def copy_features(*args):
        """
        copy_features(self, num_str, max_str_len) -> shogun::T_STRING<(short)>

        copy_features

        Parameters:
        -----------

        num_str:  number of strings (returned)

        max_str_len:  maximal string length (returned)

        string features 
        """
        return _Features.StringShortFeatures_copy_features(*args)

    def get_features(*args):
        """
        get_features(self, num_str, max_str_len) -> shogun::T_STRING<(short)>
        get_features(self, dst)

        get_features (swig compatible)

        Parameters:
        -----------

        dst:  string features (returned)

        num_str:  number of strings (returned) 
        """
        return _Features.StringShortFeatures_get_features(*args)

    def load_compressed(*args):
        """
        load_compressed(self, src, decompress) -> bool

        load compressed features from file

        Parameters:
        -----------

        src:  filename to load from

        decompress:  whether to decompress on loading

        if loading was successful 
        """
        return _Features.StringShortFeatures_load_compressed(*args)

    def save_compressed(*args):
        """
        save_compressed(self, dest, compression, level) -> bool

        save compressed features to file

        Parameters:
        -----------

        dest:  filename to save to

        compression:  compressor to use

        level:  compression level to use (1-9)

        if saving was successful 
        """
        return _Features.StringShortFeatures_save_compressed(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.StringShortFeatures_apply_preproc(*args)

    def obtain_by_sliding_window(*args):
        """
        obtain_by_sliding_window(self, window_size, step_size, skip=0) ->  int
        obtain_by_sliding_window(self, window_size, step_size) ->  int

        slides a window of size window_size over the current single string
        step_size is the amount by which the window is shifted. creates
        (string_len-window_size)/step_size many feature obj if skip is
        nonzero, skip the first 'skip' stracters of each string

        Parameters:
        -----------

        window_size:  window size

        step_size:  step size

        skip:  skip

        something inty 
        """
        return _Features.StringShortFeatures_obtain_by_sliding_window(*args)

    def obtain_by_position_list(*args):
        """
        obtain_by_position_list(self, window_size, positions, skip=0) ->  int
        obtain_by_position_list(self, window_size, positions) ->  int

        extracts windows of size window_size from first string using the
        positions in list

        Parameters:
        -----------

        window_size:  window size

        positions:  positions

        skip:  skip

        something inty 
        """
        return _Features.StringShortFeatures_obtain_by_position_list(*args)

    def obtain_from_char(*args):
        """
        obtain_from_char(self, sf, start, p_order, gap, rev) -> bool

        obtain string features from str features

        wrapper for template method

        Parameters:
        -----------

        sf:  string features

        start:  start

        p_order:  order

        gap:  gap

        rev:  reverse

        if obtaining was successful 
        """
        return _Features.StringShortFeatures_obtain_from_char(*args)

    def have_same_length(*args):
        """
        have_same_length(self, len=-1) -> bool
        have_same_length(self) -> bool

        check if length of each vector in this feature object equals the given
        length.

        Parameters:
        -----------

        len:  vector length to check against

        if length of each vector in this feature object equals the given
        length. 
        """
        return _Features.StringShortFeatures_have_same_length(*args)

    def embed_features(*args):
        """embed_features(self, p_order)"""
        return _Features.StringShortFeatures_embed_features(*args)

    def compute_symbol_mask_table(*args):
        """compute_symbol_mask_table(self, max_val)"""
        return _Features.StringShortFeatures_compute_symbol_mask_table(*args)

    def unembed_word(*args):
        """unembed_word(self, word, seq, len)"""
        return _Features.StringShortFeatures_unembed_word(*args)

    def embed_word(*args):
        """embed_word(self, seq, len) -> short"""
        return _Features.StringShortFeatures_embed_word(*args)

    def determine_maximum_string_length(*args):
        """
        determine_maximum_string_length(self)

        determine new maximum string length 
        """
        return _Features.StringShortFeatures_determine_maximum_string_length(*args)

    def get_zero_terminated_string_copy(*args):
        """get_zero_terminated_string_copy(str) -> short"""
        return _Features.StringShortFeatures_get_zero_terminated_string_copy(*args)

    if _newclass:get_zero_terminated_string_copy = staticmethod(get_zero_terminated_string_copy)
    __swig_getmethods__["get_zero_terminated_string_copy"] = lambda x: get_zero_terminated_string_copy
    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)
        set_feature_vector(self, num, string, len)

        set feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        string:  string with the feature vector's content

        len:  length of the string 
        """
        return _Features.StringShortFeatures_set_feature_vector(*args)

StringShortFeatures_swigregister = _Features.StringShortFeatures_swigregister
StringShortFeatures_swigregister(StringShortFeatures)

def StringShortFeatures_get_zero_terminated_string_copy(*args):
  """StringShortFeatures_get_zero_terminated_string_copy(str) -> short"""
  return _Features.StringShortFeatures_get_zero_terminated_string_copy(*args)

class StringWordFeatures(Features):
    """
    Template class StringFeatures implements a list of strings.

    As this class is a template the underlying storage type is quite
    arbitrary and not limited to stracter strings, but could also be
    sequences of floating point numbers etc. Strings differ from matrices
    (cf. CSimpleFeatures) in a way that the dimensionality of the feature
    vectors (i.e. the strings) is not fixed; it may vary between strings.

    Most string kernels require StringFeatures but a number of them
    actually requires strings to have same length.

    When preprocessors are attached to string features they may shorten
    the string, but are not allowed to return strings longer than
    max_string_length, as some algorithms depend on this.

    Also note that string features cannot currently be computed on-the-
    fly.

    C++ includes: StringFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringWordFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringWordFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringWordFeatures
        __init__(self, alpha) -> StringWordFeatures
        __init__(self, p_features, alpha) -> StringWordFeatures
        __init__(self, alpha) -> StringWordFeatures
        __init__(self, orig) -> StringWordFeatures
        __init__(self, fname, alpha=DNA) -> StringWordFeatures
        __init__(self, fname) -> StringWordFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringWordFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringWordFeatures
    __del__ = lambda self : None;
    def cleanup(*args):
        """
        cleanup(self)

        cleanup string features 
        """
        return _Features.StringWordFeatures_cleanup(*args)

    def cleanup_feature_vector(*args):
        """
        cleanup_feature_vector(self, num)

        cleanup a single feature vector 
        """
        return _Features.StringWordFeatures_cleanup_feature_vector(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> Alphabet

        get alphabet used in string features

        alphabet 
        """
        return _Features.StringWordFeatures_get_alphabet(*args)

    def enable_on_the_fly_preprocessing(*args):
        """
        enable_on_the_fly_preprocessing(self)

        call this to preprocess string features upon get_feature_vector 
        """
        return _Features.StringWordFeatures_enable_on_the_fly_preprocessing(*args)

    def disable_on_the_fly_preprocessing(*args):
        """
        disable_on_the_fly_preprocessing(self)

        call this to disable on the fly feature preprocessing on
        get_feature_vector. Useful when you manually apply preprocessors. 
        """
        return _Features.StringWordFeatures_disable_on_the_fly_preprocessing(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, dst, num)
        get_feature_vector(self, num, len, dofree) -> unsigned short

        get feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        len:  length is returned by reference

        dofree:  whether returned vector must be freed by caller via
        free_feature_vector

        feature vector for sample num 
        """
        return _Features.StringWordFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.StringWordFeatures_free_feature_vector(*args)

    def get_feature(*args):
        """
        get_feature(self, vec_num, feat_num) -> unsigned short

        get feature

        Parameters:
        -----------

        vec_num:  which vector

        feat_num:  which feature

        feature 
        """
        return _Features.StringWordFeatures_get_feature(*args)

    def get_vector_length(*args):
        """
        get_vector_length(self, vec_num) ->  int

        get vector length

        Parameters:
        -----------

        vec_num:  which vector

        length of vector 
        """
        return _Features.StringWordFeatures_get_vector_length(*args)

    def get_max_vector_length(*args):
        """
        get_max_vector_length(self) ->  int

        get maximum vector length

        maximum vector/string length 
        """
        return _Features.StringWordFeatures_get_max_vector_length(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) -> floatmax_t

        get number of symbols

        Note: floatmax_t sounds weird, but LONG is not long enough

        number of symbols 
        """
        return _Features.StringWordFeatures_get_num_symbols(*args)

    def get_max_num_symbols(*args):
        """
        get_max_num_symbols(self) -> floatmax_t

        get maximum number of symbols

        Note: floatmax_t sounds weird, but int is not long enough (and
        there is no int128_t type)

        maximum number of symbols 
        """
        return _Features.StringWordFeatures_get_max_num_symbols(*args)

    def get_original_num_symbols(*args):
        """
        get_original_num_symbols(self) -> floatmax_t

        number of symbols before higher order mapping

        original number of symbols 
        """
        return _Features.StringWordFeatures_get_original_num_symbols(*args)

    def get_order(*args):
        """
        get_order(self) ->  int

        order used for higher order mapping

        order 
        """
        return _Features.StringWordFeatures_get_order(*args)

    def get_masked_symbols(*args):
        """get_masked_symbols(self, symbol, mask) -> unsigned short"""
        return _Features.StringWordFeatures_get_masked_symbols(*args)

    def shift_offset(*args):
        """shift_offset(self, offset, amount) -> unsigned short"""
        return _Features.StringWordFeatures_shift_offset(*args)

    def shift_symbol(*args):
        """shift_symbol(self, symbol, amount) -> unsigned short"""
        return _Features.StringWordFeatures_shift_symbol(*args)

    def load_dna_file(*args):
        """
        load_dna_file(self, fname, remap_to_bin=True) -> bool
        load_dna_file(self, fname) -> bool

        load DNA features from file

        Parameters:
        -----------

        fname:  filename to load from

        remap_to_bin:  if remap_to_bin

        if loading was successful 
        """
        return _Features.StringWordFeatures_load_dna_file(*args)

    def load_fasta_file(*args):
        """
        load_fasta_file(self, fname, ignore_invalid=False) -> bool
        load_fasta_file(self, fname) -> bool

        load fasta file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        if loading was successful 
        """
        return _Features.StringWordFeatures_load_fasta_file(*args)

    def load_fastq_file(*args):
        """
        load_fastq_file(self, fname, ignore_invalid=False, bitremap_in_single_string=False) -> bool
        load_fastq_file(self, fname, ignore_invalid=False) -> bool
        load_fastq_file(self, fname) -> bool

        load fastq file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        bitremap_in_single_string:  if set to true, do binary embedding of
        symbols

        if loading was successful 
        """
        return _Features.StringWordFeatures_load_fastq_file(*args)

    def load_from_directory(*args):
        """
        load_from_directory(self, dirname) -> bool

        load features from directory

        Parameters:
        -----------

        dirname:  directory name to load from

        if loading was successful 
        """
        return _Features.StringWordFeatures_load_from_directory(*args)

    def set_features(*args):
        """
        set_features(self, p_features) -> bool

        set features

        Parameters:
        -----------

        p_features:  new features

        p_num_vectors:  number of vectors

        p_max_string_length:  maximum string length

        if setting was successful 
        """
        return _Features.StringWordFeatures_set_features(*args)

    def copy_features(*args):
        """
        copy_features(self, num_str, max_str_len) -> shogun::T_STRING<(unsigned short)>

        copy_features

        Parameters:
        -----------

        num_str:  number of strings (returned)

        max_str_len:  maximal string length (returned)

        string features 
        """
        return _Features.StringWordFeatures_copy_features(*args)

    def get_features(*args):
        """
        get_features(self, num_str, max_str_len) -> shogun::T_STRING<(unsigned short)>
        get_features(self, dst)

        get_features (swig compatible)

        Parameters:
        -----------

        dst:  string features (returned)

        num_str:  number of strings (returned) 
        """
        return _Features.StringWordFeatures_get_features(*args)

    def load_compressed(*args):
        """
        load_compressed(self, src, decompress) -> bool

        load compressed features from file

        Parameters:
        -----------

        src:  filename to load from

        decompress:  whether to decompress on loading

        if loading was successful 
        """
        return _Features.StringWordFeatures_load_compressed(*args)

    def save_compressed(*args):
        """
        save_compressed(self, dest, compression, level) -> bool

        save compressed features to file

        Parameters:
        -----------

        dest:  filename to save to

        compression:  compressor to use

        level:  compression level to use (1-9)

        if saving was successful 
        """
        return _Features.StringWordFeatures_save_compressed(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.StringWordFeatures_apply_preproc(*args)

    def obtain_by_sliding_window(*args):
        """
        obtain_by_sliding_window(self, window_size, step_size, skip=0) ->  int
        obtain_by_sliding_window(self, window_size, step_size) ->  int

        slides a window of size window_size over the current single string
        step_size is the amount by which the window is shifted. creates
        (string_len-window_size)/step_size many feature obj if skip is
        nonzero, skip the first 'skip' stracters of each string

        Parameters:
        -----------

        window_size:  window size

        step_size:  step size

        skip:  skip

        something inty 
        """
        return _Features.StringWordFeatures_obtain_by_sliding_window(*args)

    def obtain_by_position_list(*args):
        """
        obtain_by_position_list(self, window_size, positions, skip=0) ->  int
        obtain_by_position_list(self, window_size, positions) ->  int

        extracts windows of size window_size from first string using the
        positions in list

        Parameters:
        -----------

        window_size:  window size

        positions:  positions

        skip:  skip

        something inty 
        """
        return _Features.StringWordFeatures_obtain_by_position_list(*args)

    def obtain_from_char(*args):
        """
        obtain_from_char(self, sf, start, p_order, gap, rev) -> bool

        obtain string features from str features

        wrapper for template method

        Parameters:
        -----------

        sf:  string features

        start:  start

        p_order:  order

        gap:  gap

        rev:  reverse

        if obtaining was successful 
        """
        return _Features.StringWordFeatures_obtain_from_char(*args)

    def have_same_length(*args):
        """
        have_same_length(self, len=-1) -> bool
        have_same_length(self) -> bool

        check if length of each vector in this feature object equals the given
        length.

        Parameters:
        -----------

        len:  vector length to check against

        if length of each vector in this feature object equals the given
        length. 
        """
        return _Features.StringWordFeatures_have_same_length(*args)

    def embed_features(*args):
        """embed_features(self, p_order)"""
        return _Features.StringWordFeatures_embed_features(*args)

    def compute_symbol_mask_table(*args):
        """compute_symbol_mask_table(self, max_val)"""
        return _Features.StringWordFeatures_compute_symbol_mask_table(*args)

    def unembed_word(*args):
        """unembed_word(self, word, seq, len)"""
        return _Features.StringWordFeatures_unembed_word(*args)

    def embed_word(*args):
        """embed_word(self, seq, len) -> unsigned short"""
        return _Features.StringWordFeatures_embed_word(*args)

    def determine_maximum_string_length(*args):
        """
        determine_maximum_string_length(self)

        determine new maximum string length 
        """
        return _Features.StringWordFeatures_determine_maximum_string_length(*args)

    def get_zero_terminated_string_copy(*args):
        """get_zero_terminated_string_copy(str) -> unsigned short"""
        return _Features.StringWordFeatures_get_zero_terminated_string_copy(*args)

    if _newclass:get_zero_terminated_string_copy = staticmethod(get_zero_terminated_string_copy)
    __swig_getmethods__["get_zero_terminated_string_copy"] = lambda x: get_zero_terminated_string_copy
    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)
        set_feature_vector(self, num, string, len)

        set feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        string:  string with the feature vector's content

        len:  length of the string 
        """
        return _Features.StringWordFeatures_set_feature_vector(*args)

StringWordFeatures_swigregister = _Features.StringWordFeatures_swigregister
StringWordFeatures_swigregister(StringWordFeatures)

def StringWordFeatures_get_zero_terminated_string_copy(*args):
  """StringWordFeatures_get_zero_terminated_string_copy(str) -> unsigned short"""
  return _Features.StringWordFeatures_get_zero_terminated_string_copy(*args)

class StringIntFeatures(Features):
    """
    Template class StringFeatures implements a list of strings.

    As this class is a template the underlying storage type is quite
    arbitrary and not limited to stracter strings, but could also be
    sequences of floating point numbers etc. Strings differ from matrices
    (cf. CSimpleFeatures) in a way that the dimensionality of the feature
    vectors (i.e. the strings) is not fixed; it may vary between strings.

    Most string kernels require StringFeatures but a number of them
    actually requires strings to have same length.

    When preprocessors are attached to string features they may shorten
    the string, but are not allowed to return strings longer than
    max_string_length, as some algorithms depend on this.

    Also note that string features cannot currently be computed on-the-
    fly.

    C++ includes: StringFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringIntFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringIntFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringIntFeatures
        __init__(self, alpha) -> StringIntFeatures
        __init__(self, p_features, alpha) -> StringIntFeatures
        __init__(self, alpha) -> StringIntFeatures
        __init__(self, orig) -> StringIntFeatures
        __init__(self, fname, alpha=DNA) -> StringIntFeatures
        __init__(self, fname) -> StringIntFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringIntFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringIntFeatures
    __del__ = lambda self : None;
    def cleanup(*args):
        """
        cleanup(self)

        cleanup string features 
        """
        return _Features.StringIntFeatures_cleanup(*args)

    def cleanup_feature_vector(*args):
        """
        cleanup_feature_vector(self, num)

        cleanup a single feature vector 
        """
        return _Features.StringIntFeatures_cleanup_feature_vector(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> Alphabet

        get alphabet used in string features

        alphabet 
        """
        return _Features.StringIntFeatures_get_alphabet(*args)

    def enable_on_the_fly_preprocessing(*args):
        """
        enable_on_the_fly_preprocessing(self)

        call this to preprocess string features upon get_feature_vector 
        """
        return _Features.StringIntFeatures_enable_on_the_fly_preprocessing(*args)

    def disable_on_the_fly_preprocessing(*args):
        """
        disable_on_the_fly_preprocessing(self)

        call this to disable on the fly feature preprocessing on
        get_feature_vector. Useful when you manually apply preprocessors. 
        """
        return _Features.StringIntFeatures_disable_on_the_fly_preprocessing(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, dst, num)
        get_feature_vector(self, num, len, dofree) -> int

        get feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        len:  length is returned by reference

        dofree:  whether returned vector must be freed by caller via
        free_feature_vector

        feature vector for sample num 
        """
        return _Features.StringIntFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.StringIntFeatures_free_feature_vector(*args)

    def get_feature(*args):
        """
        get_feature(self, vec_num, feat_num) -> int

        get feature

        Parameters:
        -----------

        vec_num:  which vector

        feat_num:  which feature

        feature 
        """
        return _Features.StringIntFeatures_get_feature(*args)

    def get_vector_length(*args):
        """
        get_vector_length(self, vec_num) ->  int

        get vector length

        Parameters:
        -----------

        vec_num:  which vector

        length of vector 
        """
        return _Features.StringIntFeatures_get_vector_length(*args)

    def get_max_vector_length(*args):
        """
        get_max_vector_length(self) ->  int

        get maximum vector length

        maximum vector/string length 
        """
        return _Features.StringIntFeatures_get_max_vector_length(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) -> floatmax_t

        get number of symbols

        Note: floatmax_t sounds weird, but LONG is not long enough

        number of symbols 
        """
        return _Features.StringIntFeatures_get_num_symbols(*args)

    def get_max_num_symbols(*args):
        """
        get_max_num_symbols(self) -> floatmax_t

        get maximum number of symbols

        Note: floatmax_t sounds weird, but int is not long enough (and
        there is no int128_t type)

        maximum number of symbols 
        """
        return _Features.StringIntFeatures_get_max_num_symbols(*args)

    def get_original_num_symbols(*args):
        """
        get_original_num_symbols(self) -> floatmax_t

        number of symbols before higher order mapping

        original number of symbols 
        """
        return _Features.StringIntFeatures_get_original_num_symbols(*args)

    def get_order(*args):
        """
        get_order(self) ->  int

        order used for higher order mapping

        order 
        """
        return _Features.StringIntFeatures_get_order(*args)

    def get_masked_symbols(*args):
        """get_masked_symbols(self, symbol, mask) -> int"""
        return _Features.StringIntFeatures_get_masked_symbols(*args)

    def shift_offset(*args):
        """shift_offset(self, offset, amount) -> int"""
        return _Features.StringIntFeatures_shift_offset(*args)

    def shift_symbol(*args):
        """shift_symbol(self, symbol, amount) -> int"""
        return _Features.StringIntFeatures_shift_symbol(*args)

    def load_dna_file(*args):
        """
        load_dna_file(self, fname, remap_to_bin=True) -> bool
        load_dna_file(self, fname) -> bool

        load DNA features from file

        Parameters:
        -----------

        fname:  filename to load from

        remap_to_bin:  if remap_to_bin

        if loading was successful 
        """
        return _Features.StringIntFeatures_load_dna_file(*args)

    def load_fasta_file(*args):
        """
        load_fasta_file(self, fname, ignore_invalid=False) -> bool
        load_fasta_file(self, fname) -> bool

        load fasta file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        if loading was successful 
        """
        return _Features.StringIntFeatures_load_fasta_file(*args)

    def load_fastq_file(*args):
        """
        load_fastq_file(self, fname, ignore_invalid=False, bitremap_in_single_string=False) -> bool
        load_fastq_file(self, fname, ignore_invalid=False) -> bool
        load_fastq_file(self, fname) -> bool

        load fastq file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        bitremap_in_single_string:  if set to true, do binary embedding of
        symbols

        if loading was successful 
        """
        return _Features.StringIntFeatures_load_fastq_file(*args)

    def load_from_directory(*args):
        """
        load_from_directory(self, dirname) -> bool

        load features from directory

        Parameters:
        -----------

        dirname:  directory name to load from

        if loading was successful 
        """
        return _Features.StringIntFeatures_load_from_directory(*args)

    def set_features(*args):
        """
        set_features(self, p_features) -> bool

        set features

        Parameters:
        -----------

        p_features:  new features

        p_num_vectors:  number of vectors

        p_max_string_length:  maximum string length

        if setting was successful 
        """
        return _Features.StringIntFeatures_set_features(*args)

    def copy_features(*args):
        """
        copy_features(self, num_str, max_str_len) -> shogun::T_STRING<(int)>

        copy_features

        Parameters:
        -----------

        num_str:  number of strings (returned)

        max_str_len:  maximal string length (returned)

        string features 
        """
        return _Features.StringIntFeatures_copy_features(*args)

    def get_features(*args):
        """
        get_features(self, num_str, max_str_len) -> shogun::T_STRING<(int)>
        get_features(self, dst)

        get_features (swig compatible)

        Parameters:
        -----------

        dst:  string features (returned)

        num_str:  number of strings (returned) 
        """
        return _Features.StringIntFeatures_get_features(*args)

    def load_compressed(*args):
        """
        load_compressed(self, src, decompress) -> bool

        load compressed features from file

        Parameters:
        -----------

        src:  filename to load from

        decompress:  whether to decompress on loading

        if loading was successful 
        """
        return _Features.StringIntFeatures_load_compressed(*args)

    def save_compressed(*args):
        """
        save_compressed(self, dest, compression, level) -> bool

        save compressed features to file

        Parameters:
        -----------

        dest:  filename to save to

        compression:  compressor to use

        level:  compression level to use (1-9)

        if saving was successful 
        """
        return _Features.StringIntFeatures_save_compressed(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.StringIntFeatures_apply_preproc(*args)

    def obtain_by_sliding_window(*args):
        """
        obtain_by_sliding_window(self, window_size, step_size, skip=0) ->  int
        obtain_by_sliding_window(self, window_size, step_size) ->  int

        slides a window of size window_size over the current single string
        step_size is the amount by which the window is shifted. creates
        (string_len-window_size)/step_size many feature obj if skip is
        nonzero, skip the first 'skip' stracters of each string

        Parameters:
        -----------

        window_size:  window size

        step_size:  step size

        skip:  skip

        something inty 
        """
        return _Features.StringIntFeatures_obtain_by_sliding_window(*args)

    def obtain_by_position_list(*args):
        """
        obtain_by_position_list(self, window_size, positions, skip=0) ->  int
        obtain_by_position_list(self, window_size, positions) ->  int

        extracts windows of size window_size from first string using the
        positions in list

        Parameters:
        -----------

        window_size:  window size

        positions:  positions

        skip:  skip

        something inty 
        """
        return _Features.StringIntFeatures_obtain_by_position_list(*args)

    def obtain_from_char(*args):
        """
        obtain_from_char(self, sf, start, p_order, gap, rev) -> bool

        obtain string features from str features

        wrapper for template method

        Parameters:
        -----------

        sf:  string features

        start:  start

        p_order:  order

        gap:  gap

        rev:  reverse

        if obtaining was successful 
        """
        return _Features.StringIntFeatures_obtain_from_char(*args)

    def have_same_length(*args):
        """
        have_same_length(self, len=-1) -> bool
        have_same_length(self) -> bool

        check if length of each vector in this feature object equals the given
        length.

        Parameters:
        -----------

        len:  vector length to check against

        if length of each vector in this feature object equals the given
        length. 
        """
        return _Features.StringIntFeatures_have_same_length(*args)

    def embed_features(*args):
        """embed_features(self, p_order)"""
        return _Features.StringIntFeatures_embed_features(*args)

    def compute_symbol_mask_table(*args):
        """compute_symbol_mask_table(self, max_val)"""
        return _Features.StringIntFeatures_compute_symbol_mask_table(*args)

    def unembed_word(*args):
        """unembed_word(self, word, seq, len)"""
        return _Features.StringIntFeatures_unembed_word(*args)

    def embed_word(*args):
        """embed_word(self, seq, len) -> int"""
        return _Features.StringIntFeatures_embed_word(*args)

    def determine_maximum_string_length(*args):
        """
        determine_maximum_string_length(self)

        determine new maximum string length 
        """
        return _Features.StringIntFeatures_determine_maximum_string_length(*args)

    def get_zero_terminated_string_copy(*args):
        """get_zero_terminated_string_copy(str) -> int"""
        return _Features.StringIntFeatures_get_zero_terminated_string_copy(*args)

    if _newclass:get_zero_terminated_string_copy = staticmethod(get_zero_terminated_string_copy)
    __swig_getmethods__["get_zero_terminated_string_copy"] = lambda x: get_zero_terminated_string_copy
    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)
        set_feature_vector(self, num, string, len)

        set feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        string:  string with the feature vector's content

        len:  length of the string 
        """
        return _Features.StringIntFeatures_set_feature_vector(*args)

StringIntFeatures_swigregister = _Features.StringIntFeatures_swigregister
StringIntFeatures_swigregister(StringIntFeatures)

def StringIntFeatures_get_zero_terminated_string_copy(*args):
  """StringIntFeatures_get_zero_terminated_string_copy(str) -> int"""
  return _Features.StringIntFeatures_get_zero_terminated_string_copy(*args)

class StringUIntFeatures(Features):
    """
    Template class StringFeatures implements a list of strings.

    As this class is a template the underlying storage type is quite
    arbitrary and not limited to stracter strings, but could also be
    sequences of floating point numbers etc. Strings differ from matrices
    (cf. CSimpleFeatures) in a way that the dimensionality of the feature
    vectors (i.e. the strings) is not fixed; it may vary between strings.

    Most string kernels require StringFeatures but a number of them
    actually requires strings to have same length.

    When preprocessors are attached to string features they may shorten
    the string, but are not allowed to return strings longer than
    max_string_length, as some algorithms depend on this.

    Also note that string features cannot currently be computed on-the-
    fly.

    C++ includes: StringFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringUIntFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringUIntFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringUIntFeatures
        __init__(self, alpha) -> StringUIntFeatures
        __init__(self, p_features, alpha) -> StringUIntFeatures
        __init__(self, alpha) -> StringUIntFeatures
        __init__(self, orig) -> StringUIntFeatures
        __init__(self, fname, alpha=DNA) -> StringUIntFeatures
        __init__(self, fname) -> StringUIntFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringUIntFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringUIntFeatures
    __del__ = lambda self : None;
    def cleanup(*args):
        """
        cleanup(self)

        cleanup string features 
        """
        return _Features.StringUIntFeatures_cleanup(*args)

    def cleanup_feature_vector(*args):
        """
        cleanup_feature_vector(self, num)

        cleanup a single feature vector 
        """
        return _Features.StringUIntFeatures_cleanup_feature_vector(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> Alphabet

        get alphabet used in string features

        alphabet 
        """
        return _Features.StringUIntFeatures_get_alphabet(*args)

    def enable_on_the_fly_preprocessing(*args):
        """
        enable_on_the_fly_preprocessing(self)

        call this to preprocess string features upon get_feature_vector 
        """
        return _Features.StringUIntFeatures_enable_on_the_fly_preprocessing(*args)

    def disable_on_the_fly_preprocessing(*args):
        """
        disable_on_the_fly_preprocessing(self)

        call this to disable on the fly feature preprocessing on
        get_feature_vector. Useful when you manually apply preprocessors. 
        """
        return _Features.StringUIntFeatures_disable_on_the_fly_preprocessing(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, dst, num)
        get_feature_vector(self, num, len, dofree) -> unsigned int

        get feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        len:  length is returned by reference

        dofree:  whether returned vector must be freed by caller via
        free_feature_vector

        feature vector for sample num 
        """
        return _Features.StringUIntFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.StringUIntFeatures_free_feature_vector(*args)

    def get_feature(*args):
        """
        get_feature(self, vec_num, feat_num) -> unsigned int

        get feature

        Parameters:
        -----------

        vec_num:  which vector

        feat_num:  which feature

        feature 
        """
        return _Features.StringUIntFeatures_get_feature(*args)

    def get_vector_length(*args):
        """
        get_vector_length(self, vec_num) ->  int

        get vector length

        Parameters:
        -----------

        vec_num:  which vector

        length of vector 
        """
        return _Features.StringUIntFeatures_get_vector_length(*args)

    def get_max_vector_length(*args):
        """
        get_max_vector_length(self) ->  int

        get maximum vector length

        maximum vector/string length 
        """
        return _Features.StringUIntFeatures_get_max_vector_length(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) -> floatmax_t

        get number of symbols

        Note: floatmax_t sounds weird, but LONG is not long enough

        number of symbols 
        """
        return _Features.StringUIntFeatures_get_num_symbols(*args)

    def get_max_num_symbols(*args):
        """
        get_max_num_symbols(self) -> floatmax_t

        get maximum number of symbols

        Note: floatmax_t sounds weird, but int is not long enough (and
        there is no int128_t type)

        maximum number of symbols 
        """
        return _Features.StringUIntFeatures_get_max_num_symbols(*args)

    def get_original_num_symbols(*args):
        """
        get_original_num_symbols(self) -> floatmax_t

        number of symbols before higher order mapping

        original number of symbols 
        """
        return _Features.StringUIntFeatures_get_original_num_symbols(*args)

    def get_order(*args):
        """
        get_order(self) ->  int

        order used for higher order mapping

        order 
        """
        return _Features.StringUIntFeatures_get_order(*args)

    def get_masked_symbols(*args):
        """get_masked_symbols(self, symbol, mask) -> unsigned int"""
        return _Features.StringUIntFeatures_get_masked_symbols(*args)

    def shift_offset(*args):
        """shift_offset(self, offset, amount) -> unsigned int"""
        return _Features.StringUIntFeatures_shift_offset(*args)

    def shift_symbol(*args):
        """shift_symbol(self, symbol, amount) -> unsigned int"""
        return _Features.StringUIntFeatures_shift_symbol(*args)

    def load_dna_file(*args):
        """
        load_dna_file(self, fname, remap_to_bin=True) -> bool
        load_dna_file(self, fname) -> bool

        load DNA features from file

        Parameters:
        -----------

        fname:  filename to load from

        remap_to_bin:  if remap_to_bin

        if loading was successful 
        """
        return _Features.StringUIntFeatures_load_dna_file(*args)

    def load_fasta_file(*args):
        """
        load_fasta_file(self, fname, ignore_invalid=False) -> bool
        load_fasta_file(self, fname) -> bool

        load fasta file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        if loading was successful 
        """
        return _Features.StringUIntFeatures_load_fasta_file(*args)

    def load_fastq_file(*args):
        """
        load_fastq_file(self, fname, ignore_invalid=False, bitremap_in_single_string=False) -> bool
        load_fastq_file(self, fname, ignore_invalid=False) -> bool
        load_fastq_file(self, fname) -> bool

        load fastq file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        bitremap_in_single_string:  if set to true, do binary embedding of
        symbols

        if loading was successful 
        """
        return _Features.StringUIntFeatures_load_fastq_file(*args)

    def load_from_directory(*args):
        """
        load_from_directory(self, dirname) -> bool

        load features from directory

        Parameters:
        -----------

        dirname:  directory name to load from

        if loading was successful 
        """
        return _Features.StringUIntFeatures_load_from_directory(*args)

    def set_features(*args):
        """
        set_features(self, p_features) -> bool

        set features

        Parameters:
        -----------

        p_features:  new features

        p_num_vectors:  number of vectors

        p_max_string_length:  maximum string length

        if setting was successful 
        """
        return _Features.StringUIntFeatures_set_features(*args)

    def copy_features(*args):
        """
        copy_features(self, num_str, max_str_len) -> shogun::T_STRING<(unsigned int)>

        copy_features

        Parameters:
        -----------

        num_str:  number of strings (returned)

        max_str_len:  maximal string length (returned)

        string features 
        """
        return _Features.StringUIntFeatures_copy_features(*args)

    def get_features(*args):
        """
        get_features(self, num_str, max_str_len) -> shogun::T_STRING<(unsigned int)>
        get_features(self, dst)

        get_features (swig compatible)

        Parameters:
        -----------

        dst:  string features (returned)

        num_str:  number of strings (returned) 
        """
        return _Features.StringUIntFeatures_get_features(*args)

    def load_compressed(*args):
        """
        load_compressed(self, src, decompress) -> bool

        load compressed features from file

        Parameters:
        -----------

        src:  filename to load from

        decompress:  whether to decompress on loading

        if loading was successful 
        """
        return _Features.StringUIntFeatures_load_compressed(*args)

    def save_compressed(*args):
        """
        save_compressed(self, dest, compression, level) -> bool

        save compressed features to file

        Parameters:
        -----------

        dest:  filename to save to

        compression:  compressor to use

        level:  compression level to use (1-9)

        if saving was successful 
        """
        return _Features.StringUIntFeatures_save_compressed(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.StringUIntFeatures_apply_preproc(*args)

    def obtain_by_sliding_window(*args):
        """
        obtain_by_sliding_window(self, window_size, step_size, skip=0) ->  int
        obtain_by_sliding_window(self, window_size, step_size) ->  int

        slides a window of size window_size over the current single string
        step_size is the amount by which the window is shifted. creates
        (string_len-window_size)/step_size many feature obj if skip is
        nonzero, skip the first 'skip' stracters of each string

        Parameters:
        -----------

        window_size:  window size

        step_size:  step size

        skip:  skip

        something inty 
        """
        return _Features.StringUIntFeatures_obtain_by_sliding_window(*args)

    def obtain_by_position_list(*args):
        """
        obtain_by_position_list(self, window_size, positions, skip=0) ->  int
        obtain_by_position_list(self, window_size, positions) ->  int

        extracts windows of size window_size from first string using the
        positions in list

        Parameters:
        -----------

        window_size:  window size

        positions:  positions

        skip:  skip

        something inty 
        """
        return _Features.StringUIntFeatures_obtain_by_position_list(*args)

    def obtain_from_char(*args):
        """
        obtain_from_char(self, sf, start, p_order, gap, rev) -> bool

        obtain string features from str features

        wrapper for template method

        Parameters:
        -----------

        sf:  string features

        start:  start

        p_order:  order

        gap:  gap

        rev:  reverse

        if obtaining was successful 
        """
        return _Features.StringUIntFeatures_obtain_from_char(*args)

    def have_same_length(*args):
        """
        have_same_length(self, len=-1) -> bool
        have_same_length(self) -> bool

        check if length of each vector in this feature object equals the given
        length.

        Parameters:
        -----------

        len:  vector length to check against

        if length of each vector in this feature object equals the given
        length. 
        """
        return _Features.StringUIntFeatures_have_same_length(*args)

    def embed_features(*args):
        """embed_features(self, p_order)"""
        return _Features.StringUIntFeatures_embed_features(*args)

    def compute_symbol_mask_table(*args):
        """compute_symbol_mask_table(self, max_val)"""
        return _Features.StringUIntFeatures_compute_symbol_mask_table(*args)

    def unembed_word(*args):
        """unembed_word(self, word, seq, len)"""
        return _Features.StringUIntFeatures_unembed_word(*args)

    def embed_word(*args):
        """embed_word(self, seq, len) -> unsigned int"""
        return _Features.StringUIntFeatures_embed_word(*args)

    def determine_maximum_string_length(*args):
        """
        determine_maximum_string_length(self)

        determine new maximum string length 
        """
        return _Features.StringUIntFeatures_determine_maximum_string_length(*args)

    def get_zero_terminated_string_copy(*args):
        """get_zero_terminated_string_copy(str) -> unsigned int"""
        return _Features.StringUIntFeatures_get_zero_terminated_string_copy(*args)

    if _newclass:get_zero_terminated_string_copy = staticmethod(get_zero_terminated_string_copy)
    __swig_getmethods__["get_zero_terminated_string_copy"] = lambda x: get_zero_terminated_string_copy
    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)
        set_feature_vector(self, num, string, len)

        set feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        string:  string with the feature vector's content

        len:  length of the string 
        """
        return _Features.StringUIntFeatures_set_feature_vector(*args)

StringUIntFeatures_swigregister = _Features.StringUIntFeatures_swigregister
StringUIntFeatures_swigregister(StringUIntFeatures)

def StringUIntFeatures_get_zero_terminated_string_copy(*args):
  """StringUIntFeatures_get_zero_terminated_string_copy(str) -> unsigned int"""
  return _Features.StringUIntFeatures_get_zero_terminated_string_copy(*args)

class StringLongFeatures(Features):
    """
    Template class StringFeatures implements a list of strings.

    As this class is a template the underlying storage type is quite
    arbitrary and not limited to stracter strings, but could also be
    sequences of floating point numbers etc. Strings differ from matrices
    (cf. CSimpleFeatures) in a way that the dimensionality of the feature
    vectors (i.e. the strings) is not fixed; it may vary between strings.

    Most string kernels require StringFeatures but a number of them
    actually requires strings to have same length.

    When preprocessors are attached to string features they may shorten
    the string, but are not allowed to return strings longer than
    max_string_length, as some algorithms depend on this.

    Also note that string features cannot currently be computed on-the-
    fly.

    C++ includes: StringFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringLongFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringLongFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringLongFeatures
        __init__(self, alpha) -> StringLongFeatures
        __init__(self, p_features, alpha) -> StringLongFeatures
        __init__(self, alpha) -> StringLongFeatures
        __init__(self, orig) -> StringLongFeatures
        __init__(self, fname, alpha=DNA) -> StringLongFeatures
        __init__(self, fname) -> StringLongFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringLongFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringLongFeatures
    __del__ = lambda self : None;
    def cleanup(*args):
        """
        cleanup(self)

        cleanup string features 
        """
        return _Features.StringLongFeatures_cleanup(*args)

    def cleanup_feature_vector(*args):
        """
        cleanup_feature_vector(self, num)

        cleanup a single feature vector 
        """
        return _Features.StringLongFeatures_cleanup_feature_vector(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> Alphabet

        get alphabet used in string features

        alphabet 
        """
        return _Features.StringLongFeatures_get_alphabet(*args)

    def enable_on_the_fly_preprocessing(*args):
        """
        enable_on_the_fly_preprocessing(self)

        call this to preprocess string features upon get_feature_vector 
        """
        return _Features.StringLongFeatures_enable_on_the_fly_preprocessing(*args)

    def disable_on_the_fly_preprocessing(*args):
        """
        disable_on_the_fly_preprocessing(self)

        call this to disable on the fly feature preprocessing on
        get_feature_vector. Useful when you manually apply preprocessors. 
        """
        return _Features.StringLongFeatures_disable_on_the_fly_preprocessing(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, dst, num)
        get_feature_vector(self, num, len, dofree) -> long long

        get feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        len:  length is returned by reference

        dofree:  whether returned vector must be freed by caller via
        free_feature_vector

        feature vector for sample num 
        """
        return _Features.StringLongFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.StringLongFeatures_free_feature_vector(*args)

    def get_feature(*args):
        """
        get_feature(self, vec_num, feat_num) -> long long

        get feature

        Parameters:
        -----------

        vec_num:  which vector

        feat_num:  which feature

        feature 
        """
        return _Features.StringLongFeatures_get_feature(*args)

    def get_vector_length(*args):
        """
        get_vector_length(self, vec_num) ->  int

        get vector length

        Parameters:
        -----------

        vec_num:  which vector

        length of vector 
        """
        return _Features.StringLongFeatures_get_vector_length(*args)

    def get_max_vector_length(*args):
        """
        get_max_vector_length(self) ->  int

        get maximum vector length

        maximum vector/string length 
        """
        return _Features.StringLongFeatures_get_max_vector_length(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) -> floatmax_t

        get number of symbols

        Note: floatmax_t sounds weird, but LONG is not long enough

        number of symbols 
        """
        return _Features.StringLongFeatures_get_num_symbols(*args)

    def get_max_num_symbols(*args):
        """
        get_max_num_symbols(self) -> floatmax_t

        get maximum number of symbols

        Note: floatmax_t sounds weird, but int is not long enough (and
        there is no int128_t type)

        maximum number of symbols 
        """
        return _Features.StringLongFeatures_get_max_num_symbols(*args)

    def get_original_num_symbols(*args):
        """
        get_original_num_symbols(self) -> floatmax_t

        number of symbols before higher order mapping

        original number of symbols 
        """
        return _Features.StringLongFeatures_get_original_num_symbols(*args)

    def get_order(*args):
        """
        get_order(self) ->  int

        order used for higher order mapping

        order 
        """
        return _Features.StringLongFeatures_get_order(*args)

    def get_masked_symbols(*args):
        """get_masked_symbols(self, symbol, mask) -> long long"""
        return _Features.StringLongFeatures_get_masked_symbols(*args)

    def shift_offset(*args):
        """shift_offset(self, offset, amount) -> long long"""
        return _Features.StringLongFeatures_shift_offset(*args)

    def shift_symbol(*args):
        """shift_symbol(self, symbol, amount) -> long long"""
        return _Features.StringLongFeatures_shift_symbol(*args)

    def load_dna_file(*args):
        """
        load_dna_file(self, fname, remap_to_bin=True) -> bool
        load_dna_file(self, fname) -> bool

        load DNA features from file

        Parameters:
        -----------

        fname:  filename to load from

        remap_to_bin:  if remap_to_bin

        if loading was successful 
        """
        return _Features.StringLongFeatures_load_dna_file(*args)

    def load_fasta_file(*args):
        """
        load_fasta_file(self, fname, ignore_invalid=False) -> bool
        load_fasta_file(self, fname) -> bool

        load fasta file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        if loading was successful 
        """
        return _Features.StringLongFeatures_load_fasta_file(*args)

    def load_fastq_file(*args):
        """
        load_fastq_file(self, fname, ignore_invalid=False, bitremap_in_single_string=False) -> bool
        load_fastq_file(self, fname, ignore_invalid=False) -> bool
        load_fastq_file(self, fname) -> bool

        load fastq file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        bitremap_in_single_string:  if set to true, do binary embedding of
        symbols

        if loading was successful 
        """
        return _Features.StringLongFeatures_load_fastq_file(*args)

    def load_from_directory(*args):
        """
        load_from_directory(self, dirname) -> bool

        load features from directory

        Parameters:
        -----------

        dirname:  directory name to load from

        if loading was successful 
        """
        return _Features.StringLongFeatures_load_from_directory(*args)

    def set_features(*args):
        """
        set_features(self, p_features) -> bool

        set features

        Parameters:
        -----------

        p_features:  new features

        p_num_vectors:  number of vectors

        p_max_string_length:  maximum string length

        if setting was successful 
        """
        return _Features.StringLongFeatures_set_features(*args)

    def copy_features(*args):
        """
        copy_features(self, num_str, max_str_len) -> shogun::T_STRING<(long long)>

        copy_features

        Parameters:
        -----------

        num_str:  number of strings (returned)

        max_str_len:  maximal string length (returned)

        string features 
        """
        return _Features.StringLongFeatures_copy_features(*args)

    def get_features(*args):
        """
        get_features(self, num_str, max_str_len) -> shogun::T_STRING<(long long)>
        get_features(self, dst)

        get_features (swig compatible)

        Parameters:
        -----------

        dst:  string features (returned)

        num_str:  number of strings (returned) 
        """
        return _Features.StringLongFeatures_get_features(*args)

    def load_compressed(*args):
        """
        load_compressed(self, src, decompress) -> bool

        load compressed features from file

        Parameters:
        -----------

        src:  filename to load from

        decompress:  whether to decompress on loading

        if loading was successful 
        """
        return _Features.StringLongFeatures_load_compressed(*args)

    def save_compressed(*args):
        """
        save_compressed(self, dest, compression, level) -> bool

        save compressed features to file

        Parameters:
        -----------

        dest:  filename to save to

        compression:  compressor to use

        level:  compression level to use (1-9)

        if saving was successful 
        """
        return _Features.StringLongFeatures_save_compressed(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.StringLongFeatures_apply_preproc(*args)

    def obtain_by_sliding_window(*args):
        """
        obtain_by_sliding_window(self, window_size, step_size, skip=0) ->  int
        obtain_by_sliding_window(self, window_size, step_size) ->  int

        slides a window of size window_size over the current single string
        step_size is the amount by which the window is shifted. creates
        (string_len-window_size)/step_size many feature obj if skip is
        nonzero, skip the first 'skip' stracters of each string

        Parameters:
        -----------

        window_size:  window size

        step_size:  step size

        skip:  skip

        something inty 
        """
        return _Features.StringLongFeatures_obtain_by_sliding_window(*args)

    def obtain_by_position_list(*args):
        """
        obtain_by_position_list(self, window_size, positions, skip=0) ->  int
        obtain_by_position_list(self, window_size, positions) ->  int

        extracts windows of size window_size from first string using the
        positions in list

        Parameters:
        -----------

        window_size:  window size

        positions:  positions

        skip:  skip

        something inty 
        """
        return _Features.StringLongFeatures_obtain_by_position_list(*args)

    def obtain_from_char(*args):
        """
        obtain_from_char(self, sf, start, p_order, gap, rev) -> bool

        obtain string features from str features

        wrapper for template method

        Parameters:
        -----------

        sf:  string features

        start:  start

        p_order:  order

        gap:  gap

        rev:  reverse

        if obtaining was successful 
        """
        return _Features.StringLongFeatures_obtain_from_char(*args)

    def have_same_length(*args):
        """
        have_same_length(self, len=-1) -> bool
        have_same_length(self) -> bool

        check if length of each vector in this feature object equals the given
        length.

        Parameters:
        -----------

        len:  vector length to check against

        if length of each vector in this feature object equals the given
        length. 
        """
        return _Features.StringLongFeatures_have_same_length(*args)

    def embed_features(*args):
        """embed_features(self, p_order)"""
        return _Features.StringLongFeatures_embed_features(*args)

    def compute_symbol_mask_table(*args):
        """compute_symbol_mask_table(self, max_val)"""
        return _Features.StringLongFeatures_compute_symbol_mask_table(*args)

    def unembed_word(*args):
        """unembed_word(self, word, seq, len)"""
        return _Features.StringLongFeatures_unembed_word(*args)

    def embed_word(*args):
        """embed_word(self, seq, len) -> long long"""
        return _Features.StringLongFeatures_embed_word(*args)

    def determine_maximum_string_length(*args):
        """
        determine_maximum_string_length(self)

        determine new maximum string length 
        """
        return _Features.StringLongFeatures_determine_maximum_string_length(*args)

    def get_zero_terminated_string_copy(*args):
        """get_zero_terminated_string_copy(str) -> long long"""
        return _Features.StringLongFeatures_get_zero_terminated_string_copy(*args)

    if _newclass:get_zero_terminated_string_copy = staticmethod(get_zero_terminated_string_copy)
    __swig_getmethods__["get_zero_terminated_string_copy"] = lambda x: get_zero_terminated_string_copy
    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)
        set_feature_vector(self, num, string, len)

        set feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        string:  string with the feature vector's content

        len:  length of the string 
        """
        return _Features.StringLongFeatures_set_feature_vector(*args)

StringLongFeatures_swigregister = _Features.StringLongFeatures_swigregister
StringLongFeatures_swigregister(StringLongFeatures)

def StringLongFeatures_get_zero_terminated_string_copy(*args):
  """StringLongFeatures_get_zero_terminated_string_copy(str) -> long long"""
  return _Features.StringLongFeatures_get_zero_terminated_string_copy(*args)

class StringUlongFeatures(Features):
    """
    Template class StringFeatures implements a list of strings.

    As this class is a template the underlying storage type is quite
    arbitrary and not limited to stracter strings, but could also be
    sequences of floating point numbers etc. Strings differ from matrices
    (cf. CSimpleFeatures) in a way that the dimensionality of the feature
    vectors (i.e. the strings) is not fixed; it may vary between strings.

    Most string kernels require StringFeatures but a number of them
    actually requires strings to have same length.

    When preprocessors are attached to string features they may shorten
    the string, but are not allowed to return strings longer than
    max_string_length, as some algorithms depend on this.

    Also note that string features cannot currently be computed on-the-
    fly.

    C++ includes: StringFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringUlongFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringUlongFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringUlongFeatures
        __init__(self, alpha) -> StringUlongFeatures
        __init__(self, p_features, alpha) -> StringUlongFeatures
        __init__(self, alpha) -> StringUlongFeatures
        __init__(self, orig) -> StringUlongFeatures
        __init__(self, fname, alpha=DNA) -> StringUlongFeatures
        __init__(self, fname) -> StringUlongFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringUlongFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringUlongFeatures
    __del__ = lambda self : None;
    def cleanup(*args):
        """
        cleanup(self)

        cleanup string features 
        """
        return _Features.StringUlongFeatures_cleanup(*args)

    def cleanup_feature_vector(*args):
        """
        cleanup_feature_vector(self, num)

        cleanup a single feature vector 
        """
        return _Features.StringUlongFeatures_cleanup_feature_vector(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> Alphabet

        get alphabet used in string features

        alphabet 
        """
        return _Features.StringUlongFeatures_get_alphabet(*args)

    def enable_on_the_fly_preprocessing(*args):
        """
        enable_on_the_fly_preprocessing(self)

        call this to preprocess string features upon get_feature_vector 
        """
        return _Features.StringUlongFeatures_enable_on_the_fly_preprocessing(*args)

    def disable_on_the_fly_preprocessing(*args):
        """
        disable_on_the_fly_preprocessing(self)

        call this to disable on the fly feature preprocessing on
        get_feature_vector. Useful when you manually apply preprocessors. 
        """
        return _Features.StringUlongFeatures_disable_on_the_fly_preprocessing(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, dst, num)
        get_feature_vector(self, num, len, dofree) -> unsigned long long

        get feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        len:  length is returned by reference

        dofree:  whether returned vector must be freed by caller via
        free_feature_vector

        feature vector for sample num 
        """
        return _Features.StringUlongFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.StringUlongFeatures_free_feature_vector(*args)

    def get_feature(*args):
        """
        get_feature(self, vec_num, feat_num) -> unsigned long long

        get feature

        Parameters:
        -----------

        vec_num:  which vector

        feat_num:  which feature

        feature 
        """
        return _Features.StringUlongFeatures_get_feature(*args)

    def get_vector_length(*args):
        """
        get_vector_length(self, vec_num) ->  int

        get vector length

        Parameters:
        -----------

        vec_num:  which vector

        length of vector 
        """
        return _Features.StringUlongFeatures_get_vector_length(*args)

    def get_max_vector_length(*args):
        """
        get_max_vector_length(self) ->  int

        get maximum vector length

        maximum vector/string length 
        """
        return _Features.StringUlongFeatures_get_max_vector_length(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) -> floatmax_t

        get number of symbols

        Note: floatmax_t sounds weird, but LONG is not long enough

        number of symbols 
        """
        return _Features.StringUlongFeatures_get_num_symbols(*args)

    def get_max_num_symbols(*args):
        """
        get_max_num_symbols(self) -> floatmax_t

        get maximum number of symbols

        Note: floatmax_t sounds weird, but int is not long enough (and
        there is no int128_t type)

        maximum number of symbols 
        """
        return _Features.StringUlongFeatures_get_max_num_symbols(*args)

    def get_original_num_symbols(*args):
        """
        get_original_num_symbols(self) -> floatmax_t

        number of symbols before higher order mapping

        original number of symbols 
        """
        return _Features.StringUlongFeatures_get_original_num_symbols(*args)

    def get_order(*args):
        """
        get_order(self) ->  int

        order used for higher order mapping

        order 
        """
        return _Features.StringUlongFeatures_get_order(*args)

    def get_masked_symbols(*args):
        """get_masked_symbols(self, symbol, mask) -> unsigned long long"""
        return _Features.StringUlongFeatures_get_masked_symbols(*args)

    def shift_offset(*args):
        """shift_offset(self, offset, amount) -> unsigned long long"""
        return _Features.StringUlongFeatures_shift_offset(*args)

    def shift_symbol(*args):
        """shift_symbol(self, symbol, amount) -> unsigned long long"""
        return _Features.StringUlongFeatures_shift_symbol(*args)

    def load_dna_file(*args):
        """
        load_dna_file(self, fname, remap_to_bin=True) -> bool
        load_dna_file(self, fname) -> bool

        load DNA features from file

        Parameters:
        -----------

        fname:  filename to load from

        remap_to_bin:  if remap_to_bin

        if loading was successful 
        """
        return _Features.StringUlongFeatures_load_dna_file(*args)

    def load_fasta_file(*args):
        """
        load_fasta_file(self, fname, ignore_invalid=False) -> bool
        load_fasta_file(self, fname) -> bool

        load fasta file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        if loading was successful 
        """
        return _Features.StringUlongFeatures_load_fasta_file(*args)

    def load_fastq_file(*args):
        """
        load_fastq_file(self, fname, ignore_invalid=False, bitremap_in_single_string=False) -> bool
        load_fastq_file(self, fname, ignore_invalid=False) -> bool
        load_fastq_file(self, fname) -> bool

        load fastq file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        bitremap_in_single_string:  if set to true, do binary embedding of
        symbols

        if loading was successful 
        """
        return _Features.StringUlongFeatures_load_fastq_file(*args)

    def load_from_directory(*args):
        """
        load_from_directory(self, dirname) -> bool

        load features from directory

        Parameters:
        -----------

        dirname:  directory name to load from

        if loading was successful 
        """
        return _Features.StringUlongFeatures_load_from_directory(*args)

    def set_features(*args):
        """
        set_features(self, p_features) -> bool

        set features

        Parameters:
        -----------

        p_features:  new features

        p_num_vectors:  number of vectors

        p_max_string_length:  maximum string length

        if setting was successful 
        """
        return _Features.StringUlongFeatures_set_features(*args)

    def copy_features(*args):
        """
        copy_features(self, num_str, max_str_len) -> shogun::T_STRING<(unsigned long long)>

        copy_features

        Parameters:
        -----------

        num_str:  number of strings (returned)

        max_str_len:  maximal string length (returned)

        string features 
        """
        return _Features.StringUlongFeatures_copy_features(*args)

    def get_features(*args):
        """
        get_features(self, num_str, max_str_len) -> shogun::T_STRING<(unsigned long long)>
        get_features(self, dst)

        get_features (swig compatible)

        Parameters:
        -----------

        dst:  string features (returned)

        num_str:  number of strings (returned) 
        """
        return _Features.StringUlongFeatures_get_features(*args)

    def load_compressed(*args):
        """
        load_compressed(self, src, decompress) -> bool

        load compressed features from file

        Parameters:
        -----------

        src:  filename to load from

        decompress:  whether to decompress on loading

        if loading was successful 
        """
        return _Features.StringUlongFeatures_load_compressed(*args)

    def save_compressed(*args):
        """
        save_compressed(self, dest, compression, level) -> bool

        save compressed features to file

        Parameters:
        -----------

        dest:  filename to save to

        compression:  compressor to use

        level:  compression level to use (1-9)

        if saving was successful 
        """
        return _Features.StringUlongFeatures_save_compressed(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.StringUlongFeatures_apply_preproc(*args)

    def obtain_by_sliding_window(*args):
        """
        obtain_by_sliding_window(self, window_size, step_size, skip=0) ->  int
        obtain_by_sliding_window(self, window_size, step_size) ->  int

        slides a window of size window_size over the current single string
        step_size is the amount by which the window is shifted. creates
        (string_len-window_size)/step_size many feature obj if skip is
        nonzero, skip the first 'skip' stracters of each string

        Parameters:
        -----------

        window_size:  window size

        step_size:  step size

        skip:  skip

        something inty 
        """
        return _Features.StringUlongFeatures_obtain_by_sliding_window(*args)

    def obtain_by_position_list(*args):
        """
        obtain_by_position_list(self, window_size, positions, skip=0) ->  int
        obtain_by_position_list(self, window_size, positions) ->  int

        extracts windows of size window_size from first string using the
        positions in list

        Parameters:
        -----------

        window_size:  window size

        positions:  positions

        skip:  skip

        something inty 
        """
        return _Features.StringUlongFeatures_obtain_by_position_list(*args)

    def obtain_from_char(*args):
        """
        obtain_from_char(self, sf, start, p_order, gap, rev) -> bool

        obtain string features from str features

        wrapper for template method

        Parameters:
        -----------

        sf:  string features

        start:  start

        p_order:  order

        gap:  gap

        rev:  reverse

        if obtaining was successful 
        """
        return _Features.StringUlongFeatures_obtain_from_char(*args)

    def have_same_length(*args):
        """
        have_same_length(self, len=-1) -> bool
        have_same_length(self) -> bool

        check if length of each vector in this feature object equals the given
        length.

        Parameters:
        -----------

        len:  vector length to check against

        if length of each vector in this feature object equals the given
        length. 
        """
        return _Features.StringUlongFeatures_have_same_length(*args)

    def embed_features(*args):
        """embed_features(self, p_order)"""
        return _Features.StringUlongFeatures_embed_features(*args)

    def compute_symbol_mask_table(*args):
        """compute_symbol_mask_table(self, max_val)"""
        return _Features.StringUlongFeatures_compute_symbol_mask_table(*args)

    def unembed_word(*args):
        """unembed_word(self, word, seq, len)"""
        return _Features.StringUlongFeatures_unembed_word(*args)

    def embed_word(*args):
        """embed_word(self, seq, len) -> unsigned long long"""
        return _Features.StringUlongFeatures_embed_word(*args)

    def determine_maximum_string_length(*args):
        """
        determine_maximum_string_length(self)

        determine new maximum string length 
        """
        return _Features.StringUlongFeatures_determine_maximum_string_length(*args)

    def get_zero_terminated_string_copy(*args):
        """get_zero_terminated_string_copy(str) -> unsigned long long"""
        return _Features.StringUlongFeatures_get_zero_terminated_string_copy(*args)

    if _newclass:get_zero_terminated_string_copy = staticmethod(get_zero_terminated_string_copy)
    __swig_getmethods__["get_zero_terminated_string_copy"] = lambda x: get_zero_terminated_string_copy
    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)
        set_feature_vector(self, num, string, len)

        set feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        string:  string with the feature vector's content

        len:  length of the string 
        """
        return _Features.StringUlongFeatures_set_feature_vector(*args)

StringUlongFeatures_swigregister = _Features.StringUlongFeatures_swigregister
StringUlongFeatures_swigregister(StringUlongFeatures)

def StringUlongFeatures_get_zero_terminated_string_copy(*args):
  """StringUlongFeatures_get_zero_terminated_string_copy(str) -> unsigned long long"""
  return _Features.StringUlongFeatures_get_zero_terminated_string_copy(*args)

class StringShortRealFeatures(Features):
    """
    Template class StringFeatures implements a list of strings.

    As this class is a template the underlying storage type is quite
    arbitrary and not limited to stracter strings, but could also be
    sequences of floating point numbers etc. Strings differ from matrices
    (cf. CSimpleFeatures) in a way that the dimensionality of the feature
    vectors (i.e. the strings) is not fixed; it may vary between strings.

    Most string kernels require StringFeatures but a number of them
    actually requires strings to have same length.

    When preprocessors are attached to string features they may shorten
    the string, but are not allowed to return strings longer than
    max_string_length, as some algorithms depend on this.

    Also note that string features cannot currently be computed on-the-
    fly.

    C++ includes: StringFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringShortRealFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringShortRealFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringShortRealFeatures
        __init__(self, alpha) -> StringShortRealFeatures
        __init__(self, p_features, alpha) -> StringShortRealFeatures
        __init__(self, alpha) -> StringShortRealFeatures
        __init__(self, orig) -> StringShortRealFeatures
        __init__(self, fname, alpha=DNA) -> StringShortRealFeatures
        __init__(self, fname) -> StringShortRealFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringShortRealFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringShortRealFeatures
    __del__ = lambda self : None;
    def cleanup(*args):
        """
        cleanup(self)

        cleanup string features 
        """
        return _Features.StringShortRealFeatures_cleanup(*args)

    def cleanup_feature_vector(*args):
        """
        cleanup_feature_vector(self, num)

        cleanup a single feature vector 
        """
        return _Features.StringShortRealFeatures_cleanup_feature_vector(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> Alphabet

        get alphabet used in string features

        alphabet 
        """
        return _Features.StringShortRealFeatures_get_alphabet(*args)

    def enable_on_the_fly_preprocessing(*args):
        """
        enable_on_the_fly_preprocessing(self)

        call this to preprocess string features upon get_feature_vector 
        """
        return _Features.StringShortRealFeatures_enable_on_the_fly_preprocessing(*args)

    def disable_on_the_fly_preprocessing(*args):
        """
        disable_on_the_fly_preprocessing(self)

        call this to disable on the fly feature preprocessing on
        get_feature_vector. Useful when you manually apply preprocessors. 
        """
        return _Features.StringShortRealFeatures_disable_on_the_fly_preprocessing(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, dst, num)
        get_feature_vector(self, num, len, dofree) -> float

        get feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        len:  length is returned by reference

        dofree:  whether returned vector must be freed by caller via
        free_feature_vector

        feature vector for sample num 
        """
        return _Features.StringShortRealFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.StringShortRealFeatures_free_feature_vector(*args)

    def get_feature(*args):
        """
        get_feature(self, vec_num, feat_num) -> float

        get feature

        Parameters:
        -----------

        vec_num:  which vector

        feat_num:  which feature

        feature 
        """
        return _Features.StringShortRealFeatures_get_feature(*args)

    def get_vector_length(*args):
        """
        get_vector_length(self, vec_num) ->  int

        get vector length

        Parameters:
        -----------

        vec_num:  which vector

        length of vector 
        """
        return _Features.StringShortRealFeatures_get_vector_length(*args)

    def get_max_vector_length(*args):
        """
        get_max_vector_length(self) ->  int

        get maximum vector length

        maximum vector/string length 
        """
        return _Features.StringShortRealFeatures_get_max_vector_length(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) -> floatmax_t

        get number of symbols

        Note: floatmax_t sounds weird, but LONG is not long enough

        number of symbols 
        """
        return _Features.StringShortRealFeatures_get_num_symbols(*args)

    def get_max_num_symbols(*args):
        """
        get_max_num_symbols(self) -> floatmax_t

        get maximum number of symbols

        Note: floatmax_t sounds weird, but int is not long enough (and
        there is no int128_t type)

        maximum number of symbols 
        """
        return _Features.StringShortRealFeatures_get_max_num_symbols(*args)

    def get_original_num_symbols(*args):
        """
        get_original_num_symbols(self) -> floatmax_t

        number of symbols before higher order mapping

        original number of symbols 
        """
        return _Features.StringShortRealFeatures_get_original_num_symbols(*args)

    def get_order(*args):
        """
        get_order(self) ->  int

        order used for higher order mapping

        order 
        """
        return _Features.StringShortRealFeatures_get_order(*args)

    def get_masked_symbols(*args):
        """get_masked_symbols(self, symbol, mask) -> float"""
        return _Features.StringShortRealFeatures_get_masked_symbols(*args)

    def shift_offset(*args):
        """shift_offset(self, offset, amount) -> float"""
        return _Features.StringShortRealFeatures_shift_offset(*args)

    def shift_symbol(*args):
        """shift_symbol(self, symbol, amount) -> float"""
        return _Features.StringShortRealFeatures_shift_symbol(*args)

    def load_dna_file(*args):
        """
        load_dna_file(self, fname, remap_to_bin=True) -> bool
        load_dna_file(self, fname) -> bool

        load DNA features from file

        Parameters:
        -----------

        fname:  filename to load from

        remap_to_bin:  if remap_to_bin

        if loading was successful 
        """
        return _Features.StringShortRealFeatures_load_dna_file(*args)

    def load_fasta_file(*args):
        """
        load_fasta_file(self, fname, ignore_invalid=False) -> bool
        load_fasta_file(self, fname) -> bool

        load fasta file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        if loading was successful 
        """
        return _Features.StringShortRealFeatures_load_fasta_file(*args)

    def load_fastq_file(*args):
        """
        load_fastq_file(self, fname, ignore_invalid=False, bitremap_in_single_string=False) -> bool
        load_fastq_file(self, fname, ignore_invalid=False) -> bool
        load_fastq_file(self, fname) -> bool

        load fastq file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        bitremap_in_single_string:  if set to true, do binary embedding of
        symbols

        if loading was successful 
        """
        return _Features.StringShortRealFeatures_load_fastq_file(*args)

    def load_from_directory(*args):
        """
        load_from_directory(self, dirname) -> bool

        load features from directory

        Parameters:
        -----------

        dirname:  directory name to load from

        if loading was successful 
        """
        return _Features.StringShortRealFeatures_load_from_directory(*args)

    def set_features(*args):
        """
        set_features(self, p_features) -> bool

        set features

        Parameters:
        -----------

        p_features:  new features

        p_num_vectors:  number of vectors

        p_max_string_length:  maximum string length

        if setting was successful 
        """
        return _Features.StringShortRealFeatures_set_features(*args)

    def copy_features(*args):
        """
        copy_features(self, num_str, max_str_len) -> shogun::T_STRING<(float)>

        copy_features

        Parameters:
        -----------

        num_str:  number of strings (returned)

        max_str_len:  maximal string length (returned)

        string features 
        """
        return _Features.StringShortRealFeatures_copy_features(*args)

    def get_features(*args):
        """
        get_features(self, num_str, max_str_len) -> shogun::T_STRING<(float)>
        get_features(self, dst)

        get_features (swig compatible)

        Parameters:
        -----------

        dst:  string features (returned)

        num_str:  number of strings (returned) 
        """
        return _Features.StringShortRealFeatures_get_features(*args)

    def load_compressed(*args):
        """
        load_compressed(self, src, decompress) -> bool

        load compressed features from file

        Parameters:
        -----------

        src:  filename to load from

        decompress:  whether to decompress on loading

        if loading was successful 
        """
        return _Features.StringShortRealFeatures_load_compressed(*args)

    def save_compressed(*args):
        """
        save_compressed(self, dest, compression, level) -> bool

        save compressed features to file

        Parameters:
        -----------

        dest:  filename to save to

        compression:  compressor to use

        level:  compression level to use (1-9)

        if saving was successful 
        """
        return _Features.StringShortRealFeatures_save_compressed(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.StringShortRealFeatures_apply_preproc(*args)

    def obtain_by_sliding_window(*args):
        """
        obtain_by_sliding_window(self, window_size, step_size, skip=0) ->  int
        obtain_by_sliding_window(self, window_size, step_size) ->  int

        slides a window of size window_size over the current single string
        step_size is the amount by which the window is shifted. creates
        (string_len-window_size)/step_size many feature obj if skip is
        nonzero, skip the first 'skip' stracters of each string

        Parameters:
        -----------

        window_size:  window size

        step_size:  step size

        skip:  skip

        something inty 
        """
        return _Features.StringShortRealFeatures_obtain_by_sliding_window(*args)

    def obtain_by_position_list(*args):
        """
        obtain_by_position_list(self, window_size, positions, skip=0) ->  int
        obtain_by_position_list(self, window_size, positions) ->  int

        extracts windows of size window_size from first string using the
        positions in list

        Parameters:
        -----------

        window_size:  window size

        positions:  positions

        skip:  skip

        something inty 
        """
        return _Features.StringShortRealFeatures_obtain_by_position_list(*args)

    def obtain_from_char(*args):
        """
        obtain_from_char(self, sf, start, p_order, gap, rev) -> bool

        obtain string features from str features

        wrapper for template method

        Parameters:
        -----------

        sf:  string features

        start:  start

        p_order:  order

        gap:  gap

        rev:  reverse

        if obtaining was successful 
        """
        return _Features.StringShortRealFeatures_obtain_from_char(*args)

    def have_same_length(*args):
        """
        have_same_length(self, len=-1) -> bool
        have_same_length(self) -> bool

        check if length of each vector in this feature object equals the given
        length.

        Parameters:
        -----------

        len:  vector length to check against

        if length of each vector in this feature object equals the given
        length. 
        """
        return _Features.StringShortRealFeatures_have_same_length(*args)

    def embed_features(*args):
        """embed_features(self, p_order)"""
        return _Features.StringShortRealFeatures_embed_features(*args)

    def compute_symbol_mask_table(*args):
        """compute_symbol_mask_table(self, max_val)"""
        return _Features.StringShortRealFeatures_compute_symbol_mask_table(*args)

    def unembed_word(*args):
        """unembed_word(self, word, seq, len)"""
        return _Features.StringShortRealFeatures_unembed_word(*args)

    def embed_word(*args):
        """embed_word(self, seq, len) -> float"""
        return _Features.StringShortRealFeatures_embed_word(*args)

    def determine_maximum_string_length(*args):
        """
        determine_maximum_string_length(self)

        determine new maximum string length 
        """
        return _Features.StringShortRealFeatures_determine_maximum_string_length(*args)

    def get_zero_terminated_string_copy(*args):
        """get_zero_terminated_string_copy(str) -> float"""
        return _Features.StringShortRealFeatures_get_zero_terminated_string_copy(*args)

    if _newclass:get_zero_terminated_string_copy = staticmethod(get_zero_terminated_string_copy)
    __swig_getmethods__["get_zero_terminated_string_copy"] = lambda x: get_zero_terminated_string_copy
    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)
        set_feature_vector(self, num, string, len)

        set feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        string:  string with the feature vector's content

        len:  length of the string 
        """
        return _Features.StringShortRealFeatures_set_feature_vector(*args)

StringShortRealFeatures_swigregister = _Features.StringShortRealFeatures_swigregister
StringShortRealFeatures_swigregister(StringShortRealFeatures)

def StringShortRealFeatures_get_zero_terminated_string_copy(*args):
  """StringShortRealFeatures_get_zero_terminated_string_copy(str) -> float"""
  return _Features.StringShortRealFeatures_get_zero_terminated_string_copy(*args)

class StringRealFeatures(Features):
    """
    Template class StringFeatures implements a list of strings.

    As this class is a template the underlying storage type is quite
    arbitrary and not limited to stracter strings, but could also be
    sequences of floating point numbers etc. Strings differ from matrices
    (cf. CSimpleFeatures) in a way that the dimensionality of the feature
    vectors (i.e. the strings) is not fixed; it may vary between strings.

    Most string kernels require StringFeatures but a number of them
    actually requires strings to have same length.

    When preprocessors are attached to string features they may shorten
    the string, but are not allowed to return strings longer than
    max_string_length, as some algorithms depend on this.

    Also note that string features cannot currently be computed on-the-
    fly.

    C++ includes: StringFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringRealFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringRealFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringRealFeatures
        __init__(self, alpha) -> StringRealFeatures
        __init__(self, p_features, alpha) -> StringRealFeatures
        __init__(self, alpha) -> StringRealFeatures
        __init__(self, orig) -> StringRealFeatures
        __init__(self, fname, alpha=DNA) -> StringRealFeatures
        __init__(self, fname) -> StringRealFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringRealFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringRealFeatures
    __del__ = lambda self : None;
    def cleanup(*args):
        """
        cleanup(self)

        cleanup string features 
        """
        return _Features.StringRealFeatures_cleanup(*args)

    def cleanup_feature_vector(*args):
        """
        cleanup_feature_vector(self, num)

        cleanup a single feature vector 
        """
        return _Features.StringRealFeatures_cleanup_feature_vector(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> Alphabet

        get alphabet used in string features

        alphabet 
        """
        return _Features.StringRealFeatures_get_alphabet(*args)

    def enable_on_the_fly_preprocessing(*args):
        """
        enable_on_the_fly_preprocessing(self)

        call this to preprocess string features upon get_feature_vector 
        """
        return _Features.StringRealFeatures_enable_on_the_fly_preprocessing(*args)

    def disable_on_the_fly_preprocessing(*args):
        """
        disable_on_the_fly_preprocessing(self)

        call this to disable on the fly feature preprocessing on
        get_feature_vector. Useful when you manually apply preprocessors. 
        """
        return _Features.StringRealFeatures_disable_on_the_fly_preprocessing(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, dst, num)
        get_feature_vector(self, num, len, dofree) -> float

        get feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        len:  length is returned by reference

        dofree:  whether returned vector must be freed by caller via
        free_feature_vector

        feature vector for sample num 
        """
        return _Features.StringRealFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.StringRealFeatures_free_feature_vector(*args)

    def get_feature(*args):
        """
        get_feature(self, vec_num, feat_num) -> float

        get feature

        Parameters:
        -----------

        vec_num:  which vector

        feat_num:  which feature

        feature 
        """
        return _Features.StringRealFeatures_get_feature(*args)

    def get_vector_length(*args):
        """
        get_vector_length(self, vec_num) ->  int

        get vector length

        Parameters:
        -----------

        vec_num:  which vector

        length of vector 
        """
        return _Features.StringRealFeatures_get_vector_length(*args)

    def get_max_vector_length(*args):
        """
        get_max_vector_length(self) ->  int

        get maximum vector length

        maximum vector/string length 
        """
        return _Features.StringRealFeatures_get_max_vector_length(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) -> floatmax_t

        get number of symbols

        Note: floatmax_t sounds weird, but LONG is not long enough

        number of symbols 
        """
        return _Features.StringRealFeatures_get_num_symbols(*args)

    def get_max_num_symbols(*args):
        """
        get_max_num_symbols(self) -> floatmax_t

        get maximum number of symbols

        Note: floatmax_t sounds weird, but int is not long enough (and
        there is no int128_t type)

        maximum number of symbols 
        """
        return _Features.StringRealFeatures_get_max_num_symbols(*args)

    def get_original_num_symbols(*args):
        """
        get_original_num_symbols(self) -> floatmax_t

        number of symbols before higher order mapping

        original number of symbols 
        """
        return _Features.StringRealFeatures_get_original_num_symbols(*args)

    def get_order(*args):
        """
        get_order(self) ->  int

        order used for higher order mapping

        order 
        """
        return _Features.StringRealFeatures_get_order(*args)

    def get_masked_symbols(*args):
        """get_masked_symbols(self, symbol, mask) -> float"""
        return _Features.StringRealFeatures_get_masked_symbols(*args)

    def shift_offset(*args):
        """shift_offset(self, offset, amount) -> float"""
        return _Features.StringRealFeatures_shift_offset(*args)

    def shift_symbol(*args):
        """shift_symbol(self, symbol, amount) -> float"""
        return _Features.StringRealFeatures_shift_symbol(*args)

    def load_dna_file(*args):
        """
        load_dna_file(self, fname, remap_to_bin=True) -> bool
        load_dna_file(self, fname) -> bool

        load DNA features from file

        Parameters:
        -----------

        fname:  filename to load from

        remap_to_bin:  if remap_to_bin

        if loading was successful 
        """
        return _Features.StringRealFeatures_load_dna_file(*args)

    def load_fasta_file(*args):
        """
        load_fasta_file(self, fname, ignore_invalid=False) -> bool
        load_fasta_file(self, fname) -> bool

        load fasta file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        if loading was successful 
        """
        return _Features.StringRealFeatures_load_fasta_file(*args)

    def load_fastq_file(*args):
        """
        load_fastq_file(self, fname, ignore_invalid=False, bitremap_in_single_string=False) -> bool
        load_fastq_file(self, fname, ignore_invalid=False) -> bool
        load_fastq_file(self, fname) -> bool

        load fastq file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        bitremap_in_single_string:  if set to true, do binary embedding of
        symbols

        if loading was successful 
        """
        return _Features.StringRealFeatures_load_fastq_file(*args)

    def load_from_directory(*args):
        """
        load_from_directory(self, dirname) -> bool

        load features from directory

        Parameters:
        -----------

        dirname:  directory name to load from

        if loading was successful 
        """
        return _Features.StringRealFeatures_load_from_directory(*args)

    def set_features(*args):
        """
        set_features(self, p_features) -> bool

        set features

        Parameters:
        -----------

        p_features:  new features

        p_num_vectors:  number of vectors

        p_max_string_length:  maximum string length

        if setting was successful 
        """
        return _Features.StringRealFeatures_set_features(*args)

    def copy_features(*args):
        """
        copy_features(self, num_str, max_str_len) -> shogun::T_STRING<(double)>

        copy_features

        Parameters:
        -----------

        num_str:  number of strings (returned)

        max_str_len:  maximal string length (returned)

        string features 
        """
        return _Features.StringRealFeatures_copy_features(*args)

    def get_features(*args):
        """
        get_features(self, num_str, max_str_len) -> shogun::T_STRING<(double)>
        get_features(self, dst)

        get_features (swig compatible)

        Parameters:
        -----------

        dst:  string features (returned)

        num_str:  number of strings (returned) 
        """
        return _Features.StringRealFeatures_get_features(*args)

    def load_compressed(*args):
        """
        load_compressed(self, src, decompress) -> bool

        load compressed features from file

        Parameters:
        -----------

        src:  filename to load from

        decompress:  whether to decompress on loading

        if loading was successful 
        """
        return _Features.StringRealFeatures_load_compressed(*args)

    def save_compressed(*args):
        """
        save_compressed(self, dest, compression, level) -> bool

        save compressed features to file

        Parameters:
        -----------

        dest:  filename to save to

        compression:  compressor to use

        level:  compression level to use (1-9)

        if saving was successful 
        """
        return _Features.StringRealFeatures_save_compressed(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.StringRealFeatures_apply_preproc(*args)

    def obtain_by_sliding_window(*args):
        """
        obtain_by_sliding_window(self, window_size, step_size, skip=0) ->  int
        obtain_by_sliding_window(self, window_size, step_size) ->  int

        slides a window of size window_size over the current single string
        step_size is the amount by which the window is shifted. creates
        (string_len-window_size)/step_size many feature obj if skip is
        nonzero, skip the first 'skip' stracters of each string

        Parameters:
        -----------

        window_size:  window size

        step_size:  step size

        skip:  skip

        something inty 
        """
        return _Features.StringRealFeatures_obtain_by_sliding_window(*args)

    def obtain_by_position_list(*args):
        """
        obtain_by_position_list(self, window_size, positions, skip=0) ->  int
        obtain_by_position_list(self, window_size, positions) ->  int

        extracts windows of size window_size from first string using the
        positions in list

        Parameters:
        -----------

        window_size:  window size

        positions:  positions

        skip:  skip

        something inty 
        """
        return _Features.StringRealFeatures_obtain_by_position_list(*args)

    def obtain_from_char(*args):
        """
        obtain_from_char(self, sf, start, p_order, gap, rev) -> bool

        obtain string features from str features

        wrapper for template method

        Parameters:
        -----------

        sf:  string features

        start:  start

        p_order:  order

        gap:  gap

        rev:  reverse

        if obtaining was successful 
        """
        return _Features.StringRealFeatures_obtain_from_char(*args)

    def have_same_length(*args):
        """
        have_same_length(self, len=-1) -> bool
        have_same_length(self) -> bool

        check if length of each vector in this feature object equals the given
        length.

        Parameters:
        -----------

        len:  vector length to check against

        if length of each vector in this feature object equals the given
        length. 
        """
        return _Features.StringRealFeatures_have_same_length(*args)

    def embed_features(*args):
        """embed_features(self, p_order)"""
        return _Features.StringRealFeatures_embed_features(*args)

    def compute_symbol_mask_table(*args):
        """compute_symbol_mask_table(self, max_val)"""
        return _Features.StringRealFeatures_compute_symbol_mask_table(*args)

    def unembed_word(*args):
        """unembed_word(self, word, seq, len)"""
        return _Features.StringRealFeatures_unembed_word(*args)

    def embed_word(*args):
        """embed_word(self, seq, len) -> float"""
        return _Features.StringRealFeatures_embed_word(*args)

    def determine_maximum_string_length(*args):
        """
        determine_maximum_string_length(self)

        determine new maximum string length 
        """
        return _Features.StringRealFeatures_determine_maximum_string_length(*args)

    def get_zero_terminated_string_copy(*args):
        """get_zero_terminated_string_copy(str) -> float"""
        return _Features.StringRealFeatures_get_zero_terminated_string_copy(*args)

    if _newclass:get_zero_terminated_string_copy = staticmethod(get_zero_terminated_string_copy)
    __swig_getmethods__["get_zero_terminated_string_copy"] = lambda x: get_zero_terminated_string_copy
    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)
        set_feature_vector(self, num, string, len)

        set feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        string:  string with the feature vector's content

        len:  length of the string 
        """
        return _Features.StringRealFeatures_set_feature_vector(*args)

StringRealFeatures_swigregister = _Features.StringRealFeatures_swigregister
StringRealFeatures_swigregister(StringRealFeatures)

def StringRealFeatures_get_zero_terminated_string_copy(*args):
  """StringRealFeatures_get_zero_terminated_string_copy(str) -> float"""
  return _Features.StringRealFeatures_get_zero_terminated_string_copy(*args)

class StringLongRealFeatures(Features):
    """
    Template class StringFeatures implements a list of strings.

    As this class is a template the underlying storage type is quite
    arbitrary and not limited to stracter strings, but could also be
    sequences of floating point numbers etc. Strings differ from matrices
    (cf. CSimpleFeatures) in a way that the dimensionality of the feature
    vectors (i.e. the strings) is not fixed; it may vary between strings.

    Most string kernels require StringFeatures but a number of them
    actually requires strings to have same length.

    When preprocessors are attached to string features they may shorten
    the string, but are not allowed to return strings longer than
    max_string_length, as some algorithms depend on this.

    Also note that string features cannot currently be computed on-the-
    fly.

    C++ includes: StringFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringLongRealFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringLongRealFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringLongRealFeatures
        __init__(self, alpha) -> StringLongRealFeatures
        __init__(self, p_features, alpha) -> StringLongRealFeatures
        __init__(self, alpha) -> StringLongRealFeatures
        __init__(self, orig) -> StringLongRealFeatures
        __init__(self, fname, alpha=DNA) -> StringLongRealFeatures
        __init__(self, fname) -> StringLongRealFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringLongRealFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringLongRealFeatures
    __del__ = lambda self : None;
    def cleanup(*args):
        """
        cleanup(self)

        cleanup string features 
        """
        return _Features.StringLongRealFeatures_cleanup(*args)

    def cleanup_feature_vector(*args):
        """
        cleanup_feature_vector(self, num)

        cleanup a single feature vector 
        """
        return _Features.StringLongRealFeatures_cleanup_feature_vector(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> Alphabet

        get alphabet used in string features

        alphabet 
        """
        return _Features.StringLongRealFeatures_get_alphabet(*args)

    def enable_on_the_fly_preprocessing(*args):
        """
        enable_on_the_fly_preprocessing(self)

        call this to preprocess string features upon get_feature_vector 
        """
        return _Features.StringLongRealFeatures_enable_on_the_fly_preprocessing(*args)

    def disable_on_the_fly_preprocessing(*args):
        """
        disable_on_the_fly_preprocessing(self)

        call this to disable on the fly feature preprocessing on
        get_feature_vector. Useful when you manually apply preprocessors. 
        """
        return _Features.StringLongRealFeatures_disable_on_the_fly_preprocessing(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, dst, num)
        get_feature_vector(self, num, len, dofree) -> long float

        get feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        len:  length is returned by reference

        dofree:  whether returned vector must be freed by caller via
        free_feature_vector

        feature vector for sample num 
        """
        return _Features.StringLongRealFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.StringLongRealFeatures_free_feature_vector(*args)

    def get_feature(*args):
        """
        get_feature(self, vec_num, feat_num) -> long float

        get feature

        Parameters:
        -----------

        vec_num:  which vector

        feat_num:  which feature

        feature 
        """
        return _Features.StringLongRealFeatures_get_feature(*args)

    def get_vector_length(*args):
        """
        get_vector_length(self, vec_num) ->  int

        get vector length

        Parameters:
        -----------

        vec_num:  which vector

        length of vector 
        """
        return _Features.StringLongRealFeatures_get_vector_length(*args)

    def get_max_vector_length(*args):
        """
        get_max_vector_length(self) ->  int

        get maximum vector length

        maximum vector/string length 
        """
        return _Features.StringLongRealFeatures_get_max_vector_length(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) -> floatmax_t

        get number of symbols

        Note: floatmax_t sounds weird, but LONG is not long enough

        number of symbols 
        """
        return _Features.StringLongRealFeatures_get_num_symbols(*args)

    def get_max_num_symbols(*args):
        """
        get_max_num_symbols(self) -> floatmax_t

        get maximum number of symbols

        Note: floatmax_t sounds weird, but int is not long enough (and
        there is no int128_t type)

        maximum number of symbols 
        """
        return _Features.StringLongRealFeatures_get_max_num_symbols(*args)

    def get_original_num_symbols(*args):
        """
        get_original_num_symbols(self) -> floatmax_t

        number of symbols before higher order mapping

        original number of symbols 
        """
        return _Features.StringLongRealFeatures_get_original_num_symbols(*args)

    def get_order(*args):
        """
        get_order(self) ->  int

        order used for higher order mapping

        order 
        """
        return _Features.StringLongRealFeatures_get_order(*args)

    def get_masked_symbols(*args):
        """get_masked_symbols(self, symbol, mask) -> long float"""
        return _Features.StringLongRealFeatures_get_masked_symbols(*args)

    def shift_offset(*args):
        """shift_offset(self, offset, amount) -> long float"""
        return _Features.StringLongRealFeatures_shift_offset(*args)

    def shift_symbol(*args):
        """shift_symbol(self, symbol, amount) -> long float"""
        return _Features.StringLongRealFeatures_shift_symbol(*args)

    def load_dna_file(*args):
        """
        load_dna_file(self, fname, remap_to_bin=True) -> bool
        load_dna_file(self, fname) -> bool

        load DNA features from file

        Parameters:
        -----------

        fname:  filename to load from

        remap_to_bin:  if remap_to_bin

        if loading was successful 
        """
        return _Features.StringLongRealFeatures_load_dna_file(*args)

    def load_fasta_file(*args):
        """
        load_fasta_file(self, fname, ignore_invalid=False) -> bool
        load_fasta_file(self, fname) -> bool

        load fasta file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        if loading was successful 
        """
        return _Features.StringLongRealFeatures_load_fasta_file(*args)

    def load_fastq_file(*args):
        """
        load_fastq_file(self, fname, ignore_invalid=False, bitremap_in_single_string=False) -> bool
        load_fastq_file(self, fname, ignore_invalid=False) -> bool
        load_fastq_file(self, fname) -> bool

        load fastq file as string features

        Parameters:
        -----------

        fname:  filename to load from

        ignore_invalid:  if set to true, stracters other than A,C,G,T are
        converted to A

        bitremap_in_single_string:  if set to true, do binary embedding of
        symbols

        if loading was successful 
        """
        return _Features.StringLongRealFeatures_load_fastq_file(*args)

    def load_from_directory(*args):
        """
        load_from_directory(self, dirname) -> bool

        load features from directory

        Parameters:
        -----------

        dirname:  directory name to load from

        if loading was successful 
        """
        return _Features.StringLongRealFeatures_load_from_directory(*args)

    def set_features(*args):
        """
        set_features(self, p_features) -> bool

        set features

        Parameters:
        -----------

        p_features:  new features

        p_num_vectors:  number of vectors

        p_max_string_length:  maximum string length

        if setting was successful 
        """
        return _Features.StringLongRealFeatures_set_features(*args)

    def copy_features(*args):
        """
        copy_features(self, num_str, max_str_len) -> shogun::T_STRING<(long float)>

        copy_features

        Parameters:
        -----------

        num_str:  number of strings (returned)

        max_str_len:  maximal string length (returned)

        string features 
        """
        return _Features.StringLongRealFeatures_copy_features(*args)

    def get_features(*args):
        """
        get_features(self, num_str, max_str_len) -> shogun::T_STRING<(long float)>
        get_features(self, dst)

        get_features (swig compatible)

        Parameters:
        -----------

        dst:  string features (returned)

        num_str:  number of strings (returned) 
        """
        return _Features.StringLongRealFeatures_get_features(*args)

    def load_compressed(*args):
        """
        load_compressed(self, src, decompress) -> bool

        load compressed features from file

        Parameters:
        -----------

        src:  filename to load from

        decompress:  whether to decompress on loading

        if loading was successful 
        """
        return _Features.StringLongRealFeatures_load_compressed(*args)

    def save_compressed(*args):
        """
        save_compressed(self, dest, compression, level) -> bool

        save compressed features to file

        Parameters:
        -----------

        dest:  filename to save to

        compression:  compressor to use

        level:  compression level to use (1-9)

        if saving was successful 
        """
        return _Features.StringLongRealFeatures_save_compressed(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.StringLongRealFeatures_apply_preproc(*args)

    def obtain_by_sliding_window(*args):
        """
        obtain_by_sliding_window(self, window_size, step_size, skip=0) ->  int
        obtain_by_sliding_window(self, window_size, step_size) ->  int

        slides a window of size window_size over the current single string
        step_size is the amount by which the window is shifted. creates
        (string_len-window_size)/step_size many feature obj if skip is
        nonzero, skip the first 'skip' stracters of each string

        Parameters:
        -----------

        window_size:  window size

        step_size:  step size

        skip:  skip

        something inty 
        """
        return _Features.StringLongRealFeatures_obtain_by_sliding_window(*args)

    def obtain_by_position_list(*args):
        """
        obtain_by_position_list(self, window_size, positions, skip=0) ->  int
        obtain_by_position_list(self, window_size, positions) ->  int

        extracts windows of size window_size from first string using the
        positions in list

        Parameters:
        -----------

        window_size:  window size

        positions:  positions

        skip:  skip

        something inty 
        """
        return _Features.StringLongRealFeatures_obtain_by_position_list(*args)

    def obtain_from_char(*args):
        """
        obtain_from_char(self, sf, start, p_order, gap, rev) -> bool

        obtain string features from str features

        wrapper for template method

        Parameters:
        -----------

        sf:  string features

        start:  start

        p_order:  order

        gap:  gap

        rev:  reverse

        if obtaining was successful 
        """
        return _Features.StringLongRealFeatures_obtain_from_char(*args)

    def have_same_length(*args):
        """
        have_same_length(self, len=-1) -> bool
        have_same_length(self) -> bool

        check if length of each vector in this feature object equals the given
        length.

        Parameters:
        -----------

        len:  vector length to check against

        if length of each vector in this feature object equals the given
        length. 
        """
        return _Features.StringLongRealFeatures_have_same_length(*args)

    def embed_features(*args):
        """embed_features(self, p_order)"""
        return _Features.StringLongRealFeatures_embed_features(*args)

    def compute_symbol_mask_table(*args):
        """compute_symbol_mask_table(self, max_val)"""
        return _Features.StringLongRealFeatures_compute_symbol_mask_table(*args)

    def unembed_word(*args):
        """unembed_word(self, word, seq, len)"""
        return _Features.StringLongRealFeatures_unembed_word(*args)

    def embed_word(*args):
        """embed_word(self, seq, len) -> long float"""
        return _Features.StringLongRealFeatures_embed_word(*args)

    def determine_maximum_string_length(*args):
        """
        determine_maximum_string_length(self)

        determine new maximum string length 
        """
        return _Features.StringLongRealFeatures_determine_maximum_string_length(*args)

    def get_zero_terminated_string_copy(*args):
        """get_zero_terminated_string_copy(str) -> long float"""
        return _Features.StringLongRealFeatures_get_zero_terminated_string_copy(*args)

    if _newclass:get_zero_terminated_string_copy = staticmethod(get_zero_terminated_string_copy)
    __swig_getmethods__["get_zero_terminated_string_copy"] = lambda x: get_zero_terminated_string_copy
    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)
        set_feature_vector(self, num, string, len)

        set feature vector for sample num

        Parameters:
        -----------

        num:  index of feature vector

        string:  string with the feature vector's content

        len:  length of the string 
        """
        return _Features.StringLongRealFeatures_set_feature_vector(*args)

StringLongRealFeatures_swigregister = _Features.StringLongRealFeatures_swigregister
StringLongRealFeatures_swigregister(StringLongRealFeatures)

def StringLongRealFeatures_get_zero_terminated_string_copy(*args):
  """StringLongRealFeatures_get_zero_terminated_string_copy(str) -> long float"""
  return _Features.StringLongRealFeatures_get_zero_terminated_string_copy(*args)

class StringFileBoolFeatures(StringBoolFeatures):
    """
    File based string features.

    StringFeatures that are file based. Underneath memory mapped files are
    used. Derived from CStringFeatures thus transparently enabling all of
    the StringFeature functionality.

    Supported file format contains one string per line, lines of variable
    length are supported and must be separated by ' '.

    C++ includes: StringFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [StringBoolFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringFileBoolFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [StringBoolFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringFileBoolFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringFileBoolFeatures
        __init__(self, fname, alpha) -> StringFileBoolFeatures

        constructor

        Parameters:
        -----------

        fname:  filename of the file containing line based features

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringFileBoolFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringFileBoolFeatures
    __del__ = lambda self : None;
StringFileBoolFeatures_swigregister = _Features.StringFileBoolFeatures_swigregister
StringFileBoolFeatures_swigregister(StringFileBoolFeatures)

class StringFileCharFeatures(StringCharFeatures):
    """
    File based string features.

    StringFeatures that are file based. Underneath memory mapped files are
    used. Derived from CStringFeatures thus transparently enabling all of
    the StringFeature functionality.

    Supported file format contains one string per line, lines of variable
    length are supported and must be separated by ' '.

    C++ includes: StringFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [StringCharFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringFileCharFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [StringCharFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringFileCharFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringFileCharFeatures
        __init__(self, fname, alpha) -> StringFileCharFeatures

        constructor

        Parameters:
        -----------

        fname:  filename of the file containing line based features

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringFileCharFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringFileCharFeatures
    __del__ = lambda self : None;
StringFileCharFeatures_swigregister = _Features.StringFileCharFeatures_swigregister
StringFileCharFeatures_swigregister(StringFileCharFeatures)

class StringFileByteFeatures(StringByteFeatures):
    """
    File based string features.

    StringFeatures that are file based. Underneath memory mapped files are
    used. Derived from CStringFeatures thus transparently enabling all of
    the StringFeature functionality.

    Supported file format contains one string per line, lines of variable
    length are supported and must be separated by ' '.

    C++ includes: StringFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [StringByteFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringFileByteFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [StringByteFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringFileByteFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringFileByteFeatures
        __init__(self, fname, alpha) -> StringFileByteFeatures

        constructor

        Parameters:
        -----------

        fname:  filename of the file containing line based features

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringFileByteFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringFileByteFeatures
    __del__ = lambda self : None;
StringFileByteFeatures_swigregister = _Features.StringFileByteFeatures_swigregister
StringFileByteFeatures_swigregister(StringFileByteFeatures)

class StringFileShortFeatures(StringShortFeatures):
    """
    File based string features.

    StringFeatures that are file based. Underneath memory mapped files are
    used. Derived from CStringFeatures thus transparently enabling all of
    the StringFeature functionality.

    Supported file format contains one string per line, lines of variable
    length are supported and must be separated by ' '.

    C++ includes: StringFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [StringShortFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringFileShortFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [StringShortFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringFileShortFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringFileShortFeatures
        __init__(self, fname, alpha) -> StringFileShortFeatures

        constructor

        Parameters:
        -----------

        fname:  filename of the file containing line based features

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringFileShortFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringFileShortFeatures
    __del__ = lambda self : None;
StringFileShortFeatures_swigregister = _Features.StringFileShortFeatures_swigregister
StringFileShortFeatures_swigregister(StringFileShortFeatures)

class StringFileWordFeatures(StringWordFeatures):
    """
    File based string features.

    StringFeatures that are file based. Underneath memory mapped files are
    used. Derived from CStringFeatures thus transparently enabling all of
    the StringFeature functionality.

    Supported file format contains one string per line, lines of variable
    length are supported and must be separated by ' '.

    C++ includes: StringFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [StringWordFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringFileWordFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [StringWordFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringFileWordFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringFileWordFeatures
        __init__(self, fname, alpha) -> StringFileWordFeatures

        constructor

        Parameters:
        -----------

        fname:  filename of the file containing line based features

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringFileWordFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringFileWordFeatures
    __del__ = lambda self : None;
StringFileWordFeatures_swigregister = _Features.StringFileWordFeatures_swigregister
StringFileWordFeatures_swigregister(StringFileWordFeatures)

class StringFileIntFeatures(StringIntFeatures):
    """
    File based string features.

    StringFeatures that are file based. Underneath memory mapped files are
    used. Derived from CStringFeatures thus transparently enabling all of
    the StringFeature functionality.

    Supported file format contains one string per line, lines of variable
    length are supported and must be separated by ' '.

    C++ includes: StringFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [StringIntFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringFileIntFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [StringIntFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringFileIntFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringFileIntFeatures
        __init__(self, fname, alpha) -> StringFileIntFeatures

        constructor

        Parameters:
        -----------

        fname:  filename of the file containing line based features

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringFileIntFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringFileIntFeatures
    __del__ = lambda self : None;
StringFileIntFeatures_swigregister = _Features.StringFileIntFeatures_swigregister
StringFileIntFeatures_swigregister(StringFileIntFeatures)

class StringFileUIntFeatures(StringUIntFeatures):
    """
    File based string features.

    StringFeatures that are file based. Underneath memory mapped files are
    used. Derived from CStringFeatures thus transparently enabling all of
    the StringFeature functionality.

    Supported file format contains one string per line, lines of variable
    length are supported and must be separated by ' '.

    C++ includes: StringFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [StringUIntFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringFileUIntFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [StringUIntFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringFileUIntFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringFileUIntFeatures
        __init__(self, fname, alpha) -> StringFileUIntFeatures

        constructor

        Parameters:
        -----------

        fname:  filename of the file containing line based features

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringFileUIntFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringFileUIntFeatures
    __del__ = lambda self : None;
StringFileUIntFeatures_swigregister = _Features.StringFileUIntFeatures_swigregister
StringFileUIntFeatures_swigregister(StringFileUIntFeatures)

class StringFileLongFeatures(StringLongFeatures):
    """
    File based string features.

    StringFeatures that are file based. Underneath memory mapped files are
    used. Derived from CStringFeatures thus transparently enabling all of
    the StringFeature functionality.

    Supported file format contains one string per line, lines of variable
    length are supported and must be separated by ' '.

    C++ includes: StringFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [StringLongFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringFileLongFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [StringLongFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringFileLongFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringFileLongFeatures
        __init__(self, fname, alpha) -> StringFileLongFeatures

        constructor

        Parameters:
        -----------

        fname:  filename of the file containing line based features

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringFileLongFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringFileLongFeatures
    __del__ = lambda self : None;
StringFileLongFeatures_swigregister = _Features.StringFileLongFeatures_swigregister
StringFileLongFeatures_swigregister(StringFileLongFeatures)

class StringFileUlongFeatures(StringUlongFeatures):
    """
    File based string features.

    StringFeatures that are file based. Underneath memory mapped files are
    used. Derived from CStringFeatures thus transparently enabling all of
    the StringFeature functionality.

    Supported file format contains one string per line, lines of variable
    length are supported and must be separated by ' '.

    C++ includes: StringFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [StringUlongFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringFileUlongFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [StringUlongFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringFileUlongFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringFileUlongFeatures
        __init__(self, fname, alpha) -> StringFileUlongFeatures

        constructor

        Parameters:
        -----------

        fname:  filename of the file containing line based features

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringFileUlongFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringFileUlongFeatures
    __del__ = lambda self : None;
StringFileUlongFeatures_swigregister = _Features.StringFileUlongFeatures_swigregister
StringFileUlongFeatures_swigregister(StringFileUlongFeatures)

class StringFileShortRealFeatures(StringShortRealFeatures):
    """
    File based string features.

    StringFeatures that are file based. Underneath memory mapped files are
    used. Derived from CStringFeatures thus transparently enabling all of
    the StringFeature functionality.

    Supported file format contains one string per line, lines of variable
    length are supported and must be separated by ' '.

    C++ includes: StringFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [StringShortRealFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringFileShortRealFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [StringShortRealFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringFileShortRealFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringFileShortRealFeatures
        __init__(self, fname, alpha) -> StringFileShortRealFeatures

        constructor

        Parameters:
        -----------

        fname:  filename of the file containing line based features

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringFileShortRealFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringFileShortRealFeatures
    __del__ = lambda self : None;
StringFileShortRealFeatures_swigregister = _Features.StringFileShortRealFeatures_swigregister
StringFileShortRealFeatures_swigregister(StringFileShortRealFeatures)

class StringFileRealFeatures(StringRealFeatures):
    """
    File based string features.

    StringFeatures that are file based. Underneath memory mapped files are
    used. Derived from CStringFeatures thus transparently enabling all of
    the StringFeature functionality.

    Supported file format contains one string per line, lines of variable
    length are supported and must be separated by ' '.

    C++ includes: StringFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [StringRealFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringFileRealFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [StringRealFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringFileRealFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringFileRealFeatures
        __init__(self, fname, alpha) -> StringFileRealFeatures

        constructor

        Parameters:
        -----------

        fname:  filename of the file containing line based features

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringFileRealFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringFileRealFeatures
    __del__ = lambda self : None;
StringFileRealFeatures_swigregister = _Features.StringFileRealFeatures_swigregister
StringFileRealFeatures_swigregister(StringFileRealFeatures)

class StringFileLongRealFeatures(StringLongRealFeatures):
    """
    File based string features.

    StringFeatures that are file based. Underneath memory mapped files are
    used. Derived from CStringFeatures thus transparently enabling all of
    the StringFeature functionality.

    Supported file format contains one string per line, lines of variable
    length are supported and must be separated by ' '.

    C++ includes: StringFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [StringLongRealFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringFileLongRealFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [StringLongRealFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, StringFileLongRealFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> StringFileLongRealFeatures
        __init__(self, fname, alpha) -> StringFileLongRealFeatures

        constructor

        Parameters:
        -----------

        fname:  filename of the file containing line based features

        alpha:  alphabet (type) to use for string features 
        """
        this = _Features.new_StringFileLongRealFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_StringFileLongRealFeatures
    __del__ = lambda self : None;
StringFileLongRealFeatures_swigregister = _Features.StringFileLongRealFeatures_swigregister
StringFileLongRealFeatures_swigregister(StringFileLongRealFeatures)

class SparseBoolFeatures(DotFeatures):
    """
    Template class SparseFeatures implements sparse matrices.

    Features are an array of TSparse, sorted w.r.t. vec_index (increasing)
    and withing same vec_index w.r.t. feat_index (increasing);

    Sparse feature vectors can be accessed via get_sparse_feature_vector()
    and should be freed (this operation is a NOP in most cases) via
    free_sparse_feature_vector().

    As this is a template class it can directly be used for different data
    types like sparse matrices of real valued, integer, byte etc type.

    C++ includes: SparseFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, SparseBoolFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, SparseBoolFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> SparseBoolFeatures
        __init__(self) -> SparseBoolFeatures
        __init__(self, src, copy=False) -> SparseBoolFeatures
        __init__(self, src) -> SparseBoolFeatures
        __init__(self, src) -> SparseBoolFeatures
        __init__(self, orig) -> SparseBoolFeatures
        __init__(self, fname) -> SparseBoolFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_SparseBoolFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_SparseBoolFeatures
    __del__ = lambda self : None;
    def free_sparse_feature_matrix(*args):
        """
        free_sparse_feature_matrix(self)

        free sparse feature matrix 
        """
        return _Features.SparseBoolFeatures_free_sparse_feature_matrix(*args)

    def free_sparse_features(*args):
        """
        free_sparse_features(self)

        free sparse feature matrix and cache 
        """
        return _Features.SparseBoolFeatures_free_sparse_features(*args)

    def get_feature(*args):
        """
        get_feature(self, num, index) -> bool

        get a single feature

        Parameters:
        -----------

        num:  number of feature vector to retrieve

        index:  index of feature in this vector

        sum of features that match dimension index and 0 if none is found 
        """
        return _Features.SparseBoolFeatures_get_feature(*args)

    def get_full_feature_vector(*args):
        """
        get_full_feature_vector(self, num, len) -> bool
        get_full_feature_vector(self, dst, num)

        get the fully expanded dense feature vector num

        Parameters:
        -----------

        dst:  feature vector

        len:  length is returned by reference

        num:  index of feature vector 
        """
        return _Features.SparseBoolFeatures_get_full_feature_vector(*args)

    def get_sparse_feature_vector(*args):
        """
        get_sparse_feature_vector(self, num, len, vfree) -> shogun::TSparseEntry<(bool)>

        get sparse feature vector for sample num from the matrix as it is if
        matrix is initialized, else return preprocessed compute_feature_vector

        Parameters:
        -----------

        num:  index of feature vector

        len:  number of sparse entries is returned by reference

        vfree:  whether returned vector must be freed by caller via
        free_sparse_feature_vector

        sparse feature vector 
        """
        return _Features.SparseBoolFeatures_get_sparse_feature_vector(*args)

    def sparse_dot(*args):
        """
        sparse_dot(self, alpha, avec, alen, bvec, blen) -> bool

        compute the dot product between two sparse feature vectors alpha *
        vec^T * vec

        Parameters:
        -----------

        alpha:  scalar to multiply with

        avec:  first sparse feature vector

        alen:  avec's length

        bvec:  second sparse feature vector

        blen:  bvec's length

        dot product between the two sparse feature vectors 
        """
        return _Features.SparseBoolFeatures_sparse_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, num, vec, dim, abs_val=False)
        add_to_dense_vec(self, alpha, num, vec, dim)

        add a sparse feature vector onto a dense one dense+=alpha*sparse

        Parameters:
        -----------

        alpha:  scalar to multiply with

        num:  index of feature vector

        vec:  dense vector

        dim:  length of the dense vector

        abs_val:  if true, do dense+=alpha*abs(sparse) 
        """
        return _Features.SparseBoolFeatures_add_to_dense_vec(*args)

    def free_sparse_feature_vector(*args):
        """
        free_sparse_feature_vector(self, feat_vec, num, free)

        free sparse feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of this vector in the cache

        free:  if vector should be really deleted 
        """
        return _Features.SparseBoolFeatures_free_sparse_feature_vector(*args)

    def get_sparse_feature_matrix(*args):
        """
        get_sparse_feature_matrix(self, num_feat, num_vec) -> shogun::TSparse<(bool)>
        get_sparse_feature_matrix(self, dst)

        get the pointer to the sparse feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        nnz:  number of nonzero elements 
        """
        return _Features.SparseBoolFeatures_get_sparse_feature_matrix(*args)

    def clean_tsparse(*args):
        """
        clean_tsparse(self, sfm, num_vec)

        clean TSparse

        Parameters:
        -----------

        sfm:  sparse feature matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseBoolFeatures_clean_tsparse(*args)

    def get_transposed(*args):
        """
        get_transposed(self, num_feat, num_vec) -> shogun::TSparse<(bool)>

        compute and return the transpose of the sparse feature matrix which
        will be prepocessed. num_feat, num_vectors are returned by reference
        caller has to clean up

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        transposed sparse feature matrix 
        """
        return _Features.SparseBoolFeatures_get_transposed(*args)

    def set_sparse_feature_matrix(*args):
        """
        set_sparse_feature_matrix(self, src)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        src:  new sparse feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseBoolFeatures_set_sparse_feature_matrix(*args)

    def get_full_feature_matrix(*args):
        """
        get_full_feature_matrix(self, num_feat, num_vec) -> bool
        get_full_feature_matrix(self, dst)

        gets a copy of a full feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseBoolFeatures_get_full_feature_matrix(*args)

    def set_full_feature_matrix(*args):
        """
        set_full_feature_matrix(self, src) -> bool

        creates a sparse feature matrix from a full dense feature matrix
        necessary to set feature_matrix, num_features and num_vectors where
        num_features is the column offset, and columns are linear in memory
        see above for definition of sparse_feature_matrix

        Parameters:
        -----------

        src:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseBoolFeatures_set_full_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.SparseBoolFeatures_apply_preproc(*args)

    def obtain_from_simple(*args):
        """
        obtain_from_simple(self, sf) -> bool

        obtain sparse features from simple features

        Parameters:
        -----------

        sf:  simple features

        if obtaining was successful 
        """
        return _Features.SparseBoolFeatures_obtain_from_simple(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.SparseBoolFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num) ->  int

        set number of features

        Sometimes when loading sparse features not all possible dimensions are
        used. This may pose a problem to classifiers when being applied to
        higher dimensional test-data. This function allows to artificially
        explode the feature space

        Parameters:
        -----------

        num:  the number of features, must be larger than the current number
        of features

        previous number of features 
        """
        return _Features.SparseBoolFeatures_set_num_features(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, free)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of vector in cache

        free:  if vector really should be deleted 
        """
        return _Features.SparseBoolFeatures_free_feature_vector(*args)

    def get_num_nonzero_entries(*args):
        """
        get_num_nonzero_entries(self) -> int

        get number of non-zero entries in sparse feature matrix

        number of non-zero entries in sparse feature matrix 
        """
        return _Features.SparseBoolFeatures_get_num_nonzero_entries(*args)

    def compute_squared(*args):
        """
        compute_squared(self, sq) -> float

        compute a^2 on all feature vectors

        Parameters:
        -----------

        sq:  the square for each vector is stored in here

        the square for each vector 
        """
        return _Features.SparseBoolFeatures_compute_squared(*args)

    def compute_squared_norm(*args):
        """
        compute_squared_norm(self, lhs, sq_lhs, idx_a, rhs, sq_rhs, idx_b) -> float

        compute (a-b)^2 (== a^2+b^2+2ab) usually called by kernels'/distances'
        compute functions works on two feature vectors, although it is a
        member of a single feature: can either be called by lhs or rhs.

        Parameters:
        -----------

        lhs:  left-hand side features

        sq_lhs:  squared values of left-hand side

        idx_a:  index of left-hand side's vector to compute

        rhs:  right-hand side features

        sq_rhs:  squared values of right-hand side

        idx_b:  index of right-hand side's vector to compute 
        """
        return _Features.SparseBoolFeatures_compute_squared_norm(*args)

    def load_svmlight_file(*args):
        """
        load_svmlight_file(self, fname, do_sort_features=True) -> Labels
        load_svmlight_file(self, fname) -> Labels

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        do_sort_features:  if true features will be sorted to ensure they are
        in ascending order

        label object with corresponding labels 
        """
        return _Features.SparseBoolFeatures_load_svmlight_file(*args)

    def sort_features(*args):
        """
        sort_features(self)

        ensure that features occur in ascending order, only call when no
        preprocessors are attached 
        """
        return _Features.SparseBoolFeatures_sort_features(*args)

    def write_svmlight_file(*args):
        """
        write_svmlight_file(self, fname, label) -> bool

        write features to file using svm light format

        Parameters:
        -----------

        fname:  filename to write to

        label:  Label object (number of labels must correspond to number of
        features)

        true if successful 
        """
        return _Features.SparseBoolFeatures_write_svmlight_file(*args)

    def dense_dot(*args):
        """
        dense_dot(self, alpha, num, vec, dim, b) -> bool
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.SparseBoolFeatures_dense_dot(*args)

SparseBoolFeatures_swigregister = _Features.SparseBoolFeatures_swigregister
SparseBoolFeatures_swigregister(SparseBoolFeatures)

class SparseCharFeatures(DotFeatures):
    """
    Template class SparseFeatures implements sparse matrices.

    Features are an array of TSparse, sorted w.r.t. vec_index (increasing)
    and withing same vec_index w.r.t. feat_index (increasing);

    Sparse feature vectors can be accessed via get_sparse_feature_vector()
    and should be freed (this operation is a NOP in most cases) via
    free_sparse_feature_vector().

    As this is a template class it can directly be used for different data
    types like sparse matrices of real valued, integer, byte etc type.

    C++ includes: SparseFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, SparseCharFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, SparseCharFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> SparseCharFeatures
        __init__(self) -> SparseCharFeatures
        __init__(self, src, copy=False) -> SparseCharFeatures
        __init__(self, src) -> SparseCharFeatures
        __init__(self, src) -> SparseCharFeatures
        __init__(self, orig) -> SparseCharFeatures
        __init__(self, fname) -> SparseCharFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_SparseCharFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_SparseCharFeatures
    __del__ = lambda self : None;
    def free_sparse_feature_matrix(*args):
        """
        free_sparse_feature_matrix(self)

        free sparse feature matrix 
        """
        return _Features.SparseCharFeatures_free_sparse_feature_matrix(*args)

    def free_sparse_features(*args):
        """
        free_sparse_features(self)

        free sparse feature matrix and cache 
        """
        return _Features.SparseCharFeatures_free_sparse_features(*args)

    def get_feature(*args):
        """
        get_feature(self, num, index) -> str

        get a single feature

        Parameters:
        -----------

        num:  number of feature vector to retrieve

        index:  index of feature in this vector

        sum of features that match dimension index and 0 if none is found 
        """
        return _Features.SparseCharFeatures_get_feature(*args)

    def get_full_feature_vector(*args):
        """
        get_full_feature_vector(self, num, len) -> str
        get_full_feature_vector(self, dst, num)

        get the fully expanded dense feature vector num

        Parameters:
        -----------

        dst:  feature vector

        len:  length is returned by reference

        num:  index of feature vector 
        """
        return _Features.SparseCharFeatures_get_full_feature_vector(*args)

    def get_sparse_feature_vector(*args):
        """
        get_sparse_feature_vector(self, num, len, vfree) -> shogun::TSparseEntry<(char)>

        get sparse feature vector for sample num from the matrix as it is if
        matrix is initialized, else return preprocessed compute_feature_vector

        Parameters:
        -----------

        num:  index of feature vector

        len:  number of sparse entries is returned by reference

        vfree:  whether returned vector must be freed by caller via
        free_sparse_feature_vector

        sparse feature vector 
        """
        return _Features.SparseCharFeatures_get_sparse_feature_vector(*args)

    def sparse_dot(*args):
        """
        sparse_dot(self, alpha, avec, alen, bvec, blen) -> str

        compute the dot product between two sparse feature vectors alpha *
        vec^T * vec

        Parameters:
        -----------

        alpha:  scalar to multiply with

        avec:  first sparse feature vector

        alen:  avec's length

        bvec:  second sparse feature vector

        blen:  bvec's length

        dot product between the two sparse feature vectors 
        """
        return _Features.SparseCharFeatures_sparse_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, num, vec, dim, abs_val=False)
        add_to_dense_vec(self, alpha, num, vec, dim)

        add a sparse feature vector onto a dense one dense+=alpha*sparse

        Parameters:
        -----------

        alpha:  scalar to multiply with

        num:  index of feature vector

        vec:  dense vector

        dim:  length of the dense vector

        abs_val:  if true, do dense+=alpha*abs(sparse) 
        """
        return _Features.SparseCharFeatures_add_to_dense_vec(*args)

    def free_sparse_feature_vector(*args):
        """
        free_sparse_feature_vector(self, feat_vec, num, free)

        free sparse feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of this vector in the cache

        free:  if vector should be really deleted 
        """
        return _Features.SparseCharFeatures_free_sparse_feature_vector(*args)

    def get_sparse_feature_matrix(*args):
        """
        get_sparse_feature_matrix(self, num_feat, num_vec) -> shogun::TSparse<(char)>
        get_sparse_feature_matrix(self, dst)

        get the pointer to the sparse feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        nnz:  number of nonzero elements 
        """
        return _Features.SparseCharFeatures_get_sparse_feature_matrix(*args)

    def clean_tsparse(*args):
        """
        clean_tsparse(self, sfm, num_vec)

        clean TSparse

        Parameters:
        -----------

        sfm:  sparse feature matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseCharFeatures_clean_tsparse(*args)

    def get_transposed(*args):
        """
        get_transposed(self, num_feat, num_vec) -> shogun::TSparse<(char)>

        compute and return the transpose of the sparse feature matrix which
        will be prepocessed. num_feat, num_vectors are returned by reference
        caller has to clean up

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        transposed sparse feature matrix 
        """
        return _Features.SparseCharFeatures_get_transposed(*args)

    def set_sparse_feature_matrix(*args):
        """
        set_sparse_feature_matrix(self, src)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        src:  new sparse feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseCharFeatures_set_sparse_feature_matrix(*args)

    def get_full_feature_matrix(*args):
        """
        get_full_feature_matrix(self, num_feat, num_vec) -> str
        get_full_feature_matrix(self, dst)

        gets a copy of a full feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseCharFeatures_get_full_feature_matrix(*args)

    def set_full_feature_matrix(*args):
        """
        set_full_feature_matrix(self, src) -> bool

        creates a sparse feature matrix from a full dense feature matrix
        necessary to set feature_matrix, num_features and num_vectors where
        num_features is the column offset, and columns are linear in memory
        see above for definition of sparse_feature_matrix

        Parameters:
        -----------

        src:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseCharFeatures_set_full_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.SparseCharFeatures_apply_preproc(*args)

    def obtain_from_simple(*args):
        """
        obtain_from_simple(self, sf) -> bool

        obtain sparse features from simple features

        Parameters:
        -----------

        sf:  simple features

        if obtaining was successful 
        """
        return _Features.SparseCharFeatures_obtain_from_simple(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.SparseCharFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num) ->  int

        set number of features

        Sometimes when loading sparse features not all possible dimensions are
        used. This may pose a problem to classifiers when being applied to
        higher dimensional test-data. This function allows to artificially
        explode the feature space

        Parameters:
        -----------

        num:  the number of features, must be larger than the current number
        of features

        previous number of features 
        """
        return _Features.SparseCharFeatures_set_num_features(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, free)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of vector in cache

        free:  if vector really should be deleted 
        """
        return _Features.SparseCharFeatures_free_feature_vector(*args)

    def get_num_nonzero_entries(*args):
        """
        get_num_nonzero_entries(self) -> int

        get number of non-zero entries in sparse feature matrix

        number of non-zero entries in sparse feature matrix 
        """
        return _Features.SparseCharFeatures_get_num_nonzero_entries(*args)

    def compute_squared(*args):
        """
        compute_squared(self, sq) -> float

        compute a^2 on all feature vectors

        Parameters:
        -----------

        sq:  the square for each vector is stored in here

        the square for each vector 
        """
        return _Features.SparseCharFeatures_compute_squared(*args)

    def compute_squared_norm(*args):
        """
        compute_squared_norm(self, lhs, sq_lhs, idx_a, rhs, sq_rhs, idx_b) -> float

        compute (a-b)^2 (== a^2+b^2+2ab) usually called by kernels'/distances'
        compute functions works on two feature vectors, although it is a
        member of a single feature: can either be called by lhs or rhs.

        Parameters:
        -----------

        lhs:  left-hand side features

        sq_lhs:  squared values of left-hand side

        idx_a:  index of left-hand side's vector to compute

        rhs:  right-hand side features

        sq_rhs:  squared values of right-hand side

        idx_b:  index of right-hand side's vector to compute 
        """
        return _Features.SparseCharFeatures_compute_squared_norm(*args)

    def load_svmlight_file(*args):
        """
        load_svmlight_file(self, fname, do_sort_features=True) -> Labels
        load_svmlight_file(self, fname) -> Labels

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        do_sort_features:  if true features will be sorted to ensure they are
        in ascending order

        label object with corresponding labels 
        """
        return _Features.SparseCharFeatures_load_svmlight_file(*args)

    def sort_features(*args):
        """
        sort_features(self)

        ensure that features occur in ascending order, only call when no
        preprocessors are attached 
        """
        return _Features.SparseCharFeatures_sort_features(*args)

    def write_svmlight_file(*args):
        """
        write_svmlight_file(self, fname, label) -> bool

        write features to file using svm light format

        Parameters:
        -----------

        fname:  filename to write to

        label:  Label object (number of labels must correspond to number of
        features)

        true if successful 
        """
        return _Features.SparseCharFeatures_write_svmlight_file(*args)

    def dense_dot(*args):
        """
        dense_dot(self, alpha, num, vec, dim, b) -> str
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.SparseCharFeatures_dense_dot(*args)

SparseCharFeatures_swigregister = _Features.SparseCharFeatures_swigregister
SparseCharFeatures_swigregister(SparseCharFeatures)

class SparseByteFeatures(DotFeatures):
    """
    Template class SparseFeatures implements sparse matrices.

    Features are an array of TSparse, sorted w.r.t. vec_index (increasing)
    and withing same vec_index w.r.t. feat_index (increasing);

    Sparse feature vectors can be accessed via get_sparse_feature_vector()
    and should be freed (this operation is a NOP in most cases) via
    free_sparse_feature_vector().

    As this is a template class it can directly be used for different data
    types like sparse matrices of real valued, integer, byte etc type.

    C++ includes: SparseFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, SparseByteFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, SparseByteFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> SparseByteFeatures
        __init__(self) -> SparseByteFeatures
        __init__(self, src, copy=False) -> SparseByteFeatures
        __init__(self, src) -> SparseByteFeatures
        __init__(self, src) -> SparseByteFeatures
        __init__(self, orig) -> SparseByteFeatures
        __init__(self, fname) -> SparseByteFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_SparseByteFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_SparseByteFeatures
    __del__ = lambda self : None;
    def free_sparse_feature_matrix(*args):
        """
        free_sparse_feature_matrix(self)

        free sparse feature matrix 
        """
        return _Features.SparseByteFeatures_free_sparse_feature_matrix(*args)

    def free_sparse_features(*args):
        """
        free_sparse_features(self)

        free sparse feature matrix and cache 
        """
        return _Features.SparseByteFeatures_free_sparse_features(*args)

    def get_feature(*args):
        """
        get_feature(self, num, index) -> unsigned str

        get a single feature

        Parameters:
        -----------

        num:  number of feature vector to retrieve

        index:  index of feature in this vector

        sum of features that match dimension index and 0 if none is found 
        """
        return _Features.SparseByteFeatures_get_feature(*args)

    def get_full_feature_vector(*args):
        """
        get_full_feature_vector(self, num, len) -> unsigned str
        get_full_feature_vector(self, dst, num)

        get the fully expanded dense feature vector num

        Parameters:
        -----------

        dst:  feature vector

        len:  length is returned by reference

        num:  index of feature vector 
        """
        return _Features.SparseByteFeatures_get_full_feature_vector(*args)

    def get_sparse_feature_vector(*args):
        """
        get_sparse_feature_vector(self, num, len, vfree) -> shogun::TSparseEntry<(unsigned str)>

        get sparse feature vector for sample num from the matrix as it is if
        matrix is initialized, else return preprocessed compute_feature_vector

        Parameters:
        -----------

        num:  index of feature vector

        len:  number of sparse entries is returned by reference

        vfree:  whether returned vector must be freed by caller via
        free_sparse_feature_vector

        sparse feature vector 
        """
        return _Features.SparseByteFeatures_get_sparse_feature_vector(*args)

    def sparse_dot(*args):
        """
        sparse_dot(self, alpha, avec, alen, bvec, blen) -> unsigned str

        compute the dot product between two sparse feature vectors alpha *
        vec^T * vec

        Parameters:
        -----------

        alpha:  scalar to multiply with

        avec:  first sparse feature vector

        alen:  avec's length

        bvec:  second sparse feature vector

        blen:  bvec's length

        dot product between the two sparse feature vectors 
        """
        return _Features.SparseByteFeatures_sparse_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, num, vec, dim, abs_val=False)
        add_to_dense_vec(self, alpha, num, vec, dim)

        add a sparse feature vector onto a dense one dense+=alpha*sparse

        Parameters:
        -----------

        alpha:  scalar to multiply with

        num:  index of feature vector

        vec:  dense vector

        dim:  length of the dense vector

        abs_val:  if true, do dense+=alpha*abs(sparse) 
        """
        return _Features.SparseByteFeatures_add_to_dense_vec(*args)

    def free_sparse_feature_vector(*args):
        """
        free_sparse_feature_vector(self, feat_vec, num, free)

        free sparse feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of this vector in the cache

        free:  if vector should be really deleted 
        """
        return _Features.SparseByteFeatures_free_sparse_feature_vector(*args)

    def get_sparse_feature_matrix(*args):
        """
        get_sparse_feature_matrix(self, num_feat, num_vec) -> shogun::TSparse<(unsigned str)>
        get_sparse_feature_matrix(self, dst)

        get the pointer to the sparse feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        nnz:  number of nonzero elements 
        """
        return _Features.SparseByteFeatures_get_sparse_feature_matrix(*args)

    def clean_tsparse(*args):
        """
        clean_tsparse(self, sfm, num_vec)

        clean TSparse

        Parameters:
        -----------

        sfm:  sparse feature matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseByteFeatures_clean_tsparse(*args)

    def get_transposed(*args):
        """
        get_transposed(self, num_feat, num_vec) -> shogun::TSparse<(unsigned str)>

        compute and return the transpose of the sparse feature matrix which
        will be prepocessed. num_feat, num_vectors are returned by reference
        caller has to clean up

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        transposed sparse feature matrix 
        """
        return _Features.SparseByteFeatures_get_transposed(*args)

    def set_sparse_feature_matrix(*args):
        """
        set_sparse_feature_matrix(self, src)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        src:  new sparse feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseByteFeatures_set_sparse_feature_matrix(*args)

    def get_full_feature_matrix(*args):
        """
        get_full_feature_matrix(self, num_feat, num_vec) -> unsigned str
        get_full_feature_matrix(self, dst)

        gets a copy of a full feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseByteFeatures_get_full_feature_matrix(*args)

    def set_full_feature_matrix(*args):
        """
        set_full_feature_matrix(self, src) -> bool

        creates a sparse feature matrix from a full dense feature matrix
        necessary to set feature_matrix, num_features and num_vectors where
        num_features is the column offset, and columns are linear in memory
        see above for definition of sparse_feature_matrix

        Parameters:
        -----------

        src:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseByteFeatures_set_full_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.SparseByteFeatures_apply_preproc(*args)

    def obtain_from_simple(*args):
        """
        obtain_from_simple(self, sf) -> bool

        obtain sparse features from simple features

        Parameters:
        -----------

        sf:  simple features

        if obtaining was successful 
        """
        return _Features.SparseByteFeatures_obtain_from_simple(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.SparseByteFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num) ->  int

        set number of features

        Sometimes when loading sparse features not all possible dimensions are
        used. This may pose a problem to classifiers when being applied to
        higher dimensional test-data. This function allows to artificially
        explode the feature space

        Parameters:
        -----------

        num:  the number of features, must be larger than the current number
        of features

        previous number of features 
        """
        return _Features.SparseByteFeatures_set_num_features(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, free)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of vector in cache

        free:  if vector really should be deleted 
        """
        return _Features.SparseByteFeatures_free_feature_vector(*args)

    def get_num_nonzero_entries(*args):
        """
        get_num_nonzero_entries(self) -> int

        get number of non-zero entries in sparse feature matrix

        number of non-zero entries in sparse feature matrix 
        """
        return _Features.SparseByteFeatures_get_num_nonzero_entries(*args)

    def compute_squared(*args):
        """
        compute_squared(self, sq) -> float

        compute a^2 on all feature vectors

        Parameters:
        -----------

        sq:  the square for each vector is stored in here

        the square for each vector 
        """
        return _Features.SparseByteFeatures_compute_squared(*args)

    def compute_squared_norm(*args):
        """
        compute_squared_norm(self, lhs, sq_lhs, idx_a, rhs, sq_rhs, idx_b) -> float

        compute (a-b)^2 (== a^2+b^2+2ab) usually called by kernels'/distances'
        compute functions works on two feature vectors, although it is a
        member of a single feature: can either be called by lhs or rhs.

        Parameters:
        -----------

        lhs:  left-hand side features

        sq_lhs:  squared values of left-hand side

        idx_a:  index of left-hand side's vector to compute

        rhs:  right-hand side features

        sq_rhs:  squared values of right-hand side

        idx_b:  index of right-hand side's vector to compute 
        """
        return _Features.SparseByteFeatures_compute_squared_norm(*args)

    def load_svmlight_file(*args):
        """
        load_svmlight_file(self, fname, do_sort_features=True) -> Labels
        load_svmlight_file(self, fname) -> Labels

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        do_sort_features:  if true features will be sorted to ensure they are
        in ascending order

        label object with corresponding labels 
        """
        return _Features.SparseByteFeatures_load_svmlight_file(*args)

    def sort_features(*args):
        """
        sort_features(self)

        ensure that features occur in ascending order, only call when no
        preprocessors are attached 
        """
        return _Features.SparseByteFeatures_sort_features(*args)

    def write_svmlight_file(*args):
        """
        write_svmlight_file(self, fname, label) -> bool

        write features to file using svm light format

        Parameters:
        -----------

        fname:  filename to write to

        label:  Label object (number of labels must correspond to number of
        features)

        true if successful 
        """
        return _Features.SparseByteFeatures_write_svmlight_file(*args)

    def dense_dot(*args):
        """
        dense_dot(self, alpha, num, vec, dim, b) -> unsigned str
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.SparseByteFeatures_dense_dot(*args)

SparseByteFeatures_swigregister = _Features.SparseByteFeatures_swigregister
SparseByteFeatures_swigregister(SparseByteFeatures)

class SparseShortFeatures(DotFeatures):
    """
    Template class SparseFeatures implements sparse matrices.

    Features are an array of TSparse, sorted w.r.t. vec_index (increasing)
    and withing same vec_index w.r.t. feat_index (increasing);

    Sparse feature vectors can be accessed via get_sparse_feature_vector()
    and should be freed (this operation is a NOP in most cases) via
    free_sparse_feature_vector().

    As this is a template class it can directly be used for different data
    types like sparse matrices of real valued, integer, byte etc type.

    C++ includes: SparseFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, SparseShortFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, SparseShortFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> SparseShortFeatures
        __init__(self) -> SparseShortFeatures
        __init__(self, src, copy=False) -> SparseShortFeatures
        __init__(self, src) -> SparseShortFeatures
        __init__(self, src) -> SparseShortFeatures
        __init__(self, orig) -> SparseShortFeatures
        __init__(self, fname) -> SparseShortFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_SparseShortFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_SparseShortFeatures
    __del__ = lambda self : None;
    def free_sparse_feature_matrix(*args):
        """
        free_sparse_feature_matrix(self)

        free sparse feature matrix 
        """
        return _Features.SparseShortFeatures_free_sparse_feature_matrix(*args)

    def free_sparse_features(*args):
        """
        free_sparse_features(self)

        free sparse feature matrix and cache 
        """
        return _Features.SparseShortFeatures_free_sparse_features(*args)

    def get_feature(*args):
        """
        get_feature(self, num, index) -> short

        get a single feature

        Parameters:
        -----------

        num:  number of feature vector to retrieve

        index:  index of feature in this vector

        sum of features that match dimension index and 0 if none is found 
        """
        return _Features.SparseShortFeatures_get_feature(*args)

    def get_full_feature_vector(*args):
        """
        get_full_feature_vector(self, num, len) -> short
        get_full_feature_vector(self, dst, num)

        get the fully expanded dense feature vector num

        Parameters:
        -----------

        dst:  feature vector

        len:  length is returned by reference

        num:  index of feature vector 
        """
        return _Features.SparseShortFeatures_get_full_feature_vector(*args)

    def get_sparse_feature_vector(*args):
        """
        get_sparse_feature_vector(self, num, len, vfree) -> shogun::TSparseEntry<(short)>

        get sparse feature vector for sample num from the matrix as it is if
        matrix is initialized, else return preprocessed compute_feature_vector

        Parameters:
        -----------

        num:  index of feature vector

        len:  number of sparse entries is returned by reference

        vfree:  whether returned vector must be freed by caller via
        free_sparse_feature_vector

        sparse feature vector 
        """
        return _Features.SparseShortFeatures_get_sparse_feature_vector(*args)

    def sparse_dot(*args):
        """
        sparse_dot(self, alpha, avec, alen, bvec, blen) -> short

        compute the dot product between two sparse feature vectors alpha *
        vec^T * vec

        Parameters:
        -----------

        alpha:  scalar to multiply with

        avec:  first sparse feature vector

        alen:  avec's length

        bvec:  second sparse feature vector

        blen:  bvec's length

        dot product between the two sparse feature vectors 
        """
        return _Features.SparseShortFeatures_sparse_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, num, vec, dim, abs_val=False)
        add_to_dense_vec(self, alpha, num, vec, dim)

        add a sparse feature vector onto a dense one dense+=alpha*sparse

        Parameters:
        -----------

        alpha:  scalar to multiply with

        num:  index of feature vector

        vec:  dense vector

        dim:  length of the dense vector

        abs_val:  if true, do dense+=alpha*abs(sparse) 
        """
        return _Features.SparseShortFeatures_add_to_dense_vec(*args)

    def free_sparse_feature_vector(*args):
        """
        free_sparse_feature_vector(self, feat_vec, num, free)

        free sparse feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of this vector in the cache

        free:  if vector should be really deleted 
        """
        return _Features.SparseShortFeatures_free_sparse_feature_vector(*args)

    def get_sparse_feature_matrix(*args):
        """
        get_sparse_feature_matrix(self, num_feat, num_vec) -> shogun::TSparse<(short)>
        get_sparse_feature_matrix(self, dst)

        get the pointer to the sparse feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        nnz:  number of nonzero elements 
        """
        return _Features.SparseShortFeatures_get_sparse_feature_matrix(*args)

    def clean_tsparse(*args):
        """
        clean_tsparse(self, sfm, num_vec)

        clean TSparse

        Parameters:
        -----------

        sfm:  sparse feature matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseShortFeatures_clean_tsparse(*args)

    def get_transposed(*args):
        """
        get_transposed(self, num_feat, num_vec) -> shogun::TSparse<(short)>

        compute and return the transpose of the sparse feature matrix which
        will be prepocessed. num_feat, num_vectors are returned by reference
        caller has to clean up

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        transposed sparse feature matrix 
        """
        return _Features.SparseShortFeatures_get_transposed(*args)

    def set_sparse_feature_matrix(*args):
        """
        set_sparse_feature_matrix(self, src)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        src:  new sparse feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseShortFeatures_set_sparse_feature_matrix(*args)

    def get_full_feature_matrix(*args):
        """
        get_full_feature_matrix(self, num_feat, num_vec) -> short
        get_full_feature_matrix(self, dst)

        gets a copy of a full feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseShortFeatures_get_full_feature_matrix(*args)

    def set_full_feature_matrix(*args):
        """
        set_full_feature_matrix(self, src) -> bool

        creates a sparse feature matrix from a full dense feature matrix
        necessary to set feature_matrix, num_features and num_vectors where
        num_features is the column offset, and columns are linear in memory
        see above for definition of sparse_feature_matrix

        Parameters:
        -----------

        src:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseShortFeatures_set_full_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.SparseShortFeatures_apply_preproc(*args)

    def obtain_from_simple(*args):
        """
        obtain_from_simple(self, sf) -> bool

        obtain sparse features from simple features

        Parameters:
        -----------

        sf:  simple features

        if obtaining was successful 
        """
        return _Features.SparseShortFeatures_obtain_from_simple(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.SparseShortFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num) ->  int

        set number of features

        Sometimes when loading sparse features not all possible dimensions are
        used. This may pose a problem to classifiers when being applied to
        higher dimensional test-data. This function allows to artificially
        explode the feature space

        Parameters:
        -----------

        num:  the number of features, must be larger than the current number
        of features

        previous number of features 
        """
        return _Features.SparseShortFeatures_set_num_features(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, free)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of vector in cache

        free:  if vector really should be deleted 
        """
        return _Features.SparseShortFeatures_free_feature_vector(*args)

    def get_num_nonzero_entries(*args):
        """
        get_num_nonzero_entries(self) -> int

        get number of non-zero entries in sparse feature matrix

        number of non-zero entries in sparse feature matrix 
        """
        return _Features.SparseShortFeatures_get_num_nonzero_entries(*args)

    def compute_squared(*args):
        """
        compute_squared(self, sq) -> float

        compute a^2 on all feature vectors

        Parameters:
        -----------

        sq:  the square for each vector is stored in here

        the square for each vector 
        """
        return _Features.SparseShortFeatures_compute_squared(*args)

    def compute_squared_norm(*args):
        """
        compute_squared_norm(self, lhs, sq_lhs, idx_a, rhs, sq_rhs, idx_b) -> float

        compute (a-b)^2 (== a^2+b^2+2ab) usually called by kernels'/distances'
        compute functions works on two feature vectors, although it is a
        member of a single feature: can either be called by lhs or rhs.

        Parameters:
        -----------

        lhs:  left-hand side features

        sq_lhs:  squared values of left-hand side

        idx_a:  index of left-hand side's vector to compute

        rhs:  right-hand side features

        sq_rhs:  squared values of right-hand side

        idx_b:  index of right-hand side's vector to compute 
        """
        return _Features.SparseShortFeatures_compute_squared_norm(*args)

    def load_svmlight_file(*args):
        """
        load_svmlight_file(self, fname, do_sort_features=True) -> Labels
        load_svmlight_file(self, fname) -> Labels

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        do_sort_features:  if true features will be sorted to ensure they are
        in ascending order

        label object with corresponding labels 
        """
        return _Features.SparseShortFeatures_load_svmlight_file(*args)

    def sort_features(*args):
        """
        sort_features(self)

        ensure that features occur in ascending order, only call when no
        preprocessors are attached 
        """
        return _Features.SparseShortFeatures_sort_features(*args)

    def write_svmlight_file(*args):
        """
        write_svmlight_file(self, fname, label) -> bool

        write features to file using svm light format

        Parameters:
        -----------

        fname:  filename to write to

        label:  Label object (number of labels must correspond to number of
        features)

        true if successful 
        """
        return _Features.SparseShortFeatures_write_svmlight_file(*args)

    def dense_dot(*args):
        """
        dense_dot(self, alpha, num, vec, dim, b) -> short
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.SparseShortFeatures_dense_dot(*args)

SparseShortFeatures_swigregister = _Features.SparseShortFeatures_swigregister
SparseShortFeatures_swigregister(SparseShortFeatures)

class SparseWordFeatures(DotFeatures):
    """
    Template class SparseFeatures implements sparse matrices.

    Features are an array of TSparse, sorted w.r.t. vec_index (increasing)
    and withing same vec_index w.r.t. feat_index (increasing);

    Sparse feature vectors can be accessed via get_sparse_feature_vector()
    and should be freed (this operation is a NOP in most cases) via
    free_sparse_feature_vector().

    As this is a template class it can directly be used for different data
    types like sparse matrices of real valued, integer, byte etc type.

    C++ includes: SparseFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, SparseWordFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, SparseWordFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> SparseWordFeatures
        __init__(self) -> SparseWordFeatures
        __init__(self, src, copy=False) -> SparseWordFeatures
        __init__(self, src) -> SparseWordFeatures
        __init__(self, src) -> SparseWordFeatures
        __init__(self, orig) -> SparseWordFeatures
        __init__(self, fname) -> SparseWordFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_SparseWordFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_SparseWordFeatures
    __del__ = lambda self : None;
    def free_sparse_feature_matrix(*args):
        """
        free_sparse_feature_matrix(self)

        free sparse feature matrix 
        """
        return _Features.SparseWordFeatures_free_sparse_feature_matrix(*args)

    def free_sparse_features(*args):
        """
        free_sparse_features(self)

        free sparse feature matrix and cache 
        """
        return _Features.SparseWordFeatures_free_sparse_features(*args)

    def get_feature(*args):
        """
        get_feature(self, num, index) -> unsigned short

        get a single feature

        Parameters:
        -----------

        num:  number of feature vector to retrieve

        index:  index of feature in this vector

        sum of features that match dimension index and 0 if none is found 
        """
        return _Features.SparseWordFeatures_get_feature(*args)

    def get_full_feature_vector(*args):
        """
        get_full_feature_vector(self, num, len) -> unsigned short
        get_full_feature_vector(self, dst, num)

        get the fully expanded dense feature vector num

        Parameters:
        -----------

        dst:  feature vector

        len:  length is returned by reference

        num:  index of feature vector 
        """
        return _Features.SparseWordFeatures_get_full_feature_vector(*args)

    def get_sparse_feature_vector(*args):
        """
        get_sparse_feature_vector(self, num, len, vfree) -> shogun::TSparseEntry<(unsigned short)>

        get sparse feature vector for sample num from the matrix as it is if
        matrix is initialized, else return preprocessed compute_feature_vector

        Parameters:
        -----------

        num:  index of feature vector

        len:  number of sparse entries is returned by reference

        vfree:  whether returned vector must be freed by caller via
        free_sparse_feature_vector

        sparse feature vector 
        """
        return _Features.SparseWordFeatures_get_sparse_feature_vector(*args)

    def sparse_dot(*args):
        """
        sparse_dot(self, alpha, avec, alen, bvec, blen) -> unsigned short

        compute the dot product between two sparse feature vectors alpha *
        vec^T * vec

        Parameters:
        -----------

        alpha:  scalar to multiply with

        avec:  first sparse feature vector

        alen:  avec's length

        bvec:  second sparse feature vector

        blen:  bvec's length

        dot product between the two sparse feature vectors 
        """
        return _Features.SparseWordFeatures_sparse_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, num, vec, dim, abs_val=False)
        add_to_dense_vec(self, alpha, num, vec, dim)

        add a sparse feature vector onto a dense one dense+=alpha*sparse

        Parameters:
        -----------

        alpha:  scalar to multiply with

        num:  index of feature vector

        vec:  dense vector

        dim:  length of the dense vector

        abs_val:  if true, do dense+=alpha*abs(sparse) 
        """
        return _Features.SparseWordFeatures_add_to_dense_vec(*args)

    def free_sparse_feature_vector(*args):
        """
        free_sparse_feature_vector(self, feat_vec, num, free)

        free sparse feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of this vector in the cache

        free:  if vector should be really deleted 
        """
        return _Features.SparseWordFeatures_free_sparse_feature_vector(*args)

    def get_sparse_feature_matrix(*args):
        """
        get_sparse_feature_matrix(self, num_feat, num_vec) -> shogun::TSparse<(unsigned short)>
        get_sparse_feature_matrix(self, dst)

        get the pointer to the sparse feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        nnz:  number of nonzero elements 
        """
        return _Features.SparseWordFeatures_get_sparse_feature_matrix(*args)

    def clean_tsparse(*args):
        """
        clean_tsparse(self, sfm, num_vec)

        clean TSparse

        Parameters:
        -----------

        sfm:  sparse feature matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseWordFeatures_clean_tsparse(*args)

    def get_transposed(*args):
        """
        get_transposed(self, num_feat, num_vec) -> shogun::TSparse<(unsigned short)>

        compute and return the transpose of the sparse feature matrix which
        will be prepocessed. num_feat, num_vectors are returned by reference
        caller has to clean up

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        transposed sparse feature matrix 
        """
        return _Features.SparseWordFeatures_get_transposed(*args)

    def set_sparse_feature_matrix(*args):
        """
        set_sparse_feature_matrix(self, src)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        src:  new sparse feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseWordFeatures_set_sparse_feature_matrix(*args)

    def get_full_feature_matrix(*args):
        """
        get_full_feature_matrix(self, num_feat, num_vec) -> unsigned short
        get_full_feature_matrix(self, dst)

        gets a copy of a full feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseWordFeatures_get_full_feature_matrix(*args)

    def set_full_feature_matrix(*args):
        """
        set_full_feature_matrix(self, src) -> bool

        creates a sparse feature matrix from a full dense feature matrix
        necessary to set feature_matrix, num_features and num_vectors where
        num_features is the column offset, and columns are linear in memory
        see above for definition of sparse_feature_matrix

        Parameters:
        -----------

        src:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseWordFeatures_set_full_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.SparseWordFeatures_apply_preproc(*args)

    def obtain_from_simple(*args):
        """
        obtain_from_simple(self, sf) -> bool

        obtain sparse features from simple features

        Parameters:
        -----------

        sf:  simple features

        if obtaining was successful 
        """
        return _Features.SparseWordFeatures_obtain_from_simple(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.SparseWordFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num) ->  int

        set number of features

        Sometimes when loading sparse features not all possible dimensions are
        used. This may pose a problem to classifiers when being applied to
        higher dimensional test-data. This function allows to artificially
        explode the feature space

        Parameters:
        -----------

        num:  the number of features, must be larger than the current number
        of features

        previous number of features 
        """
        return _Features.SparseWordFeatures_set_num_features(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, free)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of vector in cache

        free:  if vector really should be deleted 
        """
        return _Features.SparseWordFeatures_free_feature_vector(*args)

    def get_num_nonzero_entries(*args):
        """
        get_num_nonzero_entries(self) -> int

        get number of non-zero entries in sparse feature matrix

        number of non-zero entries in sparse feature matrix 
        """
        return _Features.SparseWordFeatures_get_num_nonzero_entries(*args)

    def compute_squared(*args):
        """
        compute_squared(self, sq) -> float

        compute a^2 on all feature vectors

        Parameters:
        -----------

        sq:  the square for each vector is stored in here

        the square for each vector 
        """
        return _Features.SparseWordFeatures_compute_squared(*args)

    def compute_squared_norm(*args):
        """
        compute_squared_norm(self, lhs, sq_lhs, idx_a, rhs, sq_rhs, idx_b) -> float

        compute (a-b)^2 (== a^2+b^2+2ab) usually called by kernels'/distances'
        compute functions works on two feature vectors, although it is a
        member of a single feature: can either be called by lhs or rhs.

        Parameters:
        -----------

        lhs:  left-hand side features

        sq_lhs:  squared values of left-hand side

        idx_a:  index of left-hand side's vector to compute

        rhs:  right-hand side features

        sq_rhs:  squared values of right-hand side

        idx_b:  index of right-hand side's vector to compute 
        """
        return _Features.SparseWordFeatures_compute_squared_norm(*args)

    def load_svmlight_file(*args):
        """
        load_svmlight_file(self, fname, do_sort_features=True) -> Labels
        load_svmlight_file(self, fname) -> Labels

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        do_sort_features:  if true features will be sorted to ensure they are
        in ascending order

        label object with corresponding labels 
        """
        return _Features.SparseWordFeatures_load_svmlight_file(*args)

    def sort_features(*args):
        """
        sort_features(self)

        ensure that features occur in ascending order, only call when no
        preprocessors are attached 
        """
        return _Features.SparseWordFeatures_sort_features(*args)

    def write_svmlight_file(*args):
        """
        write_svmlight_file(self, fname, label) -> bool

        write features to file using svm light format

        Parameters:
        -----------

        fname:  filename to write to

        label:  Label object (number of labels must correspond to number of
        features)

        true if successful 
        """
        return _Features.SparseWordFeatures_write_svmlight_file(*args)

    def dense_dot(*args):
        """
        dense_dot(self, alpha, num, vec, dim, b) -> unsigned short
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.SparseWordFeatures_dense_dot(*args)

SparseWordFeatures_swigregister = _Features.SparseWordFeatures_swigregister
SparseWordFeatures_swigregister(SparseWordFeatures)

class SparseIntFeatures(DotFeatures):
    """
    Template class SparseFeatures implements sparse matrices.

    Features are an array of TSparse, sorted w.r.t. vec_index (increasing)
    and withing same vec_index w.r.t. feat_index (increasing);

    Sparse feature vectors can be accessed via get_sparse_feature_vector()
    and should be freed (this operation is a NOP in most cases) via
    free_sparse_feature_vector().

    As this is a template class it can directly be used for different data
    types like sparse matrices of real valued, integer, byte etc type.

    C++ includes: SparseFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, SparseIntFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, SparseIntFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> SparseIntFeatures
        __init__(self) -> SparseIntFeatures
        __init__(self, src, copy=False) -> SparseIntFeatures
        __init__(self, src) -> SparseIntFeatures
        __init__(self, src) -> SparseIntFeatures
        __init__(self, orig) -> SparseIntFeatures
        __init__(self, fname) -> SparseIntFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_SparseIntFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_SparseIntFeatures
    __del__ = lambda self : None;
    def free_sparse_feature_matrix(*args):
        """
        free_sparse_feature_matrix(self)

        free sparse feature matrix 
        """
        return _Features.SparseIntFeatures_free_sparse_feature_matrix(*args)

    def free_sparse_features(*args):
        """
        free_sparse_features(self)

        free sparse feature matrix and cache 
        """
        return _Features.SparseIntFeatures_free_sparse_features(*args)

    def get_feature(*args):
        """
        get_feature(self, num, index) -> int

        get a single feature

        Parameters:
        -----------

        num:  number of feature vector to retrieve

        index:  index of feature in this vector

        sum of features that match dimension index and 0 if none is found 
        """
        return _Features.SparseIntFeatures_get_feature(*args)

    def get_full_feature_vector(*args):
        """
        get_full_feature_vector(self, num, len) -> int
        get_full_feature_vector(self, dst, num)

        get the fully expanded dense feature vector num

        Parameters:
        -----------

        dst:  feature vector

        len:  length is returned by reference

        num:  index of feature vector 
        """
        return _Features.SparseIntFeatures_get_full_feature_vector(*args)

    def get_sparse_feature_vector(*args):
        """
        get_sparse_feature_vector(self, num, len, vfree) -> shogun::TSparseEntry<(int)>

        get sparse feature vector for sample num from the matrix as it is if
        matrix is initialized, else return preprocessed compute_feature_vector

        Parameters:
        -----------

        num:  index of feature vector

        len:  number of sparse entries is returned by reference

        vfree:  whether returned vector must be freed by caller via
        free_sparse_feature_vector

        sparse feature vector 
        """
        return _Features.SparseIntFeatures_get_sparse_feature_vector(*args)

    def sparse_dot(*args):
        """
        sparse_dot(self, alpha, avec, alen, bvec, blen) -> int

        compute the dot product between two sparse feature vectors alpha *
        vec^T * vec

        Parameters:
        -----------

        alpha:  scalar to multiply with

        avec:  first sparse feature vector

        alen:  avec's length

        bvec:  second sparse feature vector

        blen:  bvec's length

        dot product between the two sparse feature vectors 
        """
        return _Features.SparseIntFeatures_sparse_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, num, vec, dim, abs_val=False)
        add_to_dense_vec(self, alpha, num, vec, dim)

        add a sparse feature vector onto a dense one dense+=alpha*sparse

        Parameters:
        -----------

        alpha:  scalar to multiply with

        num:  index of feature vector

        vec:  dense vector

        dim:  length of the dense vector

        abs_val:  if true, do dense+=alpha*abs(sparse) 
        """
        return _Features.SparseIntFeatures_add_to_dense_vec(*args)

    def free_sparse_feature_vector(*args):
        """
        free_sparse_feature_vector(self, feat_vec, num, free)

        free sparse feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of this vector in the cache

        free:  if vector should be really deleted 
        """
        return _Features.SparseIntFeatures_free_sparse_feature_vector(*args)

    def get_sparse_feature_matrix(*args):
        """
        get_sparse_feature_matrix(self, num_feat, num_vec) -> shogun::TSparse<(int)>
        get_sparse_feature_matrix(self, dst)

        get the pointer to the sparse feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        nnz:  number of nonzero elements 
        """
        return _Features.SparseIntFeatures_get_sparse_feature_matrix(*args)

    def clean_tsparse(*args):
        """
        clean_tsparse(self, sfm, num_vec)

        clean TSparse

        Parameters:
        -----------

        sfm:  sparse feature matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseIntFeatures_clean_tsparse(*args)

    def get_transposed(*args):
        """
        get_transposed(self, num_feat, num_vec) -> shogun::TSparse<(int)>

        compute and return the transpose of the sparse feature matrix which
        will be prepocessed. num_feat, num_vectors are returned by reference
        caller has to clean up

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        transposed sparse feature matrix 
        """
        return _Features.SparseIntFeatures_get_transposed(*args)

    def set_sparse_feature_matrix(*args):
        """
        set_sparse_feature_matrix(self, src)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        src:  new sparse feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseIntFeatures_set_sparse_feature_matrix(*args)

    def get_full_feature_matrix(*args):
        """
        get_full_feature_matrix(self, num_feat, num_vec) -> int
        get_full_feature_matrix(self, dst)

        gets a copy of a full feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseIntFeatures_get_full_feature_matrix(*args)

    def set_full_feature_matrix(*args):
        """
        set_full_feature_matrix(self, src) -> bool

        creates a sparse feature matrix from a full dense feature matrix
        necessary to set feature_matrix, num_features and num_vectors where
        num_features is the column offset, and columns are linear in memory
        see above for definition of sparse_feature_matrix

        Parameters:
        -----------

        src:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseIntFeatures_set_full_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.SparseIntFeatures_apply_preproc(*args)

    def obtain_from_simple(*args):
        """
        obtain_from_simple(self, sf) -> bool

        obtain sparse features from simple features

        Parameters:
        -----------

        sf:  simple features

        if obtaining was successful 
        """
        return _Features.SparseIntFeatures_obtain_from_simple(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.SparseIntFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num) ->  int

        set number of features

        Sometimes when loading sparse features not all possible dimensions are
        used. This may pose a problem to classifiers when being applied to
        higher dimensional test-data. This function allows to artificially
        explode the feature space

        Parameters:
        -----------

        num:  the number of features, must be larger than the current number
        of features

        previous number of features 
        """
        return _Features.SparseIntFeatures_set_num_features(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, free)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of vector in cache

        free:  if vector really should be deleted 
        """
        return _Features.SparseIntFeatures_free_feature_vector(*args)

    def get_num_nonzero_entries(*args):
        """
        get_num_nonzero_entries(self) -> int

        get number of non-zero entries in sparse feature matrix

        number of non-zero entries in sparse feature matrix 
        """
        return _Features.SparseIntFeatures_get_num_nonzero_entries(*args)

    def compute_squared(*args):
        """
        compute_squared(self, sq) -> float

        compute a^2 on all feature vectors

        Parameters:
        -----------

        sq:  the square for each vector is stored in here

        the square for each vector 
        """
        return _Features.SparseIntFeatures_compute_squared(*args)

    def compute_squared_norm(*args):
        """
        compute_squared_norm(self, lhs, sq_lhs, idx_a, rhs, sq_rhs, idx_b) -> float

        compute (a-b)^2 (== a^2+b^2+2ab) usually called by kernels'/distances'
        compute functions works on two feature vectors, although it is a
        member of a single feature: can either be called by lhs or rhs.

        Parameters:
        -----------

        lhs:  left-hand side features

        sq_lhs:  squared values of left-hand side

        idx_a:  index of left-hand side's vector to compute

        rhs:  right-hand side features

        sq_rhs:  squared values of right-hand side

        idx_b:  index of right-hand side's vector to compute 
        """
        return _Features.SparseIntFeatures_compute_squared_norm(*args)

    def load_svmlight_file(*args):
        """
        load_svmlight_file(self, fname, do_sort_features=True) -> Labels
        load_svmlight_file(self, fname) -> Labels

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        do_sort_features:  if true features will be sorted to ensure they are
        in ascending order

        label object with corresponding labels 
        """
        return _Features.SparseIntFeatures_load_svmlight_file(*args)

    def sort_features(*args):
        """
        sort_features(self)

        ensure that features occur in ascending order, only call when no
        preprocessors are attached 
        """
        return _Features.SparseIntFeatures_sort_features(*args)

    def write_svmlight_file(*args):
        """
        write_svmlight_file(self, fname, label) -> bool

        write features to file using svm light format

        Parameters:
        -----------

        fname:  filename to write to

        label:  Label object (number of labels must correspond to number of
        features)

        true if successful 
        """
        return _Features.SparseIntFeatures_write_svmlight_file(*args)

    def dense_dot(*args):
        """
        dense_dot(self, alpha, num, vec, dim, b) -> int
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.SparseIntFeatures_dense_dot(*args)

SparseIntFeatures_swigregister = _Features.SparseIntFeatures_swigregister
SparseIntFeatures_swigregister(SparseIntFeatures)

class SparseUIntFeatures(DotFeatures):
    """
    Template class SparseFeatures implements sparse matrices.

    Features are an array of TSparse, sorted w.r.t. vec_index (increasing)
    and withing same vec_index w.r.t. feat_index (increasing);

    Sparse feature vectors can be accessed via get_sparse_feature_vector()
    and should be freed (this operation is a NOP in most cases) via
    free_sparse_feature_vector().

    As this is a template class it can directly be used for different data
    types like sparse matrices of real valued, integer, byte etc type.

    C++ includes: SparseFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, SparseUIntFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, SparseUIntFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> SparseUIntFeatures
        __init__(self) -> SparseUIntFeatures
        __init__(self, src, copy=False) -> SparseUIntFeatures
        __init__(self, src) -> SparseUIntFeatures
        __init__(self, src) -> SparseUIntFeatures
        __init__(self, orig) -> SparseUIntFeatures
        __init__(self, fname) -> SparseUIntFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_SparseUIntFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_SparseUIntFeatures
    __del__ = lambda self : None;
    def free_sparse_feature_matrix(*args):
        """
        free_sparse_feature_matrix(self)

        free sparse feature matrix 
        """
        return _Features.SparseUIntFeatures_free_sparse_feature_matrix(*args)

    def free_sparse_features(*args):
        """
        free_sparse_features(self)

        free sparse feature matrix and cache 
        """
        return _Features.SparseUIntFeatures_free_sparse_features(*args)

    def get_feature(*args):
        """
        get_feature(self, num, index) -> unsigned int

        get a single feature

        Parameters:
        -----------

        num:  number of feature vector to retrieve

        index:  index of feature in this vector

        sum of features that match dimension index and 0 if none is found 
        """
        return _Features.SparseUIntFeatures_get_feature(*args)

    def get_full_feature_vector(*args):
        """
        get_full_feature_vector(self, num, len) -> unsigned int
        get_full_feature_vector(self, dst, num)

        get the fully expanded dense feature vector num

        Parameters:
        -----------

        dst:  feature vector

        len:  length is returned by reference

        num:  index of feature vector 
        """
        return _Features.SparseUIntFeatures_get_full_feature_vector(*args)

    def get_sparse_feature_vector(*args):
        """
        get_sparse_feature_vector(self, num, len, vfree) -> shogun::TSparseEntry<(unsigned int)>

        get sparse feature vector for sample num from the matrix as it is if
        matrix is initialized, else return preprocessed compute_feature_vector

        Parameters:
        -----------

        num:  index of feature vector

        len:  number of sparse entries is returned by reference

        vfree:  whether returned vector must be freed by caller via
        free_sparse_feature_vector

        sparse feature vector 
        """
        return _Features.SparseUIntFeatures_get_sparse_feature_vector(*args)

    def sparse_dot(*args):
        """
        sparse_dot(self, alpha, avec, alen, bvec, blen) -> unsigned int

        compute the dot product between two sparse feature vectors alpha *
        vec^T * vec

        Parameters:
        -----------

        alpha:  scalar to multiply with

        avec:  first sparse feature vector

        alen:  avec's length

        bvec:  second sparse feature vector

        blen:  bvec's length

        dot product between the two sparse feature vectors 
        """
        return _Features.SparseUIntFeatures_sparse_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, num, vec, dim, abs_val=False)
        add_to_dense_vec(self, alpha, num, vec, dim)

        add a sparse feature vector onto a dense one dense+=alpha*sparse

        Parameters:
        -----------

        alpha:  scalar to multiply with

        num:  index of feature vector

        vec:  dense vector

        dim:  length of the dense vector

        abs_val:  if true, do dense+=alpha*abs(sparse) 
        """
        return _Features.SparseUIntFeatures_add_to_dense_vec(*args)

    def free_sparse_feature_vector(*args):
        """
        free_sparse_feature_vector(self, feat_vec, num, free)

        free sparse feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of this vector in the cache

        free:  if vector should be really deleted 
        """
        return _Features.SparseUIntFeatures_free_sparse_feature_vector(*args)

    def get_sparse_feature_matrix(*args):
        """
        get_sparse_feature_matrix(self, num_feat, num_vec) -> shogun::TSparse<(unsigned int)>
        get_sparse_feature_matrix(self, dst)

        get the pointer to the sparse feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        nnz:  number of nonzero elements 
        """
        return _Features.SparseUIntFeatures_get_sparse_feature_matrix(*args)

    def clean_tsparse(*args):
        """
        clean_tsparse(self, sfm, num_vec)

        clean TSparse

        Parameters:
        -----------

        sfm:  sparse feature matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseUIntFeatures_clean_tsparse(*args)

    def get_transposed(*args):
        """
        get_transposed(self, num_feat, num_vec) -> shogun::TSparse<(unsigned int)>

        compute and return the transpose of the sparse feature matrix which
        will be prepocessed. num_feat, num_vectors are returned by reference
        caller has to clean up

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        transposed sparse feature matrix 
        """
        return _Features.SparseUIntFeatures_get_transposed(*args)

    def set_sparse_feature_matrix(*args):
        """
        set_sparse_feature_matrix(self, src)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        src:  new sparse feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseUIntFeatures_set_sparse_feature_matrix(*args)

    def get_full_feature_matrix(*args):
        """
        get_full_feature_matrix(self, num_feat, num_vec) -> unsigned int
        get_full_feature_matrix(self, dst)

        gets a copy of a full feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseUIntFeatures_get_full_feature_matrix(*args)

    def set_full_feature_matrix(*args):
        """
        set_full_feature_matrix(self, src) -> bool

        creates a sparse feature matrix from a full dense feature matrix
        necessary to set feature_matrix, num_features and num_vectors where
        num_features is the column offset, and columns are linear in memory
        see above for definition of sparse_feature_matrix

        Parameters:
        -----------

        src:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseUIntFeatures_set_full_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.SparseUIntFeatures_apply_preproc(*args)

    def obtain_from_simple(*args):
        """
        obtain_from_simple(self, sf) -> bool

        obtain sparse features from simple features

        Parameters:
        -----------

        sf:  simple features

        if obtaining was successful 
        """
        return _Features.SparseUIntFeatures_obtain_from_simple(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.SparseUIntFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num) ->  int

        set number of features

        Sometimes when loading sparse features not all possible dimensions are
        used. This may pose a problem to classifiers when being applied to
        higher dimensional test-data. This function allows to artificially
        explode the feature space

        Parameters:
        -----------

        num:  the number of features, must be larger than the current number
        of features

        previous number of features 
        """
        return _Features.SparseUIntFeatures_set_num_features(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, free)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of vector in cache

        free:  if vector really should be deleted 
        """
        return _Features.SparseUIntFeatures_free_feature_vector(*args)

    def get_num_nonzero_entries(*args):
        """
        get_num_nonzero_entries(self) -> int

        get number of non-zero entries in sparse feature matrix

        number of non-zero entries in sparse feature matrix 
        """
        return _Features.SparseUIntFeatures_get_num_nonzero_entries(*args)

    def compute_squared(*args):
        """
        compute_squared(self, sq) -> float

        compute a^2 on all feature vectors

        Parameters:
        -----------

        sq:  the square for each vector is stored in here

        the square for each vector 
        """
        return _Features.SparseUIntFeatures_compute_squared(*args)

    def compute_squared_norm(*args):
        """
        compute_squared_norm(self, lhs, sq_lhs, idx_a, rhs, sq_rhs, idx_b) -> float

        compute (a-b)^2 (== a^2+b^2+2ab) usually called by kernels'/distances'
        compute functions works on two feature vectors, although it is a
        member of a single feature: can either be called by lhs or rhs.

        Parameters:
        -----------

        lhs:  left-hand side features

        sq_lhs:  squared values of left-hand side

        idx_a:  index of left-hand side's vector to compute

        rhs:  right-hand side features

        sq_rhs:  squared values of right-hand side

        idx_b:  index of right-hand side's vector to compute 
        """
        return _Features.SparseUIntFeatures_compute_squared_norm(*args)

    def load_svmlight_file(*args):
        """
        load_svmlight_file(self, fname, do_sort_features=True) -> Labels
        load_svmlight_file(self, fname) -> Labels

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        do_sort_features:  if true features will be sorted to ensure they are
        in ascending order

        label object with corresponding labels 
        """
        return _Features.SparseUIntFeatures_load_svmlight_file(*args)

    def sort_features(*args):
        """
        sort_features(self)

        ensure that features occur in ascending order, only call when no
        preprocessors are attached 
        """
        return _Features.SparseUIntFeatures_sort_features(*args)

    def write_svmlight_file(*args):
        """
        write_svmlight_file(self, fname, label) -> bool

        write features to file using svm light format

        Parameters:
        -----------

        fname:  filename to write to

        label:  Label object (number of labels must correspond to number of
        features)

        true if successful 
        """
        return _Features.SparseUIntFeatures_write_svmlight_file(*args)

    def dense_dot(*args):
        """
        dense_dot(self, alpha, num, vec, dim, b) -> unsigned int
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.SparseUIntFeatures_dense_dot(*args)

SparseUIntFeatures_swigregister = _Features.SparseUIntFeatures_swigregister
SparseUIntFeatures_swigregister(SparseUIntFeatures)

class SparseLongFeatures(DotFeatures):
    """
    Template class SparseFeatures implements sparse matrices.

    Features are an array of TSparse, sorted w.r.t. vec_index (increasing)
    and withing same vec_index w.r.t. feat_index (increasing);

    Sparse feature vectors can be accessed via get_sparse_feature_vector()
    and should be freed (this operation is a NOP in most cases) via
    free_sparse_feature_vector().

    As this is a template class it can directly be used for different data
    types like sparse matrices of real valued, integer, byte etc type.

    C++ includes: SparseFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, SparseLongFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, SparseLongFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> SparseLongFeatures
        __init__(self) -> SparseLongFeatures
        __init__(self, src, copy=False) -> SparseLongFeatures
        __init__(self, src) -> SparseLongFeatures
        __init__(self, src) -> SparseLongFeatures
        __init__(self, orig) -> SparseLongFeatures
        __init__(self, fname) -> SparseLongFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_SparseLongFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_SparseLongFeatures
    __del__ = lambda self : None;
    def free_sparse_feature_matrix(*args):
        """
        free_sparse_feature_matrix(self)

        free sparse feature matrix 
        """
        return _Features.SparseLongFeatures_free_sparse_feature_matrix(*args)

    def free_sparse_features(*args):
        """
        free_sparse_features(self)

        free sparse feature matrix and cache 
        """
        return _Features.SparseLongFeatures_free_sparse_features(*args)

    def get_feature(*args):
        """
        get_feature(self, num, index) -> long long

        get a single feature

        Parameters:
        -----------

        num:  number of feature vector to retrieve

        index:  index of feature in this vector

        sum of features that match dimension index and 0 if none is found 
        """
        return _Features.SparseLongFeatures_get_feature(*args)

    def get_full_feature_vector(*args):
        """
        get_full_feature_vector(self, num, len) -> long long
        get_full_feature_vector(self, dst, num)

        get the fully expanded dense feature vector num

        Parameters:
        -----------

        dst:  feature vector

        len:  length is returned by reference

        num:  index of feature vector 
        """
        return _Features.SparseLongFeatures_get_full_feature_vector(*args)

    def get_sparse_feature_vector(*args):
        """
        get_sparse_feature_vector(self, num, len, vfree) -> shogun::TSparseEntry<(long long)>

        get sparse feature vector for sample num from the matrix as it is if
        matrix is initialized, else return preprocessed compute_feature_vector

        Parameters:
        -----------

        num:  index of feature vector

        len:  number of sparse entries is returned by reference

        vfree:  whether returned vector must be freed by caller via
        free_sparse_feature_vector

        sparse feature vector 
        """
        return _Features.SparseLongFeatures_get_sparse_feature_vector(*args)

    def sparse_dot(*args):
        """
        sparse_dot(self, alpha, avec, alen, bvec, blen) -> long long

        compute the dot product between two sparse feature vectors alpha *
        vec^T * vec

        Parameters:
        -----------

        alpha:  scalar to multiply with

        avec:  first sparse feature vector

        alen:  avec's length

        bvec:  second sparse feature vector

        blen:  bvec's length

        dot product between the two sparse feature vectors 
        """
        return _Features.SparseLongFeatures_sparse_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, num, vec, dim, abs_val=False)
        add_to_dense_vec(self, alpha, num, vec, dim)

        add a sparse feature vector onto a dense one dense+=alpha*sparse

        Parameters:
        -----------

        alpha:  scalar to multiply with

        num:  index of feature vector

        vec:  dense vector

        dim:  length of the dense vector

        abs_val:  if true, do dense+=alpha*abs(sparse) 
        """
        return _Features.SparseLongFeatures_add_to_dense_vec(*args)

    def free_sparse_feature_vector(*args):
        """
        free_sparse_feature_vector(self, feat_vec, num, free)

        free sparse feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of this vector in the cache

        free:  if vector should be really deleted 
        """
        return _Features.SparseLongFeatures_free_sparse_feature_vector(*args)

    def get_sparse_feature_matrix(*args):
        """
        get_sparse_feature_matrix(self, num_feat, num_vec) -> shogun::TSparse<(long long)>
        get_sparse_feature_matrix(self, dst)

        get the pointer to the sparse feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        nnz:  number of nonzero elements 
        """
        return _Features.SparseLongFeatures_get_sparse_feature_matrix(*args)

    def clean_tsparse(*args):
        """
        clean_tsparse(self, sfm, num_vec)

        clean TSparse

        Parameters:
        -----------

        sfm:  sparse feature matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseLongFeatures_clean_tsparse(*args)

    def get_transposed(*args):
        """
        get_transposed(self, num_feat, num_vec) -> shogun::TSparse<(long long)>

        compute and return the transpose of the sparse feature matrix which
        will be prepocessed. num_feat, num_vectors are returned by reference
        caller has to clean up

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        transposed sparse feature matrix 
        """
        return _Features.SparseLongFeatures_get_transposed(*args)

    def set_sparse_feature_matrix(*args):
        """
        set_sparse_feature_matrix(self, src)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        src:  new sparse feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseLongFeatures_set_sparse_feature_matrix(*args)

    def get_full_feature_matrix(*args):
        """
        get_full_feature_matrix(self, num_feat, num_vec) -> long long
        get_full_feature_matrix(self, dst)

        gets a copy of a full feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseLongFeatures_get_full_feature_matrix(*args)

    def set_full_feature_matrix(*args):
        """
        set_full_feature_matrix(self, src) -> bool

        creates a sparse feature matrix from a full dense feature matrix
        necessary to set feature_matrix, num_features and num_vectors where
        num_features is the column offset, and columns are linear in memory
        see above for definition of sparse_feature_matrix

        Parameters:
        -----------

        src:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseLongFeatures_set_full_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.SparseLongFeatures_apply_preproc(*args)

    def obtain_from_simple(*args):
        """
        obtain_from_simple(self, sf) -> bool

        obtain sparse features from simple features

        Parameters:
        -----------

        sf:  simple features

        if obtaining was successful 
        """
        return _Features.SparseLongFeatures_obtain_from_simple(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.SparseLongFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num) ->  int

        set number of features

        Sometimes when loading sparse features not all possible dimensions are
        used. This may pose a problem to classifiers when being applied to
        higher dimensional test-data. This function allows to artificially
        explode the feature space

        Parameters:
        -----------

        num:  the number of features, must be larger than the current number
        of features

        previous number of features 
        """
        return _Features.SparseLongFeatures_set_num_features(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, free)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of vector in cache

        free:  if vector really should be deleted 
        """
        return _Features.SparseLongFeatures_free_feature_vector(*args)

    def get_num_nonzero_entries(*args):
        """
        get_num_nonzero_entries(self) -> int

        get number of non-zero entries in sparse feature matrix

        number of non-zero entries in sparse feature matrix 
        """
        return _Features.SparseLongFeatures_get_num_nonzero_entries(*args)

    def compute_squared(*args):
        """
        compute_squared(self, sq) -> float

        compute a^2 on all feature vectors

        Parameters:
        -----------

        sq:  the square for each vector is stored in here

        the square for each vector 
        """
        return _Features.SparseLongFeatures_compute_squared(*args)

    def compute_squared_norm(*args):
        """
        compute_squared_norm(self, lhs, sq_lhs, idx_a, rhs, sq_rhs, idx_b) -> float

        compute (a-b)^2 (== a^2+b^2+2ab) usually called by kernels'/distances'
        compute functions works on two feature vectors, although it is a
        member of a single feature: can either be called by lhs or rhs.

        Parameters:
        -----------

        lhs:  left-hand side features

        sq_lhs:  squared values of left-hand side

        idx_a:  index of left-hand side's vector to compute

        rhs:  right-hand side features

        sq_rhs:  squared values of right-hand side

        idx_b:  index of right-hand side's vector to compute 
        """
        return _Features.SparseLongFeatures_compute_squared_norm(*args)

    def load_svmlight_file(*args):
        """
        load_svmlight_file(self, fname, do_sort_features=True) -> Labels
        load_svmlight_file(self, fname) -> Labels

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        do_sort_features:  if true features will be sorted to ensure they are
        in ascending order

        label object with corresponding labels 
        """
        return _Features.SparseLongFeatures_load_svmlight_file(*args)

    def sort_features(*args):
        """
        sort_features(self)

        ensure that features occur in ascending order, only call when no
        preprocessors are attached 
        """
        return _Features.SparseLongFeatures_sort_features(*args)

    def write_svmlight_file(*args):
        """
        write_svmlight_file(self, fname, label) -> bool

        write features to file using svm light format

        Parameters:
        -----------

        fname:  filename to write to

        label:  Label object (number of labels must correspond to number of
        features)

        true if successful 
        """
        return _Features.SparseLongFeatures_write_svmlight_file(*args)

    def dense_dot(*args):
        """
        dense_dot(self, alpha, num, vec, dim, b) -> long long
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.SparseLongFeatures_dense_dot(*args)

SparseLongFeatures_swigregister = _Features.SparseLongFeatures_swigregister
SparseLongFeatures_swigregister(SparseLongFeatures)

class SparseUlongFeatures(DotFeatures):
    """
    Template class SparseFeatures implements sparse matrices.

    Features are an array of TSparse, sorted w.r.t. vec_index (increasing)
    and withing same vec_index w.r.t. feat_index (increasing);

    Sparse feature vectors can be accessed via get_sparse_feature_vector()
    and should be freed (this operation is a NOP in most cases) via
    free_sparse_feature_vector().

    As this is a template class it can directly be used for different data
    types like sparse matrices of real valued, integer, byte etc type.

    C++ includes: SparseFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, SparseUlongFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, SparseUlongFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> SparseUlongFeatures
        __init__(self) -> SparseUlongFeatures
        __init__(self, src, copy=False) -> SparseUlongFeatures
        __init__(self, src) -> SparseUlongFeatures
        __init__(self, src) -> SparseUlongFeatures
        __init__(self, orig) -> SparseUlongFeatures
        __init__(self, fname) -> SparseUlongFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_SparseUlongFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_SparseUlongFeatures
    __del__ = lambda self : None;
    def free_sparse_feature_matrix(*args):
        """
        free_sparse_feature_matrix(self)

        free sparse feature matrix 
        """
        return _Features.SparseUlongFeatures_free_sparse_feature_matrix(*args)

    def free_sparse_features(*args):
        """
        free_sparse_features(self)

        free sparse feature matrix and cache 
        """
        return _Features.SparseUlongFeatures_free_sparse_features(*args)

    def get_feature(*args):
        """
        get_feature(self, num, index) -> unsigned long long

        get a single feature

        Parameters:
        -----------

        num:  number of feature vector to retrieve

        index:  index of feature in this vector

        sum of features that match dimension index and 0 if none is found 
        """
        return _Features.SparseUlongFeatures_get_feature(*args)

    def get_full_feature_vector(*args):
        """
        get_full_feature_vector(self, num, len) -> unsigned long long
        get_full_feature_vector(self, dst, num)

        get the fully expanded dense feature vector num

        Parameters:
        -----------

        dst:  feature vector

        len:  length is returned by reference

        num:  index of feature vector 
        """
        return _Features.SparseUlongFeatures_get_full_feature_vector(*args)

    def get_sparse_feature_vector(*args):
        """
        get_sparse_feature_vector(self, num, len, vfree) -> shogun::TSparseEntry<(unsigned long long)>

        get sparse feature vector for sample num from the matrix as it is if
        matrix is initialized, else return preprocessed compute_feature_vector

        Parameters:
        -----------

        num:  index of feature vector

        len:  number of sparse entries is returned by reference

        vfree:  whether returned vector must be freed by caller via
        free_sparse_feature_vector

        sparse feature vector 
        """
        return _Features.SparseUlongFeatures_get_sparse_feature_vector(*args)

    def sparse_dot(*args):
        """
        sparse_dot(self, alpha, avec, alen, bvec, blen) -> unsigned long long

        compute the dot product between two sparse feature vectors alpha *
        vec^T * vec

        Parameters:
        -----------

        alpha:  scalar to multiply with

        avec:  first sparse feature vector

        alen:  avec's length

        bvec:  second sparse feature vector

        blen:  bvec's length

        dot product between the two sparse feature vectors 
        """
        return _Features.SparseUlongFeatures_sparse_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, num, vec, dim, abs_val=False)
        add_to_dense_vec(self, alpha, num, vec, dim)

        add a sparse feature vector onto a dense one dense+=alpha*sparse

        Parameters:
        -----------

        alpha:  scalar to multiply with

        num:  index of feature vector

        vec:  dense vector

        dim:  length of the dense vector

        abs_val:  if true, do dense+=alpha*abs(sparse) 
        """
        return _Features.SparseUlongFeatures_add_to_dense_vec(*args)

    def free_sparse_feature_vector(*args):
        """
        free_sparse_feature_vector(self, feat_vec, num, free)

        free sparse feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of this vector in the cache

        free:  if vector should be really deleted 
        """
        return _Features.SparseUlongFeatures_free_sparse_feature_vector(*args)

    def get_sparse_feature_matrix(*args):
        """
        get_sparse_feature_matrix(self, num_feat, num_vec) -> shogun::TSparse<(unsigned long long)>
        get_sparse_feature_matrix(self, dst)

        get the pointer to the sparse feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        nnz:  number of nonzero elements 
        """
        return _Features.SparseUlongFeatures_get_sparse_feature_matrix(*args)

    def clean_tsparse(*args):
        """
        clean_tsparse(self, sfm, num_vec)

        clean TSparse

        Parameters:
        -----------

        sfm:  sparse feature matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseUlongFeatures_clean_tsparse(*args)

    def get_transposed(*args):
        """
        get_transposed(self, num_feat, num_vec) -> shogun::TSparse<(unsigned long long)>

        compute and return the transpose of the sparse feature matrix which
        will be prepocessed. num_feat, num_vectors are returned by reference
        caller has to clean up

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        transposed sparse feature matrix 
        """
        return _Features.SparseUlongFeatures_get_transposed(*args)

    def set_sparse_feature_matrix(*args):
        """
        set_sparse_feature_matrix(self, src)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        src:  new sparse feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseUlongFeatures_set_sparse_feature_matrix(*args)

    def get_full_feature_matrix(*args):
        """
        get_full_feature_matrix(self, num_feat, num_vec) -> unsigned long long
        get_full_feature_matrix(self, dst)

        gets a copy of a full feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseUlongFeatures_get_full_feature_matrix(*args)

    def set_full_feature_matrix(*args):
        """
        set_full_feature_matrix(self, src) -> bool

        creates a sparse feature matrix from a full dense feature matrix
        necessary to set feature_matrix, num_features and num_vectors where
        num_features is the column offset, and columns are linear in memory
        see above for definition of sparse_feature_matrix

        Parameters:
        -----------

        src:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseUlongFeatures_set_full_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.SparseUlongFeatures_apply_preproc(*args)

    def obtain_from_simple(*args):
        """
        obtain_from_simple(self, sf) -> bool

        obtain sparse features from simple features

        Parameters:
        -----------

        sf:  simple features

        if obtaining was successful 
        """
        return _Features.SparseUlongFeatures_obtain_from_simple(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.SparseUlongFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num) ->  int

        set number of features

        Sometimes when loading sparse features not all possible dimensions are
        used. This may pose a problem to classifiers when being applied to
        higher dimensional test-data. This function allows to artificially
        explode the feature space

        Parameters:
        -----------

        num:  the number of features, must be larger than the current number
        of features

        previous number of features 
        """
        return _Features.SparseUlongFeatures_set_num_features(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, free)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of vector in cache

        free:  if vector really should be deleted 
        """
        return _Features.SparseUlongFeatures_free_feature_vector(*args)

    def get_num_nonzero_entries(*args):
        """
        get_num_nonzero_entries(self) -> int

        get number of non-zero entries in sparse feature matrix

        number of non-zero entries in sparse feature matrix 
        """
        return _Features.SparseUlongFeatures_get_num_nonzero_entries(*args)

    def compute_squared(*args):
        """
        compute_squared(self, sq) -> float

        compute a^2 on all feature vectors

        Parameters:
        -----------

        sq:  the square for each vector is stored in here

        the square for each vector 
        """
        return _Features.SparseUlongFeatures_compute_squared(*args)

    def compute_squared_norm(*args):
        """
        compute_squared_norm(self, lhs, sq_lhs, idx_a, rhs, sq_rhs, idx_b) -> float

        compute (a-b)^2 (== a^2+b^2+2ab) usually called by kernels'/distances'
        compute functions works on two feature vectors, although it is a
        member of a single feature: can either be called by lhs or rhs.

        Parameters:
        -----------

        lhs:  left-hand side features

        sq_lhs:  squared values of left-hand side

        idx_a:  index of left-hand side's vector to compute

        rhs:  right-hand side features

        sq_rhs:  squared values of right-hand side

        idx_b:  index of right-hand side's vector to compute 
        """
        return _Features.SparseUlongFeatures_compute_squared_norm(*args)

    def load_svmlight_file(*args):
        """
        load_svmlight_file(self, fname, do_sort_features=True) -> Labels
        load_svmlight_file(self, fname) -> Labels

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        do_sort_features:  if true features will be sorted to ensure they are
        in ascending order

        label object with corresponding labels 
        """
        return _Features.SparseUlongFeatures_load_svmlight_file(*args)

    def sort_features(*args):
        """
        sort_features(self)

        ensure that features occur in ascending order, only call when no
        preprocessors are attached 
        """
        return _Features.SparseUlongFeatures_sort_features(*args)

    def write_svmlight_file(*args):
        """
        write_svmlight_file(self, fname, label) -> bool

        write features to file using svm light format

        Parameters:
        -----------

        fname:  filename to write to

        label:  Label object (number of labels must correspond to number of
        features)

        true if successful 
        """
        return _Features.SparseUlongFeatures_write_svmlight_file(*args)

    def dense_dot(*args):
        """
        dense_dot(self, alpha, num, vec, dim, b) -> unsigned long long
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.SparseUlongFeatures_dense_dot(*args)

SparseUlongFeatures_swigregister = _Features.SparseUlongFeatures_swigregister
SparseUlongFeatures_swigregister(SparseUlongFeatures)

class SparseShortRealFeatures(DotFeatures):
    """
    Template class SparseFeatures implements sparse matrices.

    Features are an array of TSparse, sorted w.r.t. vec_index (increasing)
    and withing same vec_index w.r.t. feat_index (increasing);

    Sparse feature vectors can be accessed via get_sparse_feature_vector()
    and should be freed (this operation is a NOP in most cases) via
    free_sparse_feature_vector().

    As this is a template class it can directly be used for different data
    types like sparse matrices of real valued, integer, byte etc type.

    C++ includes: SparseFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, SparseShortRealFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, SparseShortRealFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> SparseShortRealFeatures
        __init__(self) -> SparseShortRealFeatures
        __init__(self, src, copy=False) -> SparseShortRealFeatures
        __init__(self, src) -> SparseShortRealFeatures
        __init__(self, src) -> SparseShortRealFeatures
        __init__(self, orig) -> SparseShortRealFeatures
        __init__(self, fname) -> SparseShortRealFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_SparseShortRealFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_SparseShortRealFeatures
    __del__ = lambda self : None;
    def free_sparse_feature_matrix(*args):
        """
        free_sparse_feature_matrix(self)

        free sparse feature matrix 
        """
        return _Features.SparseShortRealFeatures_free_sparse_feature_matrix(*args)

    def free_sparse_features(*args):
        """
        free_sparse_features(self)

        free sparse feature matrix and cache 
        """
        return _Features.SparseShortRealFeatures_free_sparse_features(*args)

    def get_feature(*args):
        """
        get_feature(self, num, index) -> float

        get a single feature

        Parameters:
        -----------

        num:  number of feature vector to retrieve

        index:  index of feature in this vector

        sum of features that match dimension index and 0 if none is found 
        """
        return _Features.SparseShortRealFeatures_get_feature(*args)

    def get_full_feature_vector(*args):
        """
        get_full_feature_vector(self, num, len) -> float
        get_full_feature_vector(self, dst, num)

        get the fully expanded dense feature vector num

        Parameters:
        -----------

        dst:  feature vector

        len:  length is returned by reference

        num:  index of feature vector 
        """
        return _Features.SparseShortRealFeatures_get_full_feature_vector(*args)

    def get_sparse_feature_vector(*args):
        """
        get_sparse_feature_vector(self, num, len, vfree) -> shogun::TSparseEntry<(float)>

        get sparse feature vector for sample num from the matrix as it is if
        matrix is initialized, else return preprocessed compute_feature_vector

        Parameters:
        -----------

        num:  index of feature vector

        len:  number of sparse entries is returned by reference

        vfree:  whether returned vector must be freed by caller via
        free_sparse_feature_vector

        sparse feature vector 
        """
        return _Features.SparseShortRealFeatures_get_sparse_feature_vector(*args)

    def sparse_dot(*args):
        """
        sparse_dot(self, alpha, avec, alen, bvec, blen) -> float

        compute the dot product between two sparse feature vectors alpha *
        vec^T * vec

        Parameters:
        -----------

        alpha:  scalar to multiply with

        avec:  first sparse feature vector

        alen:  avec's length

        bvec:  second sparse feature vector

        blen:  bvec's length

        dot product between the two sparse feature vectors 
        """
        return _Features.SparseShortRealFeatures_sparse_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, num, vec, dim, abs_val=False)
        add_to_dense_vec(self, alpha, num, vec, dim)

        add a sparse feature vector onto a dense one dense+=alpha*sparse

        Parameters:
        -----------

        alpha:  scalar to multiply with

        num:  index of feature vector

        vec:  dense vector

        dim:  length of the dense vector

        abs_val:  if true, do dense+=alpha*abs(sparse) 
        """
        return _Features.SparseShortRealFeatures_add_to_dense_vec(*args)

    def free_sparse_feature_vector(*args):
        """
        free_sparse_feature_vector(self, feat_vec, num, free)

        free sparse feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of this vector in the cache

        free:  if vector should be really deleted 
        """
        return _Features.SparseShortRealFeatures_free_sparse_feature_vector(*args)

    def get_sparse_feature_matrix(*args):
        """
        get_sparse_feature_matrix(self, num_feat, num_vec) -> shogun::TSparse<(float)>
        get_sparse_feature_matrix(self, dst)

        get the pointer to the sparse feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        nnz:  number of nonzero elements 
        """
        return _Features.SparseShortRealFeatures_get_sparse_feature_matrix(*args)

    def clean_tsparse(*args):
        """
        clean_tsparse(self, sfm, num_vec)

        clean TSparse

        Parameters:
        -----------

        sfm:  sparse feature matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseShortRealFeatures_clean_tsparse(*args)

    def get_transposed(*args):
        """
        get_transposed(self, num_feat, num_vec) -> shogun::TSparse<(float)>

        compute and return the transpose of the sparse feature matrix which
        will be prepocessed. num_feat, num_vectors are returned by reference
        caller has to clean up

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        transposed sparse feature matrix 
        """
        return _Features.SparseShortRealFeatures_get_transposed(*args)

    def set_sparse_feature_matrix(*args):
        """
        set_sparse_feature_matrix(self, src)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        src:  new sparse feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseShortRealFeatures_set_sparse_feature_matrix(*args)

    def get_full_feature_matrix(*args):
        """
        get_full_feature_matrix(self, num_feat, num_vec) -> float
        get_full_feature_matrix(self, dst)

        gets a copy of a full feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseShortRealFeatures_get_full_feature_matrix(*args)

    def set_full_feature_matrix(*args):
        """
        set_full_feature_matrix(self, src) -> bool

        creates a sparse feature matrix from a full dense feature matrix
        necessary to set feature_matrix, num_features and num_vectors where
        num_features is the column offset, and columns are linear in memory
        see above for definition of sparse_feature_matrix

        Parameters:
        -----------

        src:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseShortRealFeatures_set_full_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.SparseShortRealFeatures_apply_preproc(*args)

    def obtain_from_simple(*args):
        """
        obtain_from_simple(self, sf) -> bool

        obtain sparse features from simple features

        Parameters:
        -----------

        sf:  simple features

        if obtaining was successful 
        """
        return _Features.SparseShortRealFeatures_obtain_from_simple(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.SparseShortRealFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num) ->  int

        set number of features

        Sometimes when loading sparse features not all possible dimensions are
        used. This may pose a problem to classifiers when being applied to
        higher dimensional test-data. This function allows to artificially
        explode the feature space

        Parameters:
        -----------

        num:  the number of features, must be larger than the current number
        of features

        previous number of features 
        """
        return _Features.SparseShortRealFeatures_set_num_features(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, free)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of vector in cache

        free:  if vector really should be deleted 
        """
        return _Features.SparseShortRealFeatures_free_feature_vector(*args)

    def get_num_nonzero_entries(*args):
        """
        get_num_nonzero_entries(self) -> int

        get number of non-zero entries in sparse feature matrix

        number of non-zero entries in sparse feature matrix 
        """
        return _Features.SparseShortRealFeatures_get_num_nonzero_entries(*args)

    def compute_squared(*args):
        """
        compute_squared(self, sq) -> float

        compute a^2 on all feature vectors

        Parameters:
        -----------

        sq:  the square for each vector is stored in here

        the square for each vector 
        """
        return _Features.SparseShortRealFeatures_compute_squared(*args)

    def compute_squared_norm(*args):
        """
        compute_squared_norm(self, lhs, sq_lhs, idx_a, rhs, sq_rhs, idx_b) -> float

        compute (a-b)^2 (== a^2+b^2+2ab) usually called by kernels'/distances'
        compute functions works on two feature vectors, although it is a
        member of a single feature: can either be called by lhs or rhs.

        Parameters:
        -----------

        lhs:  left-hand side features

        sq_lhs:  squared values of left-hand side

        idx_a:  index of left-hand side's vector to compute

        rhs:  right-hand side features

        sq_rhs:  squared values of right-hand side

        idx_b:  index of right-hand side's vector to compute 
        """
        return _Features.SparseShortRealFeatures_compute_squared_norm(*args)

    def load_svmlight_file(*args):
        """
        load_svmlight_file(self, fname, do_sort_features=True) -> Labels
        load_svmlight_file(self, fname) -> Labels

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        do_sort_features:  if true features will be sorted to ensure they are
        in ascending order

        label object with corresponding labels 
        """
        return _Features.SparseShortRealFeatures_load_svmlight_file(*args)

    def sort_features(*args):
        """
        sort_features(self)

        ensure that features occur in ascending order, only call when no
        preprocessors are attached 
        """
        return _Features.SparseShortRealFeatures_sort_features(*args)

    def write_svmlight_file(*args):
        """
        write_svmlight_file(self, fname, label) -> bool

        write features to file using svm light format

        Parameters:
        -----------

        fname:  filename to write to

        label:  Label object (number of labels must correspond to number of
        features)

        true if successful 
        """
        return _Features.SparseShortRealFeatures_write_svmlight_file(*args)

    def dense_dot(*args):
        """
        dense_dot(self, alpha, num, vec, dim, b) -> float
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.SparseShortRealFeatures_dense_dot(*args)

SparseShortRealFeatures_swigregister = _Features.SparseShortRealFeatures_swigregister
SparseShortRealFeatures_swigregister(SparseShortRealFeatures)

class SparseRealFeatures(DotFeatures):
    """
    Template class SparseFeatures implements sparse matrices.

    Features are an array of TSparse, sorted w.r.t. vec_index (increasing)
    and withing same vec_index w.r.t. feat_index (increasing);

    Sparse feature vectors can be accessed via get_sparse_feature_vector()
    and should be freed (this operation is a NOP in most cases) via
    free_sparse_feature_vector().

    As this is a template class it can directly be used for different data
    types like sparse matrices of real valued, integer, byte etc type.

    C++ includes: SparseFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, SparseRealFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, SparseRealFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> SparseRealFeatures
        __init__(self) -> SparseRealFeatures
        __init__(self, src, copy=False) -> SparseRealFeatures
        __init__(self, src) -> SparseRealFeatures
        __init__(self, src) -> SparseRealFeatures
        __init__(self, orig) -> SparseRealFeatures
        __init__(self, fname) -> SparseRealFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_SparseRealFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_SparseRealFeatures
    __del__ = lambda self : None;
    def free_sparse_feature_matrix(*args):
        """
        free_sparse_feature_matrix(self)

        free sparse feature matrix 
        """
        return _Features.SparseRealFeatures_free_sparse_feature_matrix(*args)

    def free_sparse_features(*args):
        """
        free_sparse_features(self)

        free sparse feature matrix and cache 
        """
        return _Features.SparseRealFeatures_free_sparse_features(*args)

    def get_feature(*args):
        """
        get_feature(self, num, index) -> float

        get a single feature

        Parameters:
        -----------

        num:  number of feature vector to retrieve

        index:  index of feature in this vector

        sum of features that match dimension index and 0 if none is found 
        """
        return _Features.SparseRealFeatures_get_feature(*args)

    def get_full_feature_vector(*args):
        """
        get_full_feature_vector(self, num, len) -> float
        get_full_feature_vector(self, dst, num)

        get the fully expanded dense feature vector num

        Parameters:
        -----------

        dst:  feature vector

        len:  length is returned by reference

        num:  index of feature vector 
        """
        return _Features.SparseRealFeatures_get_full_feature_vector(*args)

    def get_sparse_feature_vector(*args):
        """
        get_sparse_feature_vector(self, num, len, vfree) -> shogun::TSparseEntry<(double)>

        get sparse feature vector for sample num from the matrix as it is if
        matrix is initialized, else return preprocessed compute_feature_vector

        Parameters:
        -----------

        num:  index of feature vector

        len:  number of sparse entries is returned by reference

        vfree:  whether returned vector must be freed by caller via
        free_sparse_feature_vector

        sparse feature vector 
        """
        return _Features.SparseRealFeatures_get_sparse_feature_vector(*args)

    def sparse_dot(*args):
        """
        sparse_dot(self, alpha, avec, alen, bvec, blen) -> float

        compute the dot product between two sparse feature vectors alpha *
        vec^T * vec

        Parameters:
        -----------

        alpha:  scalar to multiply with

        avec:  first sparse feature vector

        alen:  avec's length

        bvec:  second sparse feature vector

        blen:  bvec's length

        dot product between the two sparse feature vectors 
        """
        return _Features.SparseRealFeatures_sparse_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, num, vec, dim, abs_val=False)
        add_to_dense_vec(self, alpha, num, vec, dim)

        add a sparse feature vector onto a dense one dense+=alpha*sparse

        Parameters:
        -----------

        alpha:  scalar to multiply with

        num:  index of feature vector

        vec:  dense vector

        dim:  length of the dense vector

        abs_val:  if true, do dense+=alpha*abs(sparse) 
        """
        return _Features.SparseRealFeatures_add_to_dense_vec(*args)

    def free_sparse_feature_vector(*args):
        """
        free_sparse_feature_vector(self, feat_vec, num, free)

        free sparse feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of this vector in the cache

        free:  if vector should be really deleted 
        """
        return _Features.SparseRealFeatures_free_sparse_feature_vector(*args)

    def get_sparse_feature_matrix(*args):
        """
        get_sparse_feature_matrix(self, num_feat, num_vec) -> shogun::TSparse<(double)>
        get_sparse_feature_matrix(self, dst)

        get the pointer to the sparse feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        nnz:  number of nonzero elements 
        """
        return _Features.SparseRealFeatures_get_sparse_feature_matrix(*args)

    def clean_tsparse(*args):
        """
        clean_tsparse(self, sfm, num_vec)

        clean TSparse

        Parameters:
        -----------

        sfm:  sparse feature matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseRealFeatures_clean_tsparse(*args)

    def get_transposed(*args):
        """
        get_transposed(self, num_feat, num_vec) -> shogun::TSparse<(double)>

        compute and return the transpose of the sparse feature matrix which
        will be prepocessed. num_feat, num_vectors are returned by reference
        caller has to clean up

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        transposed sparse feature matrix 
        """
        return _Features.SparseRealFeatures_get_transposed(*args)

    def set_sparse_feature_matrix(*args):
        """
        set_sparse_feature_matrix(self, src)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        src:  new sparse feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseRealFeatures_set_sparse_feature_matrix(*args)

    def get_full_feature_matrix(*args):
        """
        get_full_feature_matrix(self, num_feat, num_vec) -> float
        get_full_feature_matrix(self, dst)

        gets a copy of a full feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseRealFeatures_get_full_feature_matrix(*args)

    def set_full_feature_matrix(*args):
        """
        set_full_feature_matrix(self, src) -> bool

        creates a sparse feature matrix from a full dense feature matrix
        necessary to set feature_matrix, num_features and num_vectors where
        num_features is the column offset, and columns are linear in memory
        see above for definition of sparse_feature_matrix

        Parameters:
        -----------

        src:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseRealFeatures_set_full_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.SparseRealFeatures_apply_preproc(*args)

    def obtain_from_simple(*args):
        """
        obtain_from_simple(self, sf) -> bool

        obtain sparse features from simple features

        Parameters:
        -----------

        sf:  simple features

        if obtaining was successful 
        """
        return _Features.SparseRealFeatures_obtain_from_simple(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.SparseRealFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num) ->  int

        set number of features

        Sometimes when loading sparse features not all possible dimensions are
        used. This may pose a problem to classifiers when being applied to
        higher dimensional test-data. This function allows to artificially
        explode the feature space

        Parameters:
        -----------

        num:  the number of features, must be larger than the current number
        of features

        previous number of features 
        """
        return _Features.SparseRealFeatures_set_num_features(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, free)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of vector in cache

        free:  if vector really should be deleted 
        """
        return _Features.SparseRealFeatures_free_feature_vector(*args)

    def get_num_nonzero_entries(*args):
        """
        get_num_nonzero_entries(self) -> int

        get number of non-zero entries in sparse feature matrix

        number of non-zero entries in sparse feature matrix 
        """
        return _Features.SparseRealFeatures_get_num_nonzero_entries(*args)

    def compute_squared(*args):
        """
        compute_squared(self, sq) -> float

        compute a^2 on all feature vectors

        Parameters:
        -----------

        sq:  the square for each vector is stored in here

        the square for each vector 
        """
        return _Features.SparseRealFeatures_compute_squared(*args)

    def compute_squared_norm(*args):
        """
        compute_squared_norm(self, lhs, sq_lhs, idx_a, rhs, sq_rhs, idx_b) -> float

        compute (a-b)^2 (== a^2+b^2+2ab) usually called by kernels'/distances'
        compute functions works on two feature vectors, although it is a
        member of a single feature: can either be called by lhs or rhs.

        Parameters:
        -----------

        lhs:  left-hand side features

        sq_lhs:  squared values of left-hand side

        idx_a:  index of left-hand side's vector to compute

        rhs:  right-hand side features

        sq_rhs:  squared values of right-hand side

        idx_b:  index of right-hand side's vector to compute 
        """
        return _Features.SparseRealFeatures_compute_squared_norm(*args)

    def load_svmlight_file(*args):
        """
        load_svmlight_file(self, fname, do_sort_features=True) -> Labels
        load_svmlight_file(self, fname) -> Labels

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        do_sort_features:  if true features will be sorted to ensure they are
        in ascending order

        label object with corresponding labels 
        """
        return _Features.SparseRealFeatures_load_svmlight_file(*args)

    def sort_features(*args):
        """
        sort_features(self)

        ensure that features occur in ascending order, only call when no
        preprocessors are attached 
        """
        return _Features.SparseRealFeatures_sort_features(*args)

    def write_svmlight_file(*args):
        """
        write_svmlight_file(self, fname, label) -> bool

        write features to file using svm light format

        Parameters:
        -----------

        fname:  filename to write to

        label:  Label object (number of labels must correspond to number of
        features)

        true if successful 
        """
        return _Features.SparseRealFeatures_write_svmlight_file(*args)

    def dense_dot(*args):
        """
        dense_dot(self, alpha, num, vec, dim, b) -> float
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.SparseRealFeatures_dense_dot(*args)

SparseRealFeatures_swigregister = _Features.SparseRealFeatures_swigregister
SparseRealFeatures_swigregister(SparseRealFeatures)

class SparseLongRealFeatures(DotFeatures):
    """
    Template class SparseFeatures implements sparse matrices.

    Features are an array of TSparse, sorted w.r.t. vec_index (increasing)
    and withing same vec_index w.r.t. feat_index (increasing);

    Sparse feature vectors can be accessed via get_sparse_feature_vector()
    and should be freed (this operation is a NOP in most cases) via
    free_sparse_feature_vector().

    As this is a template class it can directly be used for different data
    types like sparse matrices of real valued, integer, byte etc type.

    C++ includes: SparseFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, SparseLongRealFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, SparseLongRealFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> SparseLongRealFeatures
        __init__(self) -> SparseLongRealFeatures
        __init__(self, src, copy=False) -> SparseLongRealFeatures
        __init__(self, src) -> SparseLongRealFeatures
        __init__(self, src, num_feat, num_vec) -> SparseLongRealFeatures
        __init__(self, orig) -> SparseLongRealFeatures
        __init__(self, fname) -> SparseLongRealFeatures

        constructor

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_SparseLongRealFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_SparseLongRealFeatures
    __del__ = lambda self : None;
    def free_sparse_feature_matrix(*args):
        """
        free_sparse_feature_matrix(self)

        free sparse feature matrix 
        """
        return _Features.SparseLongRealFeatures_free_sparse_feature_matrix(*args)

    def free_sparse_features(*args):
        """
        free_sparse_features(self)

        free sparse feature matrix and cache 
        """
        return _Features.SparseLongRealFeatures_free_sparse_features(*args)

    def get_feature(*args):
        """
        get_feature(self, num, index) -> long float

        get a single feature

        Parameters:
        -----------

        num:  number of feature vector to retrieve

        index:  index of feature in this vector

        sum of features that match dimension index and 0 if none is found 
        """
        return _Features.SparseLongRealFeatures_get_feature(*args)

    def get_full_feature_vector(*args):
        """
        get_full_feature_vector(self, num, len) -> long float
        get_full_feature_vector(self, dst, num)

        get the fully expanded dense feature vector num

        Parameters:
        -----------

        dst:  feature vector

        len:  length is returned by reference

        num:  index of feature vector 
        """
        return _Features.SparseLongRealFeatures_get_full_feature_vector(*args)

    def get_sparse_feature_vector(*args):
        """
        get_sparse_feature_vector(self, num, len, vfree) -> shogun::TSparseEntry<(long float)>

        get sparse feature vector for sample num from the matrix as it is if
        matrix is initialized, else return preprocessed compute_feature_vector

        Parameters:
        -----------

        num:  index of feature vector

        len:  number of sparse entries is returned by reference

        vfree:  whether returned vector must be freed by caller via
        free_sparse_feature_vector

        sparse feature vector 
        """
        return _Features.SparseLongRealFeatures_get_sparse_feature_vector(*args)

    def sparse_dot(*args):
        """
        sparse_dot(self, alpha, avec, alen, bvec, blen) -> long float

        compute the dot product between two sparse feature vectors alpha *
        vec^T * vec

        Parameters:
        -----------

        alpha:  scalar to multiply with

        avec:  first sparse feature vector

        alen:  avec's length

        bvec:  second sparse feature vector

        blen:  bvec's length

        dot product between the two sparse feature vectors 
        """
        return _Features.SparseLongRealFeatures_sparse_dot(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, num, vec, dim, abs_val=False)
        add_to_dense_vec(self, alpha, num, vec, dim)

        add a sparse feature vector onto a dense one dense+=alpha*sparse

        Parameters:
        -----------

        alpha:  scalar to multiply with

        num:  index of feature vector

        vec:  dense vector

        dim:  length of the dense vector

        abs_val:  if true, do dense+=alpha*abs(sparse) 
        """
        return _Features.SparseLongRealFeatures_add_to_dense_vec(*args)

    def free_sparse_feature_vector(*args):
        """
        free_sparse_feature_vector(self, feat_vec, num, free)

        free sparse feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of this vector in the cache

        free:  if vector should be really deleted 
        """
        return _Features.SparseLongRealFeatures_free_sparse_feature_vector(*args)

    def get_sparse_feature_matrix(*args):
        """
        get_sparse_feature_matrix(self, num_feat, num_vec) -> shogun::TSparse<(long float)>
        get_sparse_feature_matrix(self, dst)

        get the pointer to the sparse feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        nnz:  number of nonzero elements 
        """
        return _Features.SparseLongRealFeatures_get_sparse_feature_matrix(*args)

    def clean_tsparse(*args):
        """
        clean_tsparse(self, sfm, num_vec)

        clean TSparse

        Parameters:
        -----------

        sfm:  sparse feature matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseLongRealFeatures_clean_tsparse(*args)

    def get_transposed(*args):
        """
        get_transposed(self, num_feat, num_vec) -> shogun::TSparse<(long float)>

        compute and return the transpose of the sparse feature matrix which
        will be prepocessed. num_feat, num_vectors are returned by reference
        caller has to clean up

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        transposed sparse feature matrix 
        """
        return _Features.SparseLongRealFeatures_get_transposed(*args)

    def set_sparse_feature_matrix(*args):
        """
        set_sparse_feature_matrix(self, src)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        src:  new sparse feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseLongRealFeatures_set_sparse_feature_matrix(*args)

    def get_full_feature_matrix(*args):
        """
        get_full_feature_matrix(self, num_feat, num_vec) -> long float
        get_full_feature_matrix(self, dst)

        gets a copy of a full feature matrix (swig compatible)
        num_feat,num_vectors are returned by reference

        Parameters:
        -----------

        dst:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseLongRealFeatures_get_full_feature_matrix(*args)

    def set_full_feature_matrix(*args):
        """
        set_full_feature_matrix(self, src, num_feat, num_vec) -> bool

        creates a sparse feature matrix from a full dense feature matrix
        necessary to set feature_matrix, num_features and num_vectors where
        num_features is the column offset, and columns are linear in memory
        see above for definition of sparse_feature_matrix

        Parameters:
        -----------

        src:  full feature matrix

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.SparseLongRealFeatures_set_full_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.SparseLongRealFeatures_apply_preproc(*args)

    def obtain_from_simple(*args):
        """
        obtain_from_simple(self, sf) -> bool

        obtain sparse features from simple features

        Parameters:
        -----------

        sf:  simple features

        if obtaining was successful 
        """
        return _Features.SparseLongRealFeatures_obtain_from_simple(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.SparseLongRealFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num) ->  int

        set number of features

        Sometimes when loading sparse features not all possible dimensions are
        used. This may pose a problem to classifiers when being applied to
        higher dimensional test-data. This function allows to artificially
        explode the feature space

        Parameters:
        -----------

        num:  the number of features, must be larger than the current number
        of features

        previous number of features 
        """
        return _Features.SparseLongRealFeatures_set_num_features(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, free)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index of vector in cache

        free:  if vector really should be deleted 
        """
        return _Features.SparseLongRealFeatures_free_feature_vector(*args)

    def get_num_nonzero_entries(*args):
        """
        get_num_nonzero_entries(self) -> int

        get number of non-zero entries in sparse feature matrix

        number of non-zero entries in sparse feature matrix 
        """
        return _Features.SparseLongRealFeatures_get_num_nonzero_entries(*args)

    def compute_squared(*args):
        """
        compute_squared(self, sq) -> float

        compute a^2 on all feature vectors

        Parameters:
        -----------

        sq:  the square for each vector is stored in here

        the square for each vector 
        """
        return _Features.SparseLongRealFeatures_compute_squared(*args)

    def compute_squared_norm(*args):
        """
        compute_squared_norm(self, lhs, sq_lhs, idx_a, rhs, sq_rhs, idx_b) -> float

        compute (a-b)^2 (== a^2+b^2+2ab) usually called by kernels'/distances'
        compute functions works on two feature vectors, although it is a
        member of a single feature: can either be called by lhs or rhs.

        Parameters:
        -----------

        lhs:  left-hand side features

        sq_lhs:  squared values of left-hand side

        idx_a:  index of left-hand side's vector to compute

        rhs:  right-hand side features

        sq_rhs:  squared values of right-hand side

        idx_b:  index of right-hand side's vector to compute 
        """
        return _Features.SparseLongRealFeatures_compute_squared_norm(*args)

    def load_svmlight_file(*args):
        """
        load_svmlight_file(self, fname, do_sort_features=True) -> Labels
        load_svmlight_file(self, fname) -> Labels

        load features from file

        Parameters:
        -----------

        fname:  filename to load from

        do_sort_features:  if true features will be sorted to ensure they are
        in ascending order

        label object with corresponding labels 
        """
        return _Features.SparseLongRealFeatures_load_svmlight_file(*args)

    def sort_features(*args):
        """
        sort_features(self)

        ensure that features occur in ascending order, only call when no
        preprocessors are attached 
        """
        return _Features.SparseLongRealFeatures_sort_features(*args)

    def write_svmlight_file(*args):
        """
        write_svmlight_file(self, fname, label) -> bool

        write features to file using svm light format

        Parameters:
        -----------

        fname:  filename to write to

        label:  Label object (number of labels must correspond to number of
        features)

        true if successful 
        """
        return _Features.SparseLongRealFeatures_write_svmlight_file(*args)

    def dense_dot(*args):
        """
        dense_dot(self, alpha, num, vec, dim, b) -> long float
        dense_dot(self, vec_idx1, vec2, vec2_len) -> float

        compute dot product between vector1 and a dense vector

        Parameters:
        -----------

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector 
        """
        return _Features.SparseLongRealFeatures_dense_dot(*args)

SparseLongRealFeatures_swigregister = _Features.SparseLongRealFeatures_swigregister
SparseLongRealFeatures_swigregister(SparseLongRealFeatures)

class BoolFeatures(DotFeatures):
    """
    The class SimpleFeatures implements dense feature matrices.

    The feature matrices are stored en-block in memory in fortran order,
    i.e. column-by-column, where a column denotes a feature vector.

    There are get_num_vectors() many feature vectors, of dimension
    get_num_features(). To access a feature vector call
    get_feature_vector() and when you are done treating it call
    free_feature_vector(). While free_feature_vector() is a NOP in most
    cases feature vectors might have been generated on the fly (due to a
    number preprocessors being attached to them).

    From this template class a number the following dense feature matrix
    types are used and supported:

    bool matrix - CSimpleFeatures<bool>

    8bit str matrix - CSimpleFeatures<char>

    8bit Byte matrix - CSimpleFeatures<uint8_t>

    16bit Integer matrix - CSimpleFeatures<int16_t>

    16bit Word matrix - CSimpleFeatures<uint16_t>

    32bit Integer matrix - CSimpleFeatures<int32_t>

    32bit Unsigned Integer matrix - CSimpleFeatures<uint32_t>

    32bit Float matrix - CSimpleFeatures<float32_t>

    64bit Float matrix - CSimpleFeatures<float64_t>

    64bit Float matrix in a file - CRealFileFeatures

    64bit Tangent of posterior log-odds (TOP) features from HMM -
    CTOPFeatures

    64bit Fisher Kernel (FK) features from HMM - CTOPFeatures

    96bit Float matrix - CSimpleFeatures<floatmax_t>

    C++ includes: SimpleFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, BoolFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, BoolFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> BoolFeatures
        __init__(self) -> BoolFeatures
        __init__(self, orig) -> BoolFeatures
        __init__(self, src) -> BoolFeatures
        __init__(self, fname) -> BoolFeatures

        constructor

        NOT IMPLEMENTED!

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_BoolFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_BoolFeatures
    __del__ = lambda self : None;
    def free_feature_matrix(*args):
        """
        free_feature_matrix(self)

        free feature matrix 
        """
        return _Features.BoolFeatures_free_feature_matrix(*args)

    def free_features(*args):
        """
        free_features(self)

        free feature matrix and cache 
        """
        return _Features.BoolFeatures_free_features(*args)

    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)

        set feature vector num

        ( only available in-memory feature matrices )

        Parameters:
        -----------

        src:  vector

        len:  length of vector

        num:  index where to put vector to 
        """
        return _Features.BoolFeatures_set_feature_vector(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, num, len, dofree) -> bool
        get_feature_vector(self, dst, num)

        get feature vector num

        Parameters:
        -----------

        dst:  destination to store vector in

        len:  length of vector

        num:  index of vector 
        """
        return _Features.BoolFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.BoolFeatures_free_feature_vector(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)
        get_feature_matrix(self, num_feat, num_vec) -> bool

        get the pointer to the feature matrix num_feat,num_vectors are
        returned by reference

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        feature matrix 
        """
        return _Features.BoolFeatures_get_feature_matrix(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self, fm, num_feat, num_vec)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        fm:  feature matrix to se

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.BoolFeatures_set_feature_matrix(*args)

    def copy_feature_matrix(*args):
        """
        copy_feature_matrix(self, src)

        copy feature matrix store copy of feature_matrix, where num_features
        is the column offset, and columns are linear in memory see below for
        definition of feature_matrix

        Parameters:
        -----------

        src:  feature matrix to copy

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.BoolFeatures_copy_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.BoolFeatures_apply_preproc(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.BoolFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num)

        set number of features

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.BoolFeatures_set_num_features(*args)

    def set_num_vectors(*args):
        """
        set_num_vectors(self, num)

        set number of vectors

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.BoolFeatures_set_num_vectors(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.BoolFeatures_add_to_dense_vec(*args)

    def Align_char_features(*args):
        """
        Align_char_features(self, cf, Ref, gapCost) -> bool

        align strings and compute emperical kernel map based on alignment
        scores

        non functional code - needs updating

        Parameters:
        -----------

        cf:  strings to be aligned to reference

        Ref:  reference strings to be aligned to

        gapCost:  costs for a gap 
        """
        return _Features.BoolFeatures_Align_char_features(*args)

BoolFeatures_swigregister = _Features.BoolFeatures_swigregister
BoolFeatures_swigregister(BoolFeatures)

class CharFeatures(DotFeatures):
    """
    The class SimpleFeatures implements dense feature matrices.

    The feature matrices are stored en-block in memory in fortran order,
    i.e. column-by-column, where a column denotes a feature vector.

    There are get_num_vectors() many feature vectors, of dimension
    get_num_features(). To access a feature vector call
    get_feature_vector() and when you are done treating it call
    free_feature_vector(). While free_feature_vector() is a NOP in most
    cases feature vectors might have been generated on the fly (due to a
    number preprocessors being attached to them).

    From this template class a number the following dense feature matrix
    types are used and supported:

    bool matrix - CSimpleFeatures<bool>

    8bit str matrix - CSimpleFeatures<char>

    8bit Byte matrix - CSimpleFeatures<uint8_t>

    16bit Integer matrix - CSimpleFeatures<int16_t>

    16bit Word matrix - CSimpleFeatures<uint16_t>

    32bit Integer matrix - CSimpleFeatures<int32_t>

    32bit Unsigned Integer matrix - CSimpleFeatures<uint32_t>

    32bit Float matrix - CSimpleFeatures<float32_t>

    64bit Float matrix - CSimpleFeatures<float64_t>

    64bit Float matrix in a file - CRealFileFeatures

    64bit Tangent of posterior log-odds (TOP) features from HMM -
    CTOPFeatures

    64bit Fisher Kernel (FK) features from HMM - CTOPFeatures

    96bit Float matrix - CSimpleFeatures<floatmax_t>

    C++ includes: SimpleFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, CharFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, CharFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> CharFeatures
        __init__(self) -> CharFeatures
        __init__(self, orig) -> CharFeatures
        __init__(self, src) -> CharFeatures
        __init__(self, fname) -> CharFeatures

        constructor

        NOT IMPLEMENTED!

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_CharFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_CharFeatures
    __del__ = lambda self : None;
    def free_feature_matrix(*args):
        """
        free_feature_matrix(self)

        free feature matrix 
        """
        return _Features.CharFeatures_free_feature_matrix(*args)

    def free_features(*args):
        """
        free_features(self)

        free feature matrix and cache 
        """
        return _Features.CharFeatures_free_features(*args)

    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)

        set feature vector num

        ( only available in-memory feature matrices )

        Parameters:
        -----------

        src:  vector

        len:  length of vector

        num:  index where to put vector to 
        """
        return _Features.CharFeatures_set_feature_vector(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, num, len, dofree) -> str
        get_feature_vector(self, dst, num)

        get feature vector num

        Parameters:
        -----------

        dst:  destination to store vector in

        len:  length of vector

        num:  index of vector 
        """
        return _Features.CharFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.CharFeatures_free_feature_vector(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)
        get_feature_matrix(self, num_feat, num_vec) -> str

        get the pointer to the feature matrix num_feat,num_vectors are
        returned by reference

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        feature matrix 
        """
        return _Features.CharFeatures_get_feature_matrix(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self, fm, num_feat, num_vec)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        fm:  feature matrix to se

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.CharFeatures_set_feature_matrix(*args)

    def copy_feature_matrix(*args):
        """
        copy_feature_matrix(self, src)

        copy feature matrix store copy of feature_matrix, where num_features
        is the column offset, and columns are linear in memory see below for
        definition of feature_matrix

        Parameters:
        -----------

        src:  feature matrix to copy

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.CharFeatures_copy_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.CharFeatures_apply_preproc(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.CharFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num)

        set number of features

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.CharFeatures_set_num_features(*args)

    def set_num_vectors(*args):
        """
        set_num_vectors(self, num)

        set number of vectors

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.CharFeatures_set_num_vectors(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.CharFeatures_add_to_dense_vec(*args)

    def Align_char_features(*args):
        """
        Align_char_features(self, cf, Ref, gapCost) -> bool

        align strings and compute emperical kernel map based on alignment
        scores

        non functional code - needs updating

        Parameters:
        -----------

        cf:  strings to be aligned to reference

        Ref:  reference strings to be aligned to

        gapCost:  costs for a gap 
        """
        return _Features.CharFeatures_Align_char_features(*args)

CharFeatures_swigregister = _Features.CharFeatures_swigregister
CharFeatures_swigregister(CharFeatures)

class ByteFeatures(DotFeatures):
    """
    The class SimpleFeatures implements dense feature matrices.

    The feature matrices are stored en-block in memory in fortran order,
    i.e. column-by-column, where a column denotes a feature vector.

    There are get_num_vectors() many feature vectors, of dimension
    get_num_features(). To access a feature vector call
    get_feature_vector() and when you are done treating it call
    free_feature_vector(). While free_feature_vector() is a NOP in most
    cases feature vectors might have been generated on the fly (due to a
    number preprocessors being attached to them).

    From this template class a number the following dense feature matrix
    types are used and supported:

    bool matrix - CSimpleFeatures<bool>

    8bit str matrix - CSimpleFeatures<char>

    8bit Byte matrix - CSimpleFeatures<uint8_t>

    16bit Integer matrix - CSimpleFeatures<int16_t>

    16bit Word matrix - CSimpleFeatures<uint16_t>

    32bit Integer matrix - CSimpleFeatures<int32_t>

    32bit Unsigned Integer matrix - CSimpleFeatures<uint32_t>

    32bit Float matrix - CSimpleFeatures<float32_t>

    64bit Float matrix - CSimpleFeatures<float64_t>

    64bit Float matrix in a file - CRealFileFeatures

    64bit Tangent of posterior log-odds (TOP) features from HMM -
    CTOPFeatures

    64bit Fisher Kernel (FK) features from HMM - CTOPFeatures

    96bit Float matrix - CSimpleFeatures<floatmax_t>

    C++ includes: SimpleFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, ByteFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, ByteFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> ByteFeatures
        __init__(self) -> ByteFeatures
        __init__(self, orig) -> ByteFeatures
        __init__(self, src) -> ByteFeatures
        __init__(self, fname) -> ByteFeatures

        constructor

        NOT IMPLEMENTED!

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_ByteFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_ByteFeatures
    __del__ = lambda self : None;
    def free_feature_matrix(*args):
        """
        free_feature_matrix(self)

        free feature matrix 
        """
        return _Features.ByteFeatures_free_feature_matrix(*args)

    def free_features(*args):
        """
        free_features(self)

        free feature matrix and cache 
        """
        return _Features.ByteFeatures_free_features(*args)

    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)

        set feature vector num

        ( only available in-memory feature matrices )

        Parameters:
        -----------

        src:  vector

        len:  length of vector

        num:  index where to put vector to 
        """
        return _Features.ByteFeatures_set_feature_vector(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, num, len, dofree) -> unsigned str
        get_feature_vector(self, dst, num)

        get feature vector num

        Parameters:
        -----------

        dst:  destination to store vector in

        len:  length of vector

        num:  index of vector 
        """
        return _Features.ByteFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.ByteFeatures_free_feature_vector(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)
        get_feature_matrix(self, num_feat, num_vec) -> unsigned str

        get the pointer to the feature matrix num_feat,num_vectors are
        returned by reference

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        feature matrix 
        """
        return _Features.ByteFeatures_get_feature_matrix(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self, fm, num_feat, num_vec)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        fm:  feature matrix to se

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.ByteFeatures_set_feature_matrix(*args)

    def copy_feature_matrix(*args):
        """
        copy_feature_matrix(self, src)

        copy feature matrix store copy of feature_matrix, where num_features
        is the column offset, and columns are linear in memory see below for
        definition of feature_matrix

        Parameters:
        -----------

        src:  feature matrix to copy

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.ByteFeatures_copy_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.ByteFeatures_apply_preproc(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.ByteFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num)

        set number of features

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.ByteFeatures_set_num_features(*args)

    def set_num_vectors(*args):
        """
        set_num_vectors(self, num)

        set number of vectors

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.ByteFeatures_set_num_vectors(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.ByteFeatures_add_to_dense_vec(*args)

    def Align_char_features(*args):
        """
        Align_char_features(self, cf, Ref, gapCost) -> bool

        align strings and compute emperical kernel map based on alignment
        scores

        non functional code - needs updating

        Parameters:
        -----------

        cf:  strings to be aligned to reference

        Ref:  reference strings to be aligned to

        gapCost:  costs for a gap 
        """
        return _Features.ByteFeatures_Align_char_features(*args)

ByteFeatures_swigregister = _Features.ByteFeatures_swigregister
ByteFeatures_swigregister(ByteFeatures)

class WordFeatures(DotFeatures):
    """
    The class SimpleFeatures implements dense feature matrices.

    The feature matrices are stored en-block in memory in fortran order,
    i.e. column-by-column, where a column denotes a feature vector.

    There are get_num_vectors() many feature vectors, of dimension
    get_num_features(). To access a feature vector call
    get_feature_vector() and when you are done treating it call
    free_feature_vector(). While free_feature_vector() is a NOP in most
    cases feature vectors might have been generated on the fly (due to a
    number preprocessors being attached to them).

    From this template class a number the following dense feature matrix
    types are used and supported:

    bool matrix - CSimpleFeatures<bool>

    8bit str matrix - CSimpleFeatures<char>

    8bit Byte matrix - CSimpleFeatures<uint8_t>

    16bit Integer matrix - CSimpleFeatures<int16_t>

    16bit Word matrix - CSimpleFeatures<uint16_t>

    32bit Integer matrix - CSimpleFeatures<int32_t>

    32bit Unsigned Integer matrix - CSimpleFeatures<uint32_t>

    32bit Float matrix - CSimpleFeatures<float32_t>

    64bit Float matrix - CSimpleFeatures<float64_t>

    64bit Float matrix in a file - CRealFileFeatures

    64bit Tangent of posterior log-odds (TOP) features from HMM -
    CTOPFeatures

    64bit Fisher Kernel (FK) features from HMM - CTOPFeatures

    96bit Float matrix - CSimpleFeatures<floatmax_t>

    C++ includes: SimpleFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, WordFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, WordFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> WordFeatures
        __init__(self) -> WordFeatures
        __init__(self, orig) -> WordFeatures
        __init__(self, src) -> WordFeatures
        __init__(self, fname) -> WordFeatures

        constructor

        NOT IMPLEMENTED!

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_WordFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_WordFeatures
    __del__ = lambda self : None;
    def free_feature_matrix(*args):
        """
        free_feature_matrix(self)

        free feature matrix 
        """
        return _Features.WordFeatures_free_feature_matrix(*args)

    def free_features(*args):
        """
        free_features(self)

        free feature matrix and cache 
        """
        return _Features.WordFeatures_free_features(*args)

    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)

        set feature vector num

        ( only available in-memory feature matrices )

        Parameters:
        -----------

        src:  vector

        len:  length of vector

        num:  index where to put vector to 
        """
        return _Features.WordFeatures_set_feature_vector(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, num, len, dofree) -> unsigned short
        get_feature_vector(self, dst, num)

        get feature vector num

        Parameters:
        -----------

        dst:  destination to store vector in

        len:  length of vector

        num:  index of vector 
        """
        return _Features.WordFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.WordFeatures_free_feature_vector(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)
        get_feature_matrix(self, num_feat, num_vec) -> unsigned short

        get the pointer to the feature matrix num_feat,num_vectors are
        returned by reference

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        feature matrix 
        """
        return _Features.WordFeatures_get_feature_matrix(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self, fm, num_feat, num_vec)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        fm:  feature matrix to se

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.WordFeatures_set_feature_matrix(*args)

    def copy_feature_matrix(*args):
        """
        copy_feature_matrix(self, src)

        copy feature matrix store copy of feature_matrix, where num_features
        is the column offset, and columns are linear in memory see below for
        definition of feature_matrix

        Parameters:
        -----------

        src:  feature matrix to copy

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.WordFeatures_copy_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.WordFeatures_apply_preproc(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.WordFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num)

        set number of features

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.WordFeatures_set_num_features(*args)

    def set_num_vectors(*args):
        """
        set_num_vectors(self, num)

        set number of vectors

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.WordFeatures_set_num_vectors(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.WordFeatures_add_to_dense_vec(*args)

    def Align_char_features(*args):
        """
        Align_char_features(self, cf, Ref, gapCost) -> bool

        align strings and compute emperical kernel map based on alignment
        scores

        non functional code - needs updating

        Parameters:
        -----------

        cf:  strings to be aligned to reference

        Ref:  reference strings to be aligned to

        gapCost:  costs for a gap 
        """
        return _Features.WordFeatures_Align_char_features(*args)

WordFeatures_swigregister = _Features.WordFeatures_swigregister
WordFeatures_swigregister(WordFeatures)

class ShortFeatures(DotFeatures):
    """
    The class SimpleFeatures implements dense feature matrices.

    The feature matrices are stored en-block in memory in fortran order,
    i.e. column-by-column, where a column denotes a feature vector.

    There are get_num_vectors() many feature vectors, of dimension
    get_num_features(). To access a feature vector call
    get_feature_vector() and when you are done treating it call
    free_feature_vector(). While free_feature_vector() is a NOP in most
    cases feature vectors might have been generated on the fly (due to a
    number preprocessors being attached to them).

    From this template class a number the following dense feature matrix
    types are used and supported:

    bool matrix - CSimpleFeatures<bool>

    8bit str matrix - CSimpleFeatures<char>

    8bit Byte matrix - CSimpleFeatures<uint8_t>

    16bit Integer matrix - CSimpleFeatures<int16_t>

    16bit Word matrix - CSimpleFeatures<uint16_t>

    32bit Integer matrix - CSimpleFeatures<int32_t>

    32bit Unsigned Integer matrix - CSimpleFeatures<uint32_t>

    32bit Float matrix - CSimpleFeatures<float32_t>

    64bit Float matrix - CSimpleFeatures<float64_t>

    64bit Float matrix in a file - CRealFileFeatures

    64bit Tangent of posterior log-odds (TOP) features from HMM -
    CTOPFeatures

    64bit Fisher Kernel (FK) features from HMM - CTOPFeatures

    96bit Float matrix - CSimpleFeatures<floatmax_t>

    C++ includes: SimpleFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, ShortFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, ShortFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> ShortFeatures
        __init__(self) -> ShortFeatures
        __init__(self, orig) -> ShortFeatures
        __init__(self, src) -> ShortFeatures
        __init__(self, fname) -> ShortFeatures

        constructor

        NOT IMPLEMENTED!

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_ShortFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_ShortFeatures
    __del__ = lambda self : None;
    def free_feature_matrix(*args):
        """
        free_feature_matrix(self)

        free feature matrix 
        """
        return _Features.ShortFeatures_free_feature_matrix(*args)

    def free_features(*args):
        """
        free_features(self)

        free feature matrix and cache 
        """
        return _Features.ShortFeatures_free_features(*args)

    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)

        set feature vector num

        ( only available in-memory feature matrices )

        Parameters:
        -----------

        src:  vector

        len:  length of vector

        num:  index where to put vector to 
        """
        return _Features.ShortFeatures_set_feature_vector(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, num, len, dofree) -> short
        get_feature_vector(self, dst, num)

        get feature vector num

        Parameters:
        -----------

        dst:  destination to store vector in

        len:  length of vector

        num:  index of vector 
        """
        return _Features.ShortFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.ShortFeatures_free_feature_vector(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)
        get_feature_matrix(self, num_feat, num_vec) -> short

        get the pointer to the feature matrix num_feat,num_vectors are
        returned by reference

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        feature matrix 
        """
        return _Features.ShortFeatures_get_feature_matrix(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self, fm, num_feat, num_vec)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        fm:  feature matrix to se

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.ShortFeatures_set_feature_matrix(*args)

    def copy_feature_matrix(*args):
        """
        copy_feature_matrix(self, src)

        copy feature matrix store copy of feature_matrix, where num_features
        is the column offset, and columns are linear in memory see below for
        definition of feature_matrix

        Parameters:
        -----------

        src:  feature matrix to copy

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.ShortFeatures_copy_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.ShortFeatures_apply_preproc(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.ShortFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num)

        set number of features

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.ShortFeatures_set_num_features(*args)

    def set_num_vectors(*args):
        """
        set_num_vectors(self, num)

        set number of vectors

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.ShortFeatures_set_num_vectors(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.ShortFeatures_add_to_dense_vec(*args)

    def Align_char_features(*args):
        """
        Align_char_features(self, cf, Ref, gapCost) -> bool

        align strings and compute emperical kernel map based on alignment
        scores

        non functional code - needs updating

        Parameters:
        -----------

        cf:  strings to be aligned to reference

        Ref:  reference strings to be aligned to

        gapCost:  costs for a gap 
        """
        return _Features.ShortFeatures_Align_char_features(*args)

ShortFeatures_swigregister = _Features.ShortFeatures_swigregister
ShortFeatures_swigregister(ShortFeatures)

class IntFeatures(DotFeatures):
    """
    The class SimpleFeatures implements dense feature matrices.

    The feature matrices are stored en-block in memory in fortran order,
    i.e. column-by-column, where a column denotes a feature vector.

    There are get_num_vectors() many feature vectors, of dimension
    get_num_features(). To access a feature vector call
    get_feature_vector() and when you are done treating it call
    free_feature_vector(). While free_feature_vector() is a NOP in most
    cases feature vectors might have been generated on the fly (due to a
    number preprocessors being attached to them).

    From this template class a number the following dense feature matrix
    types are used and supported:

    bool matrix - CSimpleFeatures<bool>

    8bit str matrix - CSimpleFeatures<char>

    8bit Byte matrix - CSimpleFeatures<uint8_t>

    16bit Integer matrix - CSimpleFeatures<int16_t>

    16bit Word matrix - CSimpleFeatures<uint16_t>

    32bit Integer matrix - CSimpleFeatures<int32_t>

    32bit Unsigned Integer matrix - CSimpleFeatures<uint32_t>

    32bit Float matrix - CSimpleFeatures<float32_t>

    64bit Float matrix - CSimpleFeatures<float64_t>

    64bit Float matrix in a file - CRealFileFeatures

    64bit Tangent of posterior log-odds (TOP) features from HMM -
    CTOPFeatures

    64bit Fisher Kernel (FK) features from HMM - CTOPFeatures

    96bit Float matrix - CSimpleFeatures<floatmax_t>

    C++ includes: SimpleFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, IntFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, IntFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> IntFeatures
        __init__(self) -> IntFeatures
        __init__(self, orig) -> IntFeatures
        __init__(self, src) -> IntFeatures
        __init__(self, fname) -> IntFeatures

        constructor

        NOT IMPLEMENTED!

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_IntFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_IntFeatures
    __del__ = lambda self : None;
    def free_feature_matrix(*args):
        """
        free_feature_matrix(self)

        free feature matrix 
        """
        return _Features.IntFeatures_free_feature_matrix(*args)

    def free_features(*args):
        """
        free_features(self)

        free feature matrix and cache 
        """
        return _Features.IntFeatures_free_features(*args)

    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)

        set feature vector num

        ( only available in-memory feature matrices )

        Parameters:
        -----------

        src:  vector

        len:  length of vector

        num:  index where to put vector to 
        """
        return _Features.IntFeatures_set_feature_vector(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, num, len, dofree) -> int
        get_feature_vector(self, dst, num)

        get feature vector num

        Parameters:
        -----------

        dst:  destination to store vector in

        len:  length of vector

        num:  index of vector 
        """
        return _Features.IntFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.IntFeatures_free_feature_vector(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)
        get_feature_matrix(self, num_feat, num_vec) -> int

        get the pointer to the feature matrix num_feat,num_vectors are
        returned by reference

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        feature matrix 
        """
        return _Features.IntFeatures_get_feature_matrix(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self, fm, num_feat, num_vec)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        fm:  feature matrix to se

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.IntFeatures_set_feature_matrix(*args)

    def copy_feature_matrix(*args):
        """
        copy_feature_matrix(self, src)

        copy feature matrix store copy of feature_matrix, where num_features
        is the column offset, and columns are linear in memory see below for
        definition of feature_matrix

        Parameters:
        -----------

        src:  feature matrix to copy

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.IntFeatures_copy_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.IntFeatures_apply_preproc(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.IntFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num)

        set number of features

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.IntFeatures_set_num_features(*args)

    def set_num_vectors(*args):
        """
        set_num_vectors(self, num)

        set number of vectors

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.IntFeatures_set_num_vectors(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.IntFeatures_add_to_dense_vec(*args)

    def Align_char_features(*args):
        """
        Align_char_features(self, cf, Ref, gapCost) -> bool

        align strings and compute emperical kernel map based on alignment
        scores

        non functional code - needs updating

        Parameters:
        -----------

        cf:  strings to be aligned to reference

        Ref:  reference strings to be aligned to

        gapCost:  costs for a gap 
        """
        return _Features.IntFeatures_Align_char_features(*args)

IntFeatures_swigregister = _Features.IntFeatures_swigregister
IntFeatures_swigregister(IntFeatures)

class UIntFeatures(DotFeatures):
    """
    The class SimpleFeatures implements dense feature matrices.

    The feature matrices are stored en-block in memory in fortran order,
    i.e. column-by-column, where a column denotes a feature vector.

    There are get_num_vectors() many feature vectors, of dimension
    get_num_features(). To access a feature vector call
    get_feature_vector() and when you are done treating it call
    free_feature_vector(). While free_feature_vector() is a NOP in most
    cases feature vectors might have been generated on the fly (due to a
    number preprocessors being attached to them).

    From this template class a number the following dense feature matrix
    types are used and supported:

    bool matrix - CSimpleFeatures<bool>

    8bit str matrix - CSimpleFeatures<char>

    8bit Byte matrix - CSimpleFeatures<uint8_t>

    16bit Integer matrix - CSimpleFeatures<int16_t>

    16bit Word matrix - CSimpleFeatures<uint16_t>

    32bit Integer matrix - CSimpleFeatures<int32_t>

    32bit Unsigned Integer matrix - CSimpleFeatures<uint32_t>

    32bit Float matrix - CSimpleFeatures<float32_t>

    64bit Float matrix - CSimpleFeatures<float64_t>

    64bit Float matrix in a file - CRealFileFeatures

    64bit Tangent of posterior log-odds (TOP) features from HMM -
    CTOPFeatures

    64bit Fisher Kernel (FK) features from HMM - CTOPFeatures

    96bit Float matrix - CSimpleFeatures<floatmax_t>

    C++ includes: SimpleFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, UIntFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, UIntFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> UIntFeatures
        __init__(self) -> UIntFeatures
        __init__(self, orig) -> UIntFeatures
        __init__(self, src) -> UIntFeatures
        __init__(self, fname) -> UIntFeatures

        constructor

        NOT IMPLEMENTED!

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_UIntFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_UIntFeatures
    __del__ = lambda self : None;
    def free_feature_matrix(*args):
        """
        free_feature_matrix(self)

        free feature matrix 
        """
        return _Features.UIntFeatures_free_feature_matrix(*args)

    def free_features(*args):
        """
        free_features(self)

        free feature matrix and cache 
        """
        return _Features.UIntFeatures_free_features(*args)

    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)

        set feature vector num

        ( only available in-memory feature matrices )

        Parameters:
        -----------

        src:  vector

        len:  length of vector

        num:  index where to put vector to 
        """
        return _Features.UIntFeatures_set_feature_vector(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, num, len, dofree) -> unsigned int
        get_feature_vector(self, dst, num)

        get feature vector num

        Parameters:
        -----------

        dst:  destination to store vector in

        len:  length of vector

        num:  index of vector 
        """
        return _Features.UIntFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.UIntFeatures_free_feature_vector(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)
        get_feature_matrix(self, num_feat, num_vec) -> unsigned int

        get the pointer to the feature matrix num_feat,num_vectors are
        returned by reference

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        feature matrix 
        """
        return _Features.UIntFeatures_get_feature_matrix(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self, fm, num_feat, num_vec)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        fm:  feature matrix to se

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.UIntFeatures_set_feature_matrix(*args)

    def copy_feature_matrix(*args):
        """
        copy_feature_matrix(self, src)

        copy feature matrix store copy of feature_matrix, where num_features
        is the column offset, and columns are linear in memory see below for
        definition of feature_matrix

        Parameters:
        -----------

        src:  feature matrix to copy

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.UIntFeatures_copy_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.UIntFeatures_apply_preproc(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.UIntFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num)

        set number of features

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.UIntFeatures_set_num_features(*args)

    def set_num_vectors(*args):
        """
        set_num_vectors(self, num)

        set number of vectors

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.UIntFeatures_set_num_vectors(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.UIntFeatures_add_to_dense_vec(*args)

    def Align_char_features(*args):
        """
        Align_char_features(self, cf, Ref, gapCost) -> bool

        align strings and compute emperical kernel map based on alignment
        scores

        non functional code - needs updating

        Parameters:
        -----------

        cf:  strings to be aligned to reference

        Ref:  reference strings to be aligned to

        gapCost:  costs for a gap 
        """
        return _Features.UIntFeatures_Align_char_features(*args)

UIntFeatures_swigregister = _Features.UIntFeatures_swigregister
UIntFeatures_swigregister(UIntFeatures)

class LongIntFeatures(DotFeatures):
    """
    The class SimpleFeatures implements dense feature matrices.

    The feature matrices are stored en-block in memory in fortran order,
    i.e. column-by-column, where a column denotes a feature vector.

    There are get_num_vectors() many feature vectors, of dimension
    get_num_features(). To access a feature vector call
    get_feature_vector() and when you are done treating it call
    free_feature_vector(). While free_feature_vector() is a NOP in most
    cases feature vectors might have been generated on the fly (due to a
    number preprocessors being attached to them).

    From this template class a number the following dense feature matrix
    types are used and supported:

    bool matrix - CSimpleFeatures<bool>

    8bit str matrix - CSimpleFeatures<char>

    8bit Byte matrix - CSimpleFeatures<uint8_t>

    16bit Integer matrix - CSimpleFeatures<int16_t>

    16bit Word matrix - CSimpleFeatures<uint16_t>

    32bit Integer matrix - CSimpleFeatures<int32_t>

    32bit Unsigned Integer matrix - CSimpleFeatures<uint32_t>

    32bit Float matrix - CSimpleFeatures<float32_t>

    64bit Float matrix - CSimpleFeatures<float64_t>

    64bit Float matrix in a file - CRealFileFeatures

    64bit Tangent of posterior log-odds (TOP) features from HMM -
    CTOPFeatures

    64bit Fisher Kernel (FK) features from HMM - CTOPFeatures

    96bit Float matrix - CSimpleFeatures<floatmax_t>

    C++ includes: SimpleFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, LongIntFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, LongIntFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> LongIntFeatures
        __init__(self) -> LongIntFeatures
        __init__(self, orig) -> LongIntFeatures
        __init__(self, src) -> LongIntFeatures
        __init__(self, fname) -> LongIntFeatures

        constructor

        NOT IMPLEMENTED!

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_LongIntFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_LongIntFeatures
    __del__ = lambda self : None;
    def free_feature_matrix(*args):
        """
        free_feature_matrix(self)

        free feature matrix 
        """
        return _Features.LongIntFeatures_free_feature_matrix(*args)

    def free_features(*args):
        """
        free_features(self)

        free feature matrix and cache 
        """
        return _Features.LongIntFeatures_free_features(*args)

    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)

        set feature vector num

        ( only available in-memory feature matrices )

        Parameters:
        -----------

        src:  vector

        len:  length of vector

        num:  index where to put vector to 
        """
        return _Features.LongIntFeatures_set_feature_vector(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, num, len, dofree) -> long long
        get_feature_vector(self, dst, num)

        get feature vector num

        Parameters:
        -----------

        dst:  destination to store vector in

        len:  length of vector

        num:  index of vector 
        """
        return _Features.LongIntFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.LongIntFeatures_free_feature_vector(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)
        get_feature_matrix(self, num_feat, num_vec) -> long long

        get the pointer to the feature matrix num_feat,num_vectors are
        returned by reference

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        feature matrix 
        """
        return _Features.LongIntFeatures_get_feature_matrix(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self, fm, num_feat, num_vec)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        fm:  feature matrix to se

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.LongIntFeatures_set_feature_matrix(*args)

    def copy_feature_matrix(*args):
        """
        copy_feature_matrix(self, src)

        copy feature matrix store copy of feature_matrix, where num_features
        is the column offset, and columns are linear in memory see below for
        definition of feature_matrix

        Parameters:
        -----------

        src:  feature matrix to copy

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.LongIntFeatures_copy_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.LongIntFeatures_apply_preproc(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.LongIntFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num)

        set number of features

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.LongIntFeatures_set_num_features(*args)

    def set_num_vectors(*args):
        """
        set_num_vectors(self, num)

        set number of vectors

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.LongIntFeatures_set_num_vectors(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.LongIntFeatures_add_to_dense_vec(*args)

    def Align_char_features(*args):
        """
        Align_char_features(self, cf, Ref, gapCost) -> bool

        align strings and compute emperical kernel map based on alignment
        scores

        non functional code - needs updating

        Parameters:
        -----------

        cf:  strings to be aligned to reference

        Ref:  reference strings to be aligned to

        gapCost:  costs for a gap 
        """
        return _Features.LongIntFeatures_Align_char_features(*args)

LongIntFeatures_swigregister = _Features.LongIntFeatures_swigregister
LongIntFeatures_swigregister(LongIntFeatures)

class ULongIntFeatures(DotFeatures):
    """
    The class SimpleFeatures implements dense feature matrices.

    The feature matrices are stored en-block in memory in fortran order,
    i.e. column-by-column, where a column denotes a feature vector.

    There are get_num_vectors() many feature vectors, of dimension
    get_num_features(). To access a feature vector call
    get_feature_vector() and when you are done treating it call
    free_feature_vector(). While free_feature_vector() is a NOP in most
    cases feature vectors might have been generated on the fly (due to a
    number preprocessors being attached to them).

    From this template class a number the following dense feature matrix
    types are used and supported:

    bool matrix - CSimpleFeatures<bool>

    8bit str matrix - CSimpleFeatures<char>

    8bit Byte matrix - CSimpleFeatures<uint8_t>

    16bit Integer matrix - CSimpleFeatures<int16_t>

    16bit Word matrix - CSimpleFeatures<uint16_t>

    32bit Integer matrix - CSimpleFeatures<int32_t>

    32bit Unsigned Integer matrix - CSimpleFeatures<uint32_t>

    32bit Float matrix - CSimpleFeatures<float32_t>

    64bit Float matrix - CSimpleFeatures<float64_t>

    64bit Float matrix in a file - CRealFileFeatures

    64bit Tangent of posterior log-odds (TOP) features from HMM -
    CTOPFeatures

    64bit Fisher Kernel (FK) features from HMM - CTOPFeatures

    96bit Float matrix - CSimpleFeatures<floatmax_t>

    C++ includes: SimpleFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, ULongIntFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, ULongIntFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> ULongIntFeatures
        __init__(self) -> ULongIntFeatures
        __init__(self, orig) -> ULongIntFeatures
        __init__(self, src) -> ULongIntFeatures
        __init__(self, fname) -> ULongIntFeatures

        constructor

        NOT IMPLEMENTED!

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_ULongIntFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_ULongIntFeatures
    __del__ = lambda self : None;
    def free_feature_matrix(*args):
        """
        free_feature_matrix(self)

        free feature matrix 
        """
        return _Features.ULongIntFeatures_free_feature_matrix(*args)

    def free_features(*args):
        """
        free_features(self)

        free feature matrix and cache 
        """
        return _Features.ULongIntFeatures_free_features(*args)

    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)

        set feature vector num

        ( only available in-memory feature matrices )

        Parameters:
        -----------

        src:  vector

        len:  length of vector

        num:  index where to put vector to 
        """
        return _Features.ULongIntFeatures_set_feature_vector(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, num, len, dofree) -> unsigned long long
        get_feature_vector(self, dst, num)

        get feature vector num

        Parameters:
        -----------

        dst:  destination to store vector in

        len:  length of vector

        num:  index of vector 
        """
        return _Features.ULongIntFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.ULongIntFeatures_free_feature_vector(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)
        get_feature_matrix(self, num_feat, num_vec) -> unsigned long long

        get the pointer to the feature matrix num_feat,num_vectors are
        returned by reference

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        feature matrix 
        """
        return _Features.ULongIntFeatures_get_feature_matrix(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self, fm, num_feat, num_vec)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        fm:  feature matrix to se

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.ULongIntFeatures_set_feature_matrix(*args)

    def copy_feature_matrix(*args):
        """
        copy_feature_matrix(self, src)

        copy feature matrix store copy of feature_matrix, where num_features
        is the column offset, and columns are linear in memory see below for
        definition of feature_matrix

        Parameters:
        -----------

        src:  feature matrix to copy

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.ULongIntFeatures_copy_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.ULongIntFeatures_apply_preproc(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.ULongIntFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num)

        set number of features

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.ULongIntFeatures_set_num_features(*args)

    def set_num_vectors(*args):
        """
        set_num_vectors(self, num)

        set number of vectors

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.ULongIntFeatures_set_num_vectors(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.ULongIntFeatures_add_to_dense_vec(*args)

    def Align_char_features(*args):
        """
        Align_char_features(self, cf, Ref, gapCost) -> bool

        align strings and compute emperical kernel map based on alignment
        scores

        non functional code - needs updating

        Parameters:
        -----------

        cf:  strings to be aligned to reference

        Ref:  reference strings to be aligned to

        gapCost:  costs for a gap 
        """
        return _Features.ULongIntFeatures_Align_char_features(*args)

ULongIntFeatures_swigregister = _Features.ULongIntFeatures_swigregister
ULongIntFeatures_swigregister(ULongIntFeatures)

class ShortRealFeatures(DotFeatures):
    """
    The class SimpleFeatures implements dense feature matrices.

    The feature matrices are stored en-block in memory in fortran order,
    i.e. column-by-column, where a column denotes a feature vector.

    There are get_num_vectors() many feature vectors, of dimension
    get_num_features(). To access a feature vector call
    get_feature_vector() and when you are done treating it call
    free_feature_vector(). While free_feature_vector() is a NOP in most
    cases feature vectors might have been generated on the fly (due to a
    number preprocessors being attached to them).

    From this template class a number the following dense feature matrix
    types are used and supported:

    bool matrix - CSimpleFeatures<bool>

    8bit str matrix - CSimpleFeatures<char>

    8bit Byte matrix - CSimpleFeatures<uint8_t>

    16bit Integer matrix - CSimpleFeatures<int16_t>

    16bit Word matrix - CSimpleFeatures<uint16_t>

    32bit Integer matrix - CSimpleFeatures<int32_t>

    32bit Unsigned Integer matrix - CSimpleFeatures<uint32_t>

    32bit Float matrix - CSimpleFeatures<float32_t>

    64bit Float matrix - CSimpleFeatures<float64_t>

    64bit Float matrix in a file - CRealFileFeatures

    64bit Tangent of posterior log-odds (TOP) features from HMM -
    CTOPFeatures

    64bit Fisher Kernel (FK) features from HMM - CTOPFeatures

    96bit Float matrix - CSimpleFeatures<floatmax_t>

    C++ includes: SimpleFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, ShortRealFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, ShortRealFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> ShortRealFeatures
        __init__(self) -> ShortRealFeatures
        __init__(self, orig) -> ShortRealFeatures
        __init__(self, src) -> ShortRealFeatures
        __init__(self, fname) -> ShortRealFeatures

        constructor

        NOT IMPLEMENTED!

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_ShortRealFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_ShortRealFeatures
    __del__ = lambda self : None;
    def free_feature_matrix(*args):
        """
        free_feature_matrix(self)

        free feature matrix 
        """
        return _Features.ShortRealFeatures_free_feature_matrix(*args)

    def free_features(*args):
        """
        free_features(self)

        free feature matrix and cache 
        """
        return _Features.ShortRealFeatures_free_features(*args)

    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)

        set feature vector num

        ( only available in-memory feature matrices )

        Parameters:
        -----------

        src:  vector

        len:  length of vector

        num:  index where to put vector to 
        """
        return _Features.ShortRealFeatures_set_feature_vector(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, num, len, dofree) -> float
        get_feature_vector(self, dst, num)

        get feature vector num

        Parameters:
        -----------

        dst:  destination to store vector in

        len:  length of vector

        num:  index of vector 
        """
        return _Features.ShortRealFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.ShortRealFeatures_free_feature_vector(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)
        get_feature_matrix(self, num_feat, num_vec) -> float

        get the pointer to the feature matrix num_feat,num_vectors are
        returned by reference

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        feature matrix 
        """
        return _Features.ShortRealFeatures_get_feature_matrix(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self, fm, num_feat, num_vec)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        fm:  feature matrix to se

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.ShortRealFeatures_set_feature_matrix(*args)

    def copy_feature_matrix(*args):
        """
        copy_feature_matrix(self, src)

        copy feature matrix store copy of feature_matrix, where num_features
        is the column offset, and columns are linear in memory see below for
        definition of feature_matrix

        Parameters:
        -----------

        src:  feature matrix to copy

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.ShortRealFeatures_copy_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.ShortRealFeatures_apply_preproc(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.ShortRealFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num)

        set number of features

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.ShortRealFeatures_set_num_features(*args)

    def set_num_vectors(*args):
        """
        set_num_vectors(self, num)

        set number of vectors

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.ShortRealFeatures_set_num_vectors(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.ShortRealFeatures_add_to_dense_vec(*args)

    def Align_char_features(*args):
        """
        Align_char_features(self, cf, Ref, gapCost) -> bool

        align strings and compute emperical kernel map based on alignment
        scores

        non functional code - needs updating

        Parameters:
        -----------

        cf:  strings to be aligned to reference

        Ref:  reference strings to be aligned to

        gapCost:  costs for a gap 
        """
        return _Features.ShortRealFeatures_Align_char_features(*args)

ShortRealFeatures_swigregister = _Features.ShortRealFeatures_swigregister
ShortRealFeatures_swigregister(ShortRealFeatures)

class RealFeatures(DotFeatures):
    """
    The class SimpleFeatures implements dense feature matrices.

    The feature matrices are stored en-block in memory in fortran order,
    i.e. column-by-column, where a column denotes a feature vector.

    There are get_num_vectors() many feature vectors, of dimension
    get_num_features(). To access a feature vector call
    get_feature_vector() and when you are done treating it call
    free_feature_vector(). While free_feature_vector() is a NOP in most
    cases feature vectors might have been generated on the fly (due to a
    number preprocessors being attached to them).

    From this template class a number the following dense feature matrix
    types are used and supported:

    bool matrix - CSimpleFeatures<bool>

    8bit str matrix - CSimpleFeatures<char>

    8bit Byte matrix - CSimpleFeatures<uint8_t>

    16bit Integer matrix - CSimpleFeatures<int16_t>

    16bit Word matrix - CSimpleFeatures<uint16_t>

    32bit Integer matrix - CSimpleFeatures<int32_t>

    32bit Unsigned Integer matrix - CSimpleFeatures<uint32_t>

    32bit Float matrix - CSimpleFeatures<float32_t>

    64bit Float matrix - CSimpleFeatures<float64_t>

    64bit Float matrix in a file - CRealFileFeatures

    64bit Tangent of posterior log-odds (TOP) features from HMM -
    CTOPFeatures

    64bit Fisher Kernel (FK) features from HMM - CTOPFeatures

    96bit Float matrix - CSimpleFeatures<floatmax_t>

    C++ includes: SimpleFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, RealFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, RealFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> RealFeatures
        __init__(self) -> RealFeatures
        __init__(self, orig) -> RealFeatures
        __init__(self, src) -> RealFeatures
        __init__(self, fname) -> RealFeatures

        constructor

        NOT IMPLEMENTED!

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_RealFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_RealFeatures
    __del__ = lambda self : None;
    def free_feature_matrix(*args):
        """
        free_feature_matrix(self)

        free feature matrix 
        """
        return _Features.RealFeatures_free_feature_matrix(*args)

    def free_features(*args):
        """
        free_features(self)

        free feature matrix and cache 
        """
        return _Features.RealFeatures_free_features(*args)

    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)

        set feature vector num

        ( only available in-memory feature matrices )

        Parameters:
        -----------

        src:  vector

        len:  length of vector

        num:  index where to put vector to 
        """
        return _Features.RealFeatures_set_feature_vector(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, num, len, dofree) -> float
        get_feature_vector(self, dst, num)

        get feature vector num

        Parameters:
        -----------

        dst:  destination to store vector in

        len:  length of vector

        num:  index of vector 
        """
        return _Features.RealFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.RealFeatures_free_feature_vector(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)
        get_feature_matrix(self, num_feat, num_vec) -> float

        get the pointer to the feature matrix num_feat,num_vectors are
        returned by reference

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        feature matrix 
        """
        return _Features.RealFeatures_get_feature_matrix(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self, fm, num_feat, num_vec)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        fm:  feature matrix to se

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.RealFeatures_set_feature_matrix(*args)

    def copy_feature_matrix(*args):
        """
        copy_feature_matrix(self, src)

        copy feature matrix store copy of feature_matrix, where num_features
        is the column offset, and columns are linear in memory see below for
        definition of feature_matrix

        Parameters:
        -----------

        src:  feature matrix to copy

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.RealFeatures_copy_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.RealFeatures_apply_preproc(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.RealFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num)

        set number of features

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.RealFeatures_set_num_features(*args)

    def set_num_vectors(*args):
        """
        set_num_vectors(self, num)

        set number of vectors

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.RealFeatures_set_num_vectors(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.RealFeatures_add_to_dense_vec(*args)

    def Align_char_features(*args):
        """
        Align_char_features(self, cf, Ref, gapCost) -> bool

        align strings and compute emperical kernel map based on alignment
        scores

        non functional code - needs updating

        Parameters:
        -----------

        cf:  strings to be aligned to reference

        Ref:  reference strings to be aligned to

        gapCost:  costs for a gap 
        """
        return _Features.RealFeatures_Align_char_features(*args)

RealFeatures_swigregister = _Features.RealFeatures_swigregister
RealFeatures_swigregister(RealFeatures)

class LongRealFeatures(DotFeatures):
    """
    The class SimpleFeatures implements dense feature matrices.

    The feature matrices are stored en-block in memory in fortran order,
    i.e. column-by-column, where a column denotes a feature vector.

    There are get_num_vectors() many feature vectors, of dimension
    get_num_features(). To access a feature vector call
    get_feature_vector() and when you are done treating it call
    free_feature_vector(). While free_feature_vector() is a NOP in most
    cases feature vectors might have been generated on the fly (due to a
    number preprocessors being attached to them).

    From this template class a number the following dense feature matrix
    types are used and supported:

    bool matrix - CSimpleFeatures<bool>

    8bit str matrix - CSimpleFeatures<char>

    8bit Byte matrix - CSimpleFeatures<uint8_t>

    16bit Integer matrix - CSimpleFeatures<int16_t>

    16bit Word matrix - CSimpleFeatures<uint16_t>

    32bit Integer matrix - CSimpleFeatures<int32_t>

    32bit Unsigned Integer matrix - CSimpleFeatures<uint32_t>

    32bit Float matrix - CSimpleFeatures<float32_t>

    64bit Float matrix - CSimpleFeatures<float64_t>

    64bit Float matrix in a file - CRealFileFeatures

    64bit Tangent of posterior log-odds (TOP) features from HMM -
    CTOPFeatures

    64bit Fisher Kernel (FK) features from HMM - CTOPFeatures

    96bit Float matrix - CSimpleFeatures<floatmax_t>

    C++ includes: SimpleFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, LongRealFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, LongRealFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size=0) -> LongRealFeatures
        __init__(self) -> LongRealFeatures
        __init__(self, orig) -> LongRealFeatures
        __init__(self, src, num_feat, num_vec) -> LongRealFeatures
        __init__(self, fname) -> LongRealFeatures

        constructor

        NOT IMPLEMENTED!

        Parameters:
        -----------

        fname:  filename to load features from 
        """
        this = _Features.new_LongRealFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_LongRealFeatures
    __del__ = lambda self : None;
    def free_feature_matrix(*args):
        """
        free_feature_matrix(self)

        free feature matrix 
        """
        return _Features.LongRealFeatures_free_feature_matrix(*args)

    def free_features(*args):
        """
        free_features(self)

        free feature matrix and cache 
        """
        return _Features.LongRealFeatures_free_features(*args)

    def set_feature_vector(*args):
        """
        set_feature_vector(self, src, num)

        set feature vector num

        ( only available in-memory feature matrices )

        Parameters:
        -----------

        src:  vector

        len:  length of vector

        num:  index where to put vector to 
        """
        return _Features.LongRealFeatures_set_feature_vector(*args)

    def get_feature_vector(*args):
        """
        get_feature_vector(self, num, len, dofree) -> long float
        get_feature_vector(self, dst, num)

        get feature vector num

        Parameters:
        -----------

        dst:  destination to store vector in

        len:  length of vector

        num:  index of vector 
        """
        return _Features.LongRealFeatures_get_feature_vector(*args)

    def free_feature_vector(*args):
        """
        free_feature_vector(self, feat_vec, num, dofree)

        free feature vector

        Parameters:
        -----------

        feat_vec:  feature vector to free

        num:  index in feature cache

        dofree:  if vector should be really deleted 
        """
        return _Features.LongRealFeatures_free_feature_vector(*args)

    def get_feature_matrix(*args):
        """
        get_feature_matrix(self, dst)
        get_feature_matrix(self, num_feat, num_vec) -> long float

        get the pointer to the feature matrix num_feat,num_vectors are
        returned by reference

        Parameters:
        -----------

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix

        feature matrix 
        """
        return _Features.LongRealFeatures_get_feature_matrix(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self, fm, num_feat, num_vec)

        set feature matrix necessary to set feature_matrix, num_features,
        num_vectors, where num_features is the column offset, and columns are
        linear in memory see below for definition of feature_matrix

        Parameters:
        -----------

        fm:  feature matrix to se

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.LongRealFeatures_set_feature_matrix(*args)

    def copy_feature_matrix(*args):
        """
        copy_feature_matrix(self, src, num_feat, num_vec)

        copy feature matrix store copy of feature_matrix, where num_features
        is the column offset, and columns are linear in memory see below for
        definition of feature_matrix

        Parameters:
        -----------

        src:  feature matrix to copy

        num_feat:  number of features in matrix

        num_vec:  number of vectors in matrix 
        """
        return _Features.LongRealFeatures_copy_feature_matrix(*args)

    def apply_preproc(*args):
        """
        apply_preproc(self, force_preprocessing=False) -> bool
        apply_preproc(self) -> bool

        apply preprocessor

        Parameters:
        -----------

        force_preprocessing:  if preprocssing shall be forced

        if applying was successful 
        """
        return _Features.LongRealFeatures_apply_preproc(*args)

    def get_num_features(*args):
        """
        get_num_features(self) ->  int

        get number of features

        number of features 
        """
        return _Features.LongRealFeatures_get_num_features(*args)

    def set_num_features(*args):
        """
        set_num_features(self, num)

        set number of features

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.LongRealFeatures_set_num_features(*args)

    def set_num_vectors(*args):
        """
        set_num_vectors(self, num)

        set number of vectors

        Parameters:
        -----------

        num:  number to set 
        """
        return _Features.LongRealFeatures_set_num_vectors(*args)

    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.LongRealFeatures_add_to_dense_vec(*args)

    def Align_char_features(*args):
        """
        Align_char_features(self, cf, Ref, gapCost) -> bool

        align strings and compute emperical kernel map based on alignment
        scores

        non functional code - needs updating

        Parameters:
        -----------

        cf:  strings to be aligned to reference

        Ref:  reference strings to be aligned to

        gapCost:  costs for a gap 
        """
        return _Features.LongRealFeatures_Align_char_features(*args)

LongRealFeatures_swigregister = _Features.LongRealFeatures_swigregister
LongRealFeatures_swigregister(LongRealFeatures)

class DummyFeatures(Features):
    """
    The class DummyFeatures implements features that only know the number
    of feature objects (but don't actually contain any).

    This is used in the CCustomKernel.

    C++ includes: DummyFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, DummyFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, DummyFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, num) -> DummyFeatures
        __init__(self, orig) -> DummyFeatures

        copy constructor 
        """
        this = _Features.new_DummyFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_DummyFeatures
    __del__ = lambda self : None;
DummyFeatures_swigregister = _Features.DummyFeatures_swigregister
DummyFeatures_swigregister(DummyFeatures)

class T_ATTRIBUTE(_object):
    """
    Attribute Struct

    C++ includes: AttributeFeatures.h 
    """
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, T_ATTRIBUTE, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, T_ATTRIBUTE, name)
    __repr__ = _swig_repr
    __swig_setmethods__["attr_name"] = _Features.T_ATTRIBUTE_attr_name_set
    __swig_getmethods__["attr_name"] = _Features.T_ATTRIBUTE_attr_name_get
    if _newclass:attr_name = _swig_property(_Features.T_ATTRIBUTE_attr_name_get, _Features.T_ATTRIBUTE_attr_name_set)
    __swig_setmethods__["attr_obj"] = _Features.T_ATTRIBUTE_attr_obj_set
    __swig_getmethods__["attr_obj"] = _Features.T_ATTRIBUTE_attr_obj_get
    if _newclass:attr_obj = _swig_property(_Features.T_ATTRIBUTE_attr_obj_get, _Features.T_ATTRIBUTE_attr_obj_set)
    def __init__(self, *args): 
        """__init__(self) -> T_ATTRIBUTE"""
        this = _Features.new_T_ATTRIBUTE(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_T_ATTRIBUTE
    __del__ = lambda self : None;
T_ATTRIBUTE_swigregister = _Features.T_ATTRIBUTE_swigregister
T_ATTRIBUTE_swigregister(T_ATTRIBUTE)

class AttributeFeatures(Features):
    """
    Implements attributed features, that is in the simplest case a number
    of (attribute, value) pairs.

    For example

    x[0...].attr1 = <value(s)> x[0...].attr2 = <value(s)>.

    A more complex example would be nested structures
    x[0...].attr1[0...].subattr1 = ..

    This might be used to represent (attr, value) pairs, simple
    structures, trees ...

    C++ includes: AttributeFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, AttributeFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, AttributeFeatures, name)
    def __init__(self, *args, **kwargs): raise AttributeError, "No constructor defined"
    __repr__ = _swig_repr
    __swig_destroy__ = _Features.delete_AttributeFeatures
    __del__ = lambda self : None;
    def get_attribute(*args):
        """
        get_attribute(self, attr_name) -> Features

        return the feature object matching attribute name

        Parameters:
        -----------

        attr_name:  attribute name

        feature object 
        """
        return _Features.AttributeFeatures_get_attribute(*args)

    def get_attribute_by_index(*args):
        """
        get_attribute_by_index(self, idx, attr_name, attr_obj)

        return the feature object at index

        Parameters:
        -----------

        idx:  index of attribute

        attr_name:  attribute name (returned by reference)

        attr_obj:  attribute object (returned by reference) 
        """
        return _Features.AttributeFeatures_get_attribute_by_index(*args)

    def set_attribute(*args):
        """
        set_attribute(self, attr_name, attr_obj) -> bool

        set the feature object for attribute name

        Parameters:
        -----------

        attr_name:  attribute name

        attr_obj:  feature object to set

        true on success 
        """
        return _Features.AttributeFeatures_set_attribute(*args)

    def del_attribute(*args):
        """
        del_attribute(self, attr_name) -> bool

        delete the attribute matching attribute name

        Parameters:
        -----------

        attr_name:  attribute name

        true on success 
        """
        return _Features.AttributeFeatures_del_attribute(*args)

    def get_num_attributes(*args):
        """
        get_num_attributes(self) ->  int

        get number of attributes

        number of attributes 
        """
        return _Features.AttributeFeatures_get_num_attributes(*args)

AttributeFeatures_swigregister = _Features.AttributeFeatures_swigregister
AttributeFeatures_swigregister(AttributeFeatures)

DNA = _Features.DNA
RAWDNA = _Features.RAWDNA
RNA = _Features.RNA
PROTEIN = _Features.PROTEIN
BINARY = _Features.BINARY
ALPHANUM = _Features.ALPHANUM
CUBE = _Features.CUBE
RAWBYTE = _Features.RAWBYTE
IUPAC_NUCLEIC_ACID = _Features.IUPAC_NUCLEIC_ACID
IUPAC_AMINO_ACID = _Features.IUPAC_AMINO_ACID
NONE = _Features.NONE
UNKNOWN = _Features.UNKNOWN
class Alphabet(SGObject):
    """
    The class Alphabet implements an alphabet and alphabet utility
    functions.

    These utility functions can be used to remap stracters to more
    (bit-)efficient representations, check if a string is valid, compute
    histograms etc.

    Currently supported alphabets are DNA, RAWDNA, RNA, PROTEIN, BINARY,
    ALPHANUM, CUBE, RAW, IUPAC_NUCLEIC_ACID and IUPAC_AMINO_ACID.

    C++ includes: Alphabet.h 
    """
    __swig_setmethods__ = {}
    for _s in [SGObject]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, Alphabet, name, value)
    __swig_getmethods__ = {}
    for _s in [SGObject]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, Alphabet, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, alpha, len) -> Alphabet
        __init__(self, alpha) -> Alphabet
        __init__(self, alpha) -> Alphabet

        constructor

        Parameters:
        -----------

        alpha:  alphabet to use 
        """
        this = _Features.new_Alphabet(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_Alphabet
    __del__ = lambda self : None;
    def set_alphabet(*args):
        """
        set_alphabet(self, alpha) -> bool

        set alphabet and initialize mapping table (for remap)

        Parameters:
        -----------

        alpha:  new alphabet 
        """
        return _Features.Alphabet_set_alphabet(*args)

    def get_alphabet(*args):
        """
        get_alphabet(self) -> EAlphabet

        get alphabet

        alphabet 
        """
        return _Features.Alphabet_get_alphabet(*args)

    def get_num_symbols(*args):
        """
        get_num_symbols(self) ->  int

        get number of symbols in alphabet

        number of symbols 
        """
        return _Features.Alphabet_get_num_symbols(*args)

    def get_num_bits(*args):
        """
        get_num_bits(self) ->  int

        get number of bits necessary to store all symbols in alphabet

        number of necessary storage bits 
        """
        return _Features.Alphabet_get_num_bits(*args)

    def remap_to_bin(*args):
        """
        remap_to_bin(self, c) -> int

        remap element e.g translate ACGT to 0123

        Parameters:
        -----------

        c:  element to remap

        remapped element 
        """
        return _Features.Alphabet_remap_to_bin(*args)

    def remap_to_char(*args):
        """
        remap_to_char(self, c) -> int

        remap element e.g translate 0123 to ACGT

        Parameters:
        -----------

        c:  element to remap

        remapped element 
        """
        return _Features.Alphabet_remap_to_char(*args)

    def clear_histogram(*args):
        """
        clear_histogram(self)

        clear histogram 
        """
        return _Features.Alphabet_clear_histogram(*args)

    def add_byte_to_histogram(*args):
        """
        add_byte_to_histogram(self, p)

        add element to histogram

        Parameters:
        -----------

        p:  element 
        """
        return _Features.Alphabet_add_byte_to_histogram(*args)

    def print_histogram(*args):
        """
        print_histogram(self)

        print histogram 
        """
        return _Features.Alphabet_print_histogram(*args)

    def get_hist(*args):
        """
        get_hist(self) -> numpy 1dim array of int

        get histogram

        Parameters:
        -----------

        h:  where the histogram will be stored

        len:  length of histogram 
        """
        return _Features.Alphabet_get_hist(*args)

    def get_histogram(*args):
        """
        get_histogram(self) -> int

        get pointer to histogram 
        """
        return _Features.Alphabet_get_histogram(*args)

    def check_alphabet(*args):
        """
        check_alphabet(self, print_error=True) -> bool
        check_alphabet(self) -> bool

        check whether symbols in histogram are valid in alphabet e.g. for DNA
        if only letters ACGT appear

        Parameters:
        -----------

        print_error:  if errors shall be printed

        if symbols in histogram are valid in alphabet 
        """
        return _Features.Alphabet_check_alphabet(*args)

    def is_valid(*args):
        """
        is_valid(self, c) -> bool

        check whether symbols are valid in alphabet e.g. for DNA if symbol is
        one of the A,C,G or T

        Parameters:
        -----------

        c:  symbol

        if symbol is a valid stracter in alphabet 
        """
        return _Features.Alphabet_is_valid(*args)

    def check_alphabet_size(*args):
        """
        check_alphabet_size(self, print_error=True) -> bool
        check_alphabet_size(self) -> bool

        check whether symbols in histogram ALL fit in alphabet

        Parameters:
        -----------

        print_error:  if errors shall be printed

        if symbols in histogram ALL fit in alphabet 
        """
        return _Features.Alphabet_check_alphabet_size(*args)

    def get_num_symbols_in_histogram(*args):
        """
        get_num_symbols_in_histogram(self) ->  int

        return number of symbols in histogram

        number of symbols in histogram 
        """
        return _Features.Alphabet_get_num_symbols_in_histogram(*args)

    def get_max_value_in_histogram(*args):
        """
        get_max_value_in_histogram(self) ->  int

        return maximum value in histogram

        maximum value in histogram 
        """
        return _Features.Alphabet_get_max_value_in_histogram(*args)

    def get_num_bits_in_histogram(*args):
        """
        get_num_bits_in_histogram(self) ->  int

        return number of bits required to store all symbols in histogram

        number of bits required to store all symbols in histogram 
        """
        return _Features.Alphabet_get_num_bits_in_histogram(*args)

    def get_alphabet_name(*args):
        """get_alphabet_name(alphabet) -> str"""
        return _Features.Alphabet_get_alphabet_name(*args)

    if _newclass:get_alphabet_name = staticmethod(get_alphabet_name)
    __swig_getmethods__["get_alphabet_name"] = lambda x: get_alphabet_name
    __swig_setmethods__["alphabet_names"] = _Features.Alphabet_alphabet_names_set
    __swig_getmethods__["alphabet_names"] = _Features.Alphabet_alphabet_names_get
    if _newclass:alphabet_names = _swig_property(_Features.Alphabet_alphabet_names_get, _Features.Alphabet_alphabet_names_set)
Alphabet_swigregister = _Features.Alphabet_swigregister
Alphabet_swigregister(Alphabet)

def Alphabet_get_alphabet_name(*args):
  """Alphabet_get_alphabet_name(alphabet) -> str"""
  return _Features.Alphabet_get_alphabet_name(*args)
Alphabet.B_A = _Features.cvar.Alphabet_B_A
Alphabet.B_C = _Features.cvar.Alphabet_B_C
Alphabet.B_G = _Features.cvar.Alphabet_B_G
Alphabet.B_T = _Features.cvar.Alphabet_B_T
Alphabet.MAPTABLE_UNDEF = _Features.cvar.Alphabet_MAPTABLE_UNDEF

class CombinedFeatures(Features):
    """
    The class CombinedFeatures is used to combine a number of of feature
    objects into a single CombinedFeatures object.

    It keeps pointers to the added sub-features and is especially useful
    to combine kernels working on different domains (c.f. CCombinedKernel)
    and to combine kernels looking at independent features.

    C++ includes: CombinedFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [Features]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, CombinedFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [Features]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, CombinedFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> CombinedFeatures
        __init__(self, orig) -> CombinedFeatures

        copy constructor 
        """
        this = _Features.new_CombinedFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_CombinedFeatures
    __del__ = lambda self : None;
    def list_feature_objs(*args):
        """
        list_feature_objs(self)

        list feature objects 
        """
        return _Features.CombinedFeatures_list_feature_objs(*args)

    def check_feature_obj_compatibility(*args):
        """
        check_feature_obj_compatibility(self, comb_feat) -> bool

        check feature object compatibility

        Parameters:
        -----------

        comb_feat:  feature to check for compatibility

        if feature is compatible 
        """
        return _Features.CombinedFeatures_check_feature_obj_compatibility(*args)

    def get_first_feature_obj(*args):
        """
        get_first_feature_obj(self) -> Features
        get_first_feature_obj(self, current) -> Features

        get first feature object

        Parameters:
        -----------

        current:  list of features

        first feature object 
        """
        return _Features.CombinedFeatures_get_first_feature_obj(*args)

    def get_next_feature_obj(*args):
        """
        get_next_feature_obj(self) -> Features
        get_next_feature_obj(self, current) -> Features

        get next feature object

        Parameters:
        -----------

        current:  list of features

        next feature object 
        """
        return _Features.CombinedFeatures_get_next_feature_obj(*args)

    def get_last_feature_obj(*args):
        """
        get_last_feature_obj(self) -> Features

        get last feature object

        last feature object 
        """
        return _Features.CombinedFeatures_get_last_feature_obj(*args)

    def insert_feature_obj(*args):
        """
        insert_feature_obj(self, obj) -> bool

        insert feature object

        Parameters:
        -----------

        obj:  feature object to insert

        if inserting was successful 
        """
        return _Features.CombinedFeatures_insert_feature_obj(*args)

    def append_feature_obj(*args):
        """
        append_feature_obj(self, obj) -> bool

        append feature object

        Parameters:
        -----------

        obj:  feature object to append

        if appending was successful 
        """
        return _Features.CombinedFeatures_append_feature_obj(*args)

    def delete_feature_obj(*args):
        """
        delete_feature_obj(self) -> bool

        delete feature object

        if deleting was successful 
        """
        return _Features.CombinedFeatures_delete_feature_obj(*args)

    def get_num_feature_obj(*args):
        """
        get_num_feature_obj(self) ->  int

        get number of feature objects

        number of feature objects 
        """
        return _Features.CombinedFeatures_get_num_feature_obj(*args)

CombinedFeatures_swigregister = _Features.CombinedFeatures_swigregister
CombinedFeatures_swigregister(CombinedFeatures)

class CombinedDotFeatures(DotFeatures):
    """
    Features that allow stacking of a number of DotFeatures.

    They transparently provide all the operations of DotFeatures, i.e.

    a way to obtain the dimensionality of the feature space, i.e.
    $\\mbox{dim}({\\cal X})$

    dot product between feature vectors:

    \\[r = {\\bf x} \\cdot {\\bf x'}\\]

    dot product between feature vector and a dense vector ${\\bf z}$:

    \\[r = {\\bf x} \\cdot {\\bf z}\\]

    multiplication with a scalar $\\alpha$ and addition on to a dense
    vector ${\\bf z}$:

    \\[{\\bf z'} = \\alpha {\\bf x} + {\\bf z}\\]

    C++ includes: CombinedDotFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, CombinedDotFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, CombinedDotFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> CombinedDotFeatures
        __init__(self, orig) -> CombinedDotFeatures

        copy constructor 
        """
        this = _Features.new_CombinedDotFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_CombinedDotFeatures
    __del__ = lambda self : None;
    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.CombinedDotFeatures_add_to_dense_vec(*args)

    def list_feature_objs(*args):
        """
        list_feature_objs(self)

        list feature objects 
        """
        return _Features.CombinedDotFeatures_list_feature_objs(*args)

    def get_first_feature_obj(*args):
        """
        get_first_feature_obj(self) -> DotFeatures
        get_first_feature_obj(self, current) -> DotFeatures

        get first feature object

        Parameters:
        -----------

        current:  list of features

        first feature object 
        """
        return _Features.CombinedDotFeatures_get_first_feature_obj(*args)

    def get_next_feature_obj(*args):
        """
        get_next_feature_obj(self) -> DotFeatures
        get_next_feature_obj(self, current) -> DotFeatures

        get next feature object

        Parameters:
        -----------

        current:  list of features

        next feature object 
        """
        return _Features.CombinedDotFeatures_get_next_feature_obj(*args)

    def get_last_feature_obj(*args):
        """
        get_last_feature_obj(self) -> DotFeatures

        get last feature object

        last feature object 
        """
        return _Features.CombinedDotFeatures_get_last_feature_obj(*args)

    def insert_feature_obj(*args):
        """
        insert_feature_obj(self, obj) -> bool

        insert feature object

        Parameters:
        -----------

        obj:  feature object to insert

        if inserting was successful 
        """
        return _Features.CombinedDotFeatures_insert_feature_obj(*args)

    def append_feature_obj(*args):
        """
        append_feature_obj(self, obj) -> bool

        append feature object

        Parameters:
        -----------

        obj:  feature object to append

        if appending was successful 
        """
        return _Features.CombinedDotFeatures_append_feature_obj(*args)

    def delete_feature_obj(*args):
        """
        delete_feature_obj(self) -> bool

        delete feature object

        if deleting was successful 
        """
        return _Features.CombinedDotFeatures_delete_feature_obj(*args)

    def get_num_feature_obj(*args):
        """
        get_num_feature_obj(self) ->  int

        get number of feature objects

        number of feature objects 
        """
        return _Features.CombinedDotFeatures_get_num_feature_obj(*args)

    def get_subfeature_weights(*args):
        """
        get_subfeature_weights(self, weights, num_weights)

        get subfeature weights

        Parameters:
        -----------

        weights:  subfeature weights

        num_weights:  where number of weights is stored 
        """
        return _Features.CombinedDotFeatures_get_subfeature_weights(*args)

    def set_subfeature_weights(*args):
        """
        set_subfeature_weights(self, weights, num_weights)

        set subfeature weights

        Parameters:
        -----------

        weights:  new subfeature weights

        num_weights:  number of subfeature weights 
        """
        return _Features.CombinedDotFeatures_set_subfeature_weights(*args)

CombinedDotFeatures_swigregister = _Features.CombinedDotFeatures_swigregister
CombinedDotFeatures_swigregister(CombinedDotFeatures)

class Labels(SGObject):
    """
    The class Labels models labels, i.e. class assignments of objects.

    Labels here are always real-valued and thus applicable to
    classification (cf. CClassifier) and regression (cf. CRegression)
    problems.

    C++ includes: Labels.h 
    """
    __swig_setmethods__ = {}
    for _s in [SGObject]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, Labels, name, value)
    __swig_getmethods__ = {}
    for _s in [SGObject]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, Labels, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self) -> Labels
        __init__(self, num_labels) -> Labels
        __init__(self, src) -> Labels
        __init__(self, fname) -> Labels

        constructor

        Parameters:
        -----------

        fname:  filename to load labels from 
        """
        this = _Features.new_Labels(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_Labels
    __del__ = lambda self : None;
    def load(*args):
        """
        load(self, fname) -> bool

        load labels from file

        Parameters:
        -----------

        fname:  filename to load from

        if loading was successful 
        """
        return _Features.Labels_load(*args)

    def save(*args):
        """
        save(self, fname) -> bool

        save labels to file

        Parameters:
        -----------

        fname:  filename to save to

        if saving was successful 
        """
        return _Features.Labels_save(*args)

    def set_label(*args):
        """
        set_label(self, idx, label) -> bool

        set label

        Parameters:
        -----------

        idx:  index of label to set

        label:  value of label

        if setting was successful 
        """
        return _Features.Labels_set_label(*args)

    def set_int_label(*args):
        """
        set_int_label(self, idx, label) -> bool

        set INT label

        Parameters:
        -----------

        idx:  index of label to set

        label:  INT value of label

        if setting was successful 
        """
        return _Features.Labels_set_int_label(*args)

    def get_label(*args):
        """
        get_label(self, idx) -> float

        get label

        Parameters:
        -----------

        idx:  index of label to get

        value of label 
        """
        return _Features.Labels_get_label(*args)

    def get_int_label(*args):
        """
        get_int_label(self, idx) ->  int

        get INT label

        Parameters:
        -----------

        idx:  index of label to get

        INT value of label 
        """
        return _Features.Labels_get_int_label(*args)

    def is_two_class_labeling(*args):
        """
        is_two_class_labeling(self) -> bool

        is two-class labeling

        if this is two-class labeling 
        """
        return _Features.Labels_is_two_class_labeling(*args)

    def get_num_classes(*args):
        """
        get_num_classes(self) ->  int

        return number of classes (for multiclass) labels have to be zero based
        0,1,...C missing labels are illegal

        number of classes 
        """
        return _Features.Labels_get_num_classes(*args)

    def get_labels(*args):
        """
        get_labels(self) -> numpy 1dim array of float
        get_labels(self) -> numpy 1dim array of float

        get labels (swig compatible)

        Parameters:
        -----------

        dst:  where labels will be stored in

        len:  where number of labels will be stored in 
        """
        return _Features.Labels_get_labels(*args)

    def set_labels(*args):
        """
        set_labels(self, src)

        set labels

        Parameters:
        -----------

        src:  labels to set

        len:  number of labels 
        """
        return _Features.Labels_set_labels(*args)

    def get_int_labels(*args):
        """
        get_int_labels(self, len) ->  int

        get INT label vector caller has to clean up

        Parameters:
        -----------

        len:  number of labels to get

        INT labels 
        """
        return _Features.Labels_get_int_labels(*args)

    def set_int_labels(*args):
        """
        set_int_labels(self, labels, len)

        set INT labels caller has to clean up

        Parameters:
        -----------

        labels:  INT labels

        len:  number of INT labels 
        """
        return _Features.Labels_set_int_labels(*args)

    def get_num_labels(*args):
        """
        get_num_labels(self) ->  int

        get number of labels

        number of labels 
        """
        return _Features.Labels_get_num_labels(*args)

Labels_swigregister = _Features.Labels_swigregister
Labels_swigregister(Labels)

class RealFileFeatures(RealFeatures):
    """
    The class RealFileFeatures implements a dense float-precision
    floating point matrix from a file.

    It inherits its functionality from CSimpleFeatures, which should be
    consulted for further reference.

    C++ includes: RealFileFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [RealFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, RealFileFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [RealFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, RealFileFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size, file) -> RealFileFeatures
        __init__(self, size, filename) -> RealFileFeatures
        __init__(self, orig) -> RealFileFeatures

        copy constructor 
        """
        this = _Features.new_RealFileFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_RealFileFeatures
    __del__ = lambda self : None;
    def load_feature_matrix(*args):
        """
        load_feature_matrix(self) -> float

        load feature matrix

        loaded feature matrix 
        """
        return _Features.RealFileFeatures_load_feature_matrix(*args)

    def get_label(*args):
        """
        get_label(self, idx) ->  int

        get label at given index

        Parameters:
        -----------

        idx:  index to look at

        label at given index 
        """
        return _Features.RealFileFeatures_get_label(*args)

RealFileFeatures_swigregister = _Features.RealFileFeatures_swigregister
RealFileFeatures_swigregister(RealFileFeatures)

class FKFeatures(RealFeatures):
    """
    The class FKFeatures implements Fischer kernel features obtained from
    two Hidden Markov models.

    It was used in

    K. Tsuda, M. Kawanabe, G. Raetsch, S. Sonnenburg, and K.R. Mueller. A
    new discriminative kernel from probabilistic models. Neural
    Computation, 14:2397-2414, 2002.

    which also has the details.

    Note that FK-features are computed on the fly, so to be effective
    feature caching should be enabled.

    It inherits its functionality from CSimpleFeatures, which should be
    consulted for further reference.

    C++ includes: FKFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [RealFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, FKFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [RealFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, FKFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size, p, n) -> FKFeatures
        __init__(self, orig) -> FKFeatures

        copy constructor 
        """
        this = _Features.new_FKFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_FKFeatures
    __del__ = lambda self : None;
    def set_models(*args):
        """
        set_models(self, p, n)

        set HMMs

        Parameters:
        -----------

        p:  positive HMM

        n:  negative HMM 
        """
        return _Features.FKFeatures_set_models(*args)

    def set_a(*args):
        """
        set_a(self, a)

        set weight a

        Parameters:
        -----------

        a:  weight a 
        """
        return _Features.FKFeatures_set_a(*args)

    def get_a(*args):
        """
        get_a(self) -> float

        get weight a

        weight a 
        """
        return _Features.FKFeatures_get_a(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self) -> float

        set feature matrix

        something floaty 
        """
        return _Features.FKFeatures_set_feature_matrix(*args)

    def set_opt_a(*args):
        """
        set_opt_a(self, a=-1) -> float
        set_opt_a(self) -> float

        set opt a

        Parameters:
        -----------

        a:  a

        something floaty 
        """
        return _Features.FKFeatures_set_opt_a(*args)

    def get_weight_a(*args):
        """
        get_weight_a(self) -> float

        get weight_a

        weight_a 
        """
        return _Features.FKFeatures_get_weight_a(*args)

FKFeatures_swigregister = _Features.FKFeatures_swigregister
FKFeatures_swigregister(FKFeatures)

class T_HMM_INDIZES(_object):
    """
    HMM indices

    C++ includes: TOPFeatures.h 
    """
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, T_HMM_INDIZES, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, T_HMM_INDIZES, name)
    __repr__ = _swig_repr
    __swig_setmethods__["idx_p"] = _Features.T_HMM_INDIZES_idx_p_set
    __swig_getmethods__["idx_p"] = _Features.T_HMM_INDIZES_idx_p_get
    if _newclass:idx_p = _swig_property(_Features.T_HMM_INDIZES_idx_p_get, _Features.T_HMM_INDIZES_idx_p_set)
    __swig_setmethods__["idx_q"] = _Features.T_HMM_INDIZES_idx_q_set
    __swig_getmethods__["idx_q"] = _Features.T_HMM_INDIZES_idx_q_get
    if _newclass:idx_q = _swig_property(_Features.T_HMM_INDIZES_idx_q_get, _Features.T_HMM_INDIZES_idx_q_set)
    __swig_setmethods__["idx_a_rows"] = _Features.T_HMM_INDIZES_idx_a_rows_set
    __swig_getmethods__["idx_a_rows"] = _Features.T_HMM_INDIZES_idx_a_rows_get
    if _newclass:idx_a_rows = _swig_property(_Features.T_HMM_INDIZES_idx_a_rows_get, _Features.T_HMM_INDIZES_idx_a_rows_set)
    __swig_setmethods__["idx_a_cols"] = _Features.T_HMM_INDIZES_idx_a_cols_set
    __swig_getmethods__["idx_a_cols"] = _Features.T_HMM_INDIZES_idx_a_cols_get
    if _newclass:idx_a_cols = _swig_property(_Features.T_HMM_INDIZES_idx_a_cols_get, _Features.T_HMM_INDIZES_idx_a_cols_set)
    __swig_setmethods__["idx_b_rows"] = _Features.T_HMM_INDIZES_idx_b_rows_set
    __swig_getmethods__["idx_b_rows"] = _Features.T_HMM_INDIZES_idx_b_rows_get
    if _newclass:idx_b_rows = _swig_property(_Features.T_HMM_INDIZES_idx_b_rows_get, _Features.T_HMM_INDIZES_idx_b_rows_set)
    __swig_setmethods__["idx_b_cols"] = _Features.T_HMM_INDIZES_idx_b_cols_set
    __swig_getmethods__["idx_b_cols"] = _Features.T_HMM_INDIZES_idx_b_cols_get
    if _newclass:idx_b_cols = _swig_property(_Features.T_HMM_INDIZES_idx_b_cols_get, _Features.T_HMM_INDIZES_idx_b_cols_set)
    __swig_setmethods__["num_p"] = _Features.T_HMM_INDIZES_num_p_set
    __swig_getmethods__["num_p"] = _Features.T_HMM_INDIZES_num_p_get
    if _newclass:num_p = _swig_property(_Features.T_HMM_INDIZES_num_p_get, _Features.T_HMM_INDIZES_num_p_set)
    __swig_setmethods__["num_q"] = _Features.T_HMM_INDIZES_num_q_set
    __swig_getmethods__["num_q"] = _Features.T_HMM_INDIZES_num_q_get
    if _newclass:num_q = _swig_property(_Features.T_HMM_INDIZES_num_q_get, _Features.T_HMM_INDIZES_num_q_set)
    __swig_setmethods__["num_a"] = _Features.T_HMM_INDIZES_num_a_set
    __swig_getmethods__["num_a"] = _Features.T_HMM_INDIZES_num_a_get
    if _newclass:num_a = _swig_property(_Features.T_HMM_INDIZES_num_a_get, _Features.T_HMM_INDIZES_num_a_set)
    __swig_setmethods__["num_b"] = _Features.T_HMM_INDIZES_num_b_set
    __swig_getmethods__["num_b"] = _Features.T_HMM_INDIZES_num_b_get
    if _newclass:num_b = _swig_property(_Features.T_HMM_INDIZES_num_b_get, _Features.T_HMM_INDIZES_num_b_set)
    def __init__(self, *args): 
        """__init__(self) -> T_HMM_INDIZES"""
        this = _Features.new_T_HMM_INDIZES(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_T_HMM_INDIZES
    __del__ = lambda self : None;
T_HMM_INDIZES_swigregister = _Features.T_HMM_INDIZES_swigregister
T_HMM_INDIZES_swigregister(T_HMM_INDIZES)

class TOPFeatures(RealFeatures):
    """
    The class TOPFeatures implements TOP kernel features obtained from two
    Hidden Markov models.

    It was used in

    K. Tsuda, M. Kawanabe, G. Raetsch, S. Sonnenburg, and K.R. Mueller. A
    new discriminative kernel from probabilistic models. Neural
    Computation, 14:2397-2414, 2002.

    which also has the details.

    Note that TOP-features are computed on the fly, so to be effective
    feature caching should be enabled.

    It inherits its functionality from CSimpleFeatures, which should be
    consulted for further reference.

    C++ includes: TOPFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [RealFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, TOPFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [RealFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, TOPFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, size, p, n, neglin, poslin) -> TOPFeatures
        __init__(self, orig) -> TOPFeatures

        copy constructor 
        """
        this = _Features.new_TOPFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_TOPFeatures
    __del__ = lambda self : None;
    def set_models(*args):
        """
        set_models(self, p, n)

        set HMMs

        Parameters:
        -----------

        p:  positive HMM

        n:  negative HMM 
        """
        return _Features.TOPFeatures_set_models(*args)

    def set_feature_matrix(*args):
        """
        set_feature_matrix(self) -> float

        set feature matrix

        something floaty 
        """
        return _Features.TOPFeatures_set_feature_matrix(*args)

    def compute_num_features(*args):
        """
        compute_num_features(self) ->  int

        compute number of features

        number of features 
        """
        return _Features.TOPFeatures_compute_num_features(*args)

    def compute_relevant_indizes(*args):
        """
        compute_relevant_indizes(self, hmm, hmm_idx) -> bool

        compute relevant indices

        Parameters:
        -----------

        hmm:  HMM to compute for

        hmm_idx:  HMM index

        if computing was successful 
        """
        return _Features.TOPFeatures_compute_relevant_indizes(*args)

TOPFeatures_swigregister = _Features.TOPFeatures_swigregister
TOPFeatures_swigregister(TOPFeatures)

class WDFeatures(DotFeatures):
    """
    Features that compute the Weighted Degreee Kernel feature space
    explicitly.

    See:  CWeightedDegreeStringKernel

    C++ includes: WDFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, WDFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, WDFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, str, order, from_order) -> WDFeatures
        __init__(self, orig) -> WDFeatures

        copy constructor 
        """
        this = _Features.new_WDFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_WDFeatures
    __del__ = lambda self : None;
    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.WDFeatures_add_to_dense_vec(*args)

WDFeatures_swigregister = _Features.WDFeatures_swigregister
WDFeatures_swigregister(WDFeatures)

class PolyFeatures(DotFeatures):
    """
    implement DotFeatures for the polynomial kernel

    see DotFeatures for further discription

    C++ includes: PolyFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, PolyFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, PolyFeatures, name)
    def __init__(self, *args, **kwargs): raise AttributeError, "No constructor defined"
    __repr__ = _swig_repr
    __swig_destroy__ = _Features.delete_PolyFeatures
    __del__ = lambda self : None;
PolyFeatures_swigregister = _Features.PolyFeatures_swigregister
PolyFeatures_swigregister(PolyFeatures)

class ExplicitSpecFeatures(DotFeatures):
    """
    Features that compute the Spectrum Kernel feature space explicitly.

    See:  CCommWordStringKernel

    C++ includes: ExplicitSpecFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, ExplicitSpecFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, ExplicitSpecFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, str, normalize=True) -> ExplicitSpecFeatures
        __init__(self, str) -> ExplicitSpecFeatures
        __init__(self, orig) -> ExplicitSpecFeatures

        copy constructor 
        """
        this = _Features.new_ExplicitSpecFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_ExplicitSpecFeatures
    __del__ = lambda self : None;
    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.ExplicitSpecFeatures_add_to_dense_vec(*args)

ExplicitSpecFeatures_swigregister = _Features.ExplicitSpecFeatures_swigregister
ExplicitSpecFeatures_swigregister(ExplicitSpecFeatures)

class ImplicitWeightedSpecFeatures(DotFeatures):
    """
    Features that compute the Weighted Spectrum Kernel feature space
    explicitly.

    See:  CWeightedCommWordStringKernel

    C++ includes: ImplicitWeightedSpecFeatures.h 
    """
    __swig_setmethods__ = {}
    for _s in [DotFeatures]: __swig_setmethods__.update(getattr(_s,'__swig_setmethods__',{}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, ImplicitWeightedSpecFeatures, name, value)
    __swig_getmethods__ = {}
    for _s in [DotFeatures]: __swig_getmethods__.update(getattr(_s,'__swig_getmethods__',{}))
    __getattr__ = lambda self, name: _swig_getattr(self, ImplicitWeightedSpecFeatures, name)
    __repr__ = _swig_repr
    def __init__(self, *args): 
        """
        __init__(self, str, normalize=True) -> ImplicitWeightedSpecFeatures
        __init__(self, str) -> ImplicitWeightedSpecFeatures
        __init__(self, orig) -> ImplicitWeightedSpecFeatures

        copy constructor 
        """
        this = _Features.new_ImplicitWeightedSpecFeatures(*args)
        try: self.this.append(this)
        except: self.this = this
    __swig_destroy__ = _Features.delete_ImplicitWeightedSpecFeatures
    __del__ = lambda self : None;
    def add_to_dense_vec(*args):
        """
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len, abs_val=False)
        add_to_dense_vec(self, alpha, vec_idx1, vec2, vec2_len)

        add vector 1 multiplied with alpha to dense vector2

        Parameters:
        -----------

        alpha:  scalar alpha

        vec_idx1:  index of first vector

        vec2:  pointer to real valued vector

        vec2_len:  length of real valued vector

        abs_val:  if true add the absolute value 
        """
        return _Features.ImplicitWeightedSpecFeatures_add_to_dense_vec(*args)

    def set_wd_weights(*args):
        """
        set_wd_weights(self) -> bool

        set weighted degree weights

        if setting was successful 
        """
        return _Features.ImplicitWeightedSpecFeatures_set_wd_weights(*args)

    def set_weights(*args):
        """
        set_weights(self, w, d) -> bool

        set custom weights (swig compatible)

        Parameters:
        -----------

        w:  weights

        d:  degree (must match number of weights)

        if setting was successful 
        """
        return _Features.ImplicitWeightedSpecFeatures_set_weights(*args)

ImplicitWeightedSpecFeatures_swigregister = _Features.ImplicitWeightedSpecFeatures_swigregister
ImplicitWeightedSpecFeatures_swigregister(ImplicitWeightedSpecFeatures)



